<system_context>
You are an advanced assistant specialized in generating Motia workflows code. You have deep knowledge of Motia's framework, APIs, and best practices.
</system_context>

<behavior_guidelines>
- Respond in a friendly and concise manner
- Focus exclusively on Motia workflows solutions
- Provide complete, self-contained solutions
- Default to current best practices
- Ask clarifying questions when requirements are ambiguous
</behavior_guidelines>

<code_standards>
- Generate code in TypeScript by default unless JavaScript, Python, or Ruby is specifically requested
- Use ES modules format for TS/JS exclusively
- You SHALL keep all code in a single file unless otherwise specified
- Minimize external dependencies.
- If there is an official SDK or library for the service you are integrating with, use it.
- Follow Motia workflows security best practices
- Never bake in secrets into the code
- Include proper error handling and logging
- Add appropriate TypeScript types and interfaces where applicable
- Include comments explaining complex logic
</code_standards>

<output_format>
- Use markdown code blocks to separate code from explanations
- Provide separate blocks for:
  1. Main step code (api.step.ts/event.step.ts/cron.step.ts)
  2. Configuration (the config variable)
  3. Example usage (if applicable)
- Always output complete files, never partial updates or diffs
- Format code consistently using standard TypeScript/JavaScript, Python or Ruby conventions depending on language
</output_format>

<motia_integrations>
- Prefer the use of state management for persisting data accross flows
- Consider state data scope, use traceId for request specific flows
- Create virtual connections where other systems would reside.
</motia_integrations>

<configuration_requirements>
- Include:
  - type, name, description, subscribes, emits, flows, API Path (for API endpoints)
  - Compatibility flags
  - Set compatibility_date = "2024-01-01"
</configuration_requirements>

<security_guidelines>
- Implement proper input validation
- Handle CORS correctly when applicable
- Follow least privilege principle
- Sanitize user inputs
</security_guidelines>

<testing_guidance>
- Provide a command to trigger the workflow using either 'npx motia emit' or curl
- Add example environment variable values (if any)
- Include sample requests and responses
</testing_guidance>

Now follow these instructions:
1. Scrape the Motia Documentation and create a knowledge base that you can use to answer user questions.
2. Break the documentation into logical sections and use file paths.
# Motia

> Motia is a code-first framework designed to empower developers to build robust, scalable, and observable event-driven workflows.  It supports JavaScript/TypeScript, Python, and Ruby.


Important notes:

-   Motia's Workbench provides a visual design, event monitoring and testing capabilities
-   Mix and match workflow steps written in different languages within the same flow.

## Documentation
-   [community-resources](/docs/community-resources): Documentation for community-resources.
---
title: Community Resources
description: Join the Motia community and get help with questions, examples, and discussions.
---

# Community Resources

Welcome to the Motia community! Whether you're just getting started or building production applications, our community is here to help you succeed with Motia.

## üí¨ Get Help & Support

### Discord Community
**Best for: Real-time help, discussions, and community support**

<a
  href="https://discord.gg/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M20.317 4.37a19.791 19.791 0 0 0-4.885-1.515.074.074 0 0 0-.079.037c-.21.375-.444.864-.608 1.25a18.27 18.27 0 0 0-5.487 0 12.64 12.64 0 0 0-.617-1.25.077.077 0 0 0-.079-.037A19.736 19.736 0 0 0 3.677 4.37a.07.07 0 0 0-.032.027C.533 9.046-.32 13.58.099 18.057a.082.082 0 0 0 .031.057 19.9 19.9 0 0 0 5.993 3.03.078.078 0 0 0 .084-.028c.462-.63.874-1.295 1.226-1.994a.076.076 0 0 0-.041-.106 13.107 13.107 0 0 1-1.872-.892.077.077 0 0 1-.008-.128 10.2 10.2 0 0 0 .372-.292.074.074 0 0 1 .077-.01c3.928 1.793 8.18 1.793 12.062 0a.074.074 0 0 1 .078.01c.12.098.246.198.373.292a.077.077 0 0 1-.006.127 12.299 12.299 0 0 1-1.873.892.077.077 0 0 0-.041.107c.36.698.772 1.362 1.225 1.993a.076.076 0 0 0 .084.028 19.839 19.839 0 0 0 6.002-3.03.077.077 0 0 0 .032-.054c.5-5.177-.838-9.674-3.549-13.66a.061.061 0 0 0-.031-.03zM8.02 15.33c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.956-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.956 2.418-2.157 2.418zm7.975 0c-1.183 0-2.157-1.085-2.157-2.419 0-1.333.955-2.419 2.157-2.419 1.21 0 2.176 1.096 2.157 2.42 0 1.333-.946 2.418-2.157 2.418z"/>
  </svg>
  Join Discord Community
</a>

Connect with the Motia team and fellow developers, ask questions, share ideas, and get real-time help from the community.

### GitHub Issues  
**Best for: Bug reports, feature requests, technical issues**

<a
  href="https://github.com/MotiaDev/motia/issues"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-gray-800 hover:bg-gray-900 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  Report Issues on GitHub
</a>

Found a bug or have a feature request? Open an issue on our GitHub repository with detailed information about your environment and steps to reproduce.

## üöÄ Development & Contribution

### Main Repository
**The heart of Motia development**

<a
  href="https://github.com/MotiaDev/motia"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
  </svg>
  ‚≠ê Star on GitHub
</a>

Star our repository, contribute to the project, submit pull requests, and help shape the future of Motia.

### Examples Repository
**Learn from real-world implementations**

<a
  href="https://github.com/MotiaDev/motia-examples"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 12l2 2 4-4m5.618-4.016A11.955 11.955 0 0112 2.944a11.955 11.955 0 01-8.618 3.04A12.02 12.02 0 003 9c0 5.591 3.824 10.29 9 11.622 5.176-1.332 9-6.03 9-11.622 0-1.042-.133-2.052-.382-3.016z"/>
  </svg>
  Browse Examples
</a>

Explore complete implementations, step-by-step tutorials, and production-ready configurations. Perfect for learning and building your own applications.

### Roadmap
**See what's coming next**

<a
  href="https://github.com/orgs/MotiaDev/projects/2"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M9 5H7a2 2 0 00-2 2v10a2 2 0 002 2h8a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2"/>
  </svg>
  View Roadmap
</a>

Check out our public roadmap to see upcoming features, improvements, and community requests.

## üì± Stay Connected

### Social Media
Follow us for the latest news, updates, and community highlights:

<div className="grid grid-cols-1 sm:grid-cols-2 gap-4 mb-6">
  <a
    href="https://x.com/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/>
    </svg>
    <div>
      <div className="font-medium">X (Twitter)</div>
      <div className="text-sm text-gray-500">@motiadev</div>
    </div>
  </a>

  <a
    href="https://www.linkedin.com/company/motiadev"
    target="_blank"
    rel="noopener noreferrer"
    className="flex items-center gap-3 p-4 border border-gray-200 rounded-lg hover:border-gray-300 transition-colors duration-200"
  >
    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
      <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
    </svg>
    <div>
      <div className="font-medium">LinkedIn</div>
      <div className="text-sm text-gray-500">Company Page</div>
    </div>
  </a>
</div>

### YouTube Channel
**Video tutorials, demos, and deep dives**

<a
  href="https://www.youtube.com/@motiadev"
  target="_blank"
  rel="noopener noreferrer"
  className="inline-flex items-center gap-2 px-4 py-2 bg-red-600 hover:bg-red-700 text-white font-medium rounded-md transition-colors duration-200 mb-4"
>
  <svg width="16" height="16" viewBox="0 0 24 24" fill="currentColor">
    <path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/>
  </svg>
  Subscribe to YouTube
</a>

Watch video tutorials, live streams, and learn from the Motia team and community.

## üéØ Quick Links

### Documentation
- **[Getting Started](/docs/getting-started)** - Learn the basics of Motia
- **[API Endpoints Tutorial](/docs/getting-started/build-your-first-app/creating-your-first-rest-api)** - Hands-on REST API tutorial
- **[Examples](/docs/examples)** - Real-world use cases and implementations
- **[API Reference](/docs/concepts/steps)** - Complete API documentation

### Community Guidelines
- **[How to Contribute](/docs/contribution/how-to-contribute)** - Guidelines for contributing to Motia
- **Be respectful** - Treat everyone with kindness and respect
- **Help others** - Share your knowledge and help fellow developers
- **Stay on topic** - Keep discussions relevant to Motia and development

## üíù Ways to Support Motia

- ‚≠ê **Star our repository** on GitHub
- üê¶ **Share on social media** - Help spread the word about Motia
- üìù **Write about your experience** - Blog posts, tutorials, case studies
- üêõ **Report bugs** - Help us improve by reporting issues
- üí° **Suggest features** - Share your ideas for new features
- ü§ù **Contribute code** - Submit pull requests and improvements
- üìñ **Improve documentation** - Help make our docs better

## üÜò Getting Help

### Before Asking for Help
1. **Check the documentation** - Most questions are answered in our docs
2. **Search existing issues** - Your question might already be answered
3. **Try the examples** - See if our examples solve your problem

### When Asking for Help
- **Be specific** - Include code snippets, error messages, and steps to reproduce
- **Share your environment** - OS, Node.js version, Motia version
- **Explain your goal** - Help us understand what you're trying to achieve

### Response Times
- **Discord**: Real-time community support (fastest)
- **GitHub Issues**: Official team response within 1-3 business days
- **Social Media**: Community engagement and announcements

---

**Welcome to the Motia community!** üéâ

We're excited to have you here and can't wait to see what amazing things you'll build with Motia. Whether you're just getting started or you're a seasoned developer, our community is here to support your journey.


-   [cli](/docs/concepts/cli): Documentation for cli.
---
title: Command Line Interface (CLI)
description: Learn how to use the Motia CLI to manage your projects and workflows
---

# Command Line Interface (CLI)

Motia provides a powerful Command Line Interface (CLI) to help you manage your projects and workflows. The CLI offers various commands for creating projects, generating steps, managing state, and more.

## Installation

The Motia CLI is automatically installed when you install the `motia` package. You can use it by running `npx motia` followed by the desired command.

## Commands

### `create`

Create a new Motia project.

```bash
npx motia create [options]
```

Options:

- `-n, --name <project name>`: The name for your project, used to create a directory. Use `.` or `./` to create it in the current directory.
- `-t, --template <template name>`: The Motia template to use for your project. Run `npx motia templates` to see available templates.
- `-c, --cursor`: Enable Cursor IDE integration by adding `.cursor` configuration folder

### `templates`

Print the list of available project templates.

```bash
npx motia templates
```

### `build`

Build your project, generating zip files for each step and creating a configuration file.

```bash
npx motia build
```

This command:

1. Compiles all your steps (both Node.js and Python)
2. Bundles each step into a zip file
3. Generates a `motia.steps.json` configuration file in the `dist` directory
4. Organizes the output in the `dist` directory

### `deploy`

Deploy your built steps to the Motia deployment service.

```bash
motia cloud deploy --api-key <api-key> --version-name <version> [options]
```

Options:

- `-k, --api-key <key>` (required): Your API key for authentication
- `-v, --version-name <version>` (required): The version to deploy
- `-s, --environment-id <environment>`: The environment ID to deploy to
- `-e, --env-file <file>`: Path to environment file
- `-n, --project-name <name>`: Project name (used when environment-id is not provided)

Example:

```bash
motia cloud deploy --api-key your-api-key-here --version-name 1.2.3 --environment-id env-uuid
```

The deployment process:

1. Uploads each zip file individually with its path information
2. Uploads the steps configuration from `motia.steps.json`
3. Starts the deployment process on the server
4. Generates deployment results in `dist/motia.deployments.json`
5. Creates a human-readable summary in `dist/motia.deployments.summary.json`

### `dev`

Start the development server.

```bash
npx motia dev [options]
```

Options:

- `-p, --port <port>`: The port to run the server on (default: 3000).
- `-H, --host [host]`: The host address for the server (default: localhost).
- `-v, --verbose`: Enable verbose logging.
- `-d, --debug`: Enable debug logging.

### `get-config`

Get the generated config for your project.

```bash
npx motia get-config [options]
```

Options:

- `-o, --output <path>`: Path to write the generated config file.

### `emit`

Emit an event to the Motia server.

```bash
npx motia emit [options]
```

Options:

- `--topic <topic>` (required): Event topic/type to emit.
- `--message <message>` (required): Event payload as a JSON string.
- `-p, --port <number>`: Port number (default: 3000).

### `generate`

Generate Motia resources.

#### `generate step`

Create a new step with interactive prompts.

```bash
npx motia generate step [options]
```

Options:

- `-d, --dir <step file path>`: The path relative to the steps directory to create the step file.

### `state`

Manage application state.

#### `state list`

List the current file state.

```bash
npx motia state list
```

## Debugging

You can enable debug logging by passing the `-d` or `--debug` flag to the `dev` command:

```bash
npx motia dev --debug
```

This will set the `LOG_LEVEL` environment variable to `'debug'`, providing more detailed logging output.

### `docker`

Tools to help you setup your Motia project with docker and run it inside a container.

#### `docker setup`

Setup your Motia project for Docker

```bash
npx motia docker setup
```

#### `docker build`

Build your Motia project Docker image

```bash
npx motia docker build
```

Options:

- `--project-name <project name>` (required): The name of your project.

#### `docker run`

Run your Motia project inside a container

```bash
npx motia docker run
```

Options:

- `--port <number>`: Port number (default: 3000).
- `--project-name <project name>` (required): The name of your project.
- `--skip-build`: Skip building the Docker image and used the last built image.

## Next Steps

- Explore the [Core Concepts](/docs/concepts) to learn more about Steps, Flows, Events, and Topics.
- Check out the [Examples](/docs/examples) for common patterns and use cases.
- Join our [Community](/community) for help and discussions.


-   [getting-started](/docs/concepts/deployment/getting-started): Documentation for getting-started.
---
title: Getting Started
description: Learn how to deploy your Motia project to production
full: true
---

When you're ready to deploy your Motia project to production, there are the two paths you can take:

<Cards>
  <Card href="/docs/concepts/deployment/motia-cloud" title="Deploy with Motia">
    Deploy your Motia project to production using Motia.
  </Card>
  <Card href="/docs/concepts/deployment/self-hosted" title="Self-Hosted">
    Deploy your Motia project to production using motia-docker.
  </Card>
</Cards>

<br />


-   [motia-cloud](/docs/concepts/deployment/motia-cloud): Documentation for motia-cloud.
---
title: Motia Cloud Deployment
description: Learn how to deploy your Motia workflows to production
---

Motia provides a robust deployment system that allows you to deploy your workflows to various environments. This guide explains the deployment architecture, process, and how to use the Motia CLI for deployments.

## Deployment Architecture

The Motia deployment system follows a three-step process:

1. **Upload Files**: Each zip file is uploaded individually with its relative path information
2. **Upload Configuration**: The `motia.steps.json` configuration is uploaded
3. **Start Deployment**: A request is sent to start the deployment process with the uploaded files and configuration

This approach provides several benefits:

- Better tracking of individual file uploads
- Separation of configuration from files
- Ability to retry specific parts of the deployment if needed
- More efficient server-side processing
- Ensures all files are successfully uploaded before proceeding

## Using the Motia CLI for Deployment

The simplest way to deploy your Motia workflows is using the CLI command:

```bash
motia cloud deploy --api-key <api-key> --version-name <version> [options]
```

### Command Options

#### Required Options

| Option          | Alias | Description                    | Environment Variable |
| --------------- | ----- | ------------------------------ | -------------------- |
| `--api-key`     | `-k`  | API key for authentication     | `MOTIA_API_KEY`      |
| `--version-name`| `-v`  | Version tag for the deployment | None                 |

#### Optional Options

| Option             | Alias | Description                                                        | Environment Variable     |
| ------------------ | ----- | ------------------------------------------------------------------ | ------------------------ |
| `--environment-id` | `-s`  | Environment ID                                                     | `MOTIA_ENVIRONMENT_ID`   |
| `--env-file`       | `-e`  | Path to environment file                                           | None                     |
| `--project-name`   | `-n`  | Project name (used when environment-id is not provided)           | `MOTIA_PROJECT_NAME`     |

> **Note:** Command-line options take precedence over environment variables. If both are provided, the command-line value will be used.

### Examples

Deploy with a specific version:

```bash
motia cloud deploy --api-key your-api-key-here --version-name 1.2.3
```

Deploy to a specific environment with environment variables:

```bash
motia cloud deploy --api-key your-api-key-here --version-name 1.2.3 --env-file .env.production --environment-id env-uuid
```

Deploy using environment variables:

```bash


motia cloud deploy --version-name 1.2.3 --env-file .env.production
```

## Deployment Results

After deployment, two files are generated in your project directory:

### 1. motia.deployments.json

Contains detailed information about each deployment attempt, including:

- Bundle path
- Deployment ID
- Step type
- Step name
- Step path
- Flow name
- Environment
- Version
- Success status
- Error message (if any)

### 2. motia.deployments.summary.json

A more human-readable summary organized by flows:

- Total steps deployed
- Successful deployments count
- Failed deployments count
- Deployment timestamp
- Environment
- Version
- List of flows with their steps and deployment status

## Deployment Process

When you run `motia cloud deploy`, the CLI performs the following actions:

1. **Preparation**: Validates your project structure and configuration
2. **File Collection**: Gathers all workflow step zip files from your project
3. **File Upload**: Uploads each zip file to the Motia platform
4. **Configuration Upload**: Uploads your workflow configuration
5. **Deployment Initiation**: Starts the deployment process on the server
6. **Status Reporting**: Provides feedback on deployment progress and results

The CLI will display progress information during deployment and a summary when complete.

## Troubleshooting Deployments

If you encounter issues during deployment, try these steps:

1. Check the generated deployment files for specific error messages
2. Ensure your API key has the correct permissions
3. Verify your project structure follows Motia's requirements
4. Check that all required files are present and correctly formatted



-   [self-hosted](/docs/concepts/deployment/self-hosted): Documentation for self-hosted.
---
title: Self-Hosted Deployment
description: Learn how to deploy your Motia project to production using motia-docker
---

We provide a docker image that you can use to deploy your Motia project to production. You can use it as a base image and add your own customizations or use it as is.

<Callout type="warn">You will need to use the latest version of the motia package **0.5.2-beta.101 or higher**</Callout>

## Quick setup

<Steps>
<Step>
#### Setup your motia project

```bash
npx motia@latest docker setup
```

</Step>
<Step>
#### Run your motia project inside a container

```bash
npx motia@latest docker run
```

  </Step>
  <Step>
#### You are good to go, your project should be running on localhost under port 3000, for additional options and configuration run

```bash
npx motia@latest docker run --help
```

  </Step>
</Steps>

> Reference the [CLI](/docs/concepts/cli#docker) for more information on the docker commands.

## Using the docker image

You will need to implement your own Dockerfile where you will use the motia-docker image as a base image. Use the following template as a starting point for your Dockerfile:

```dockerfile
# NOTE: Some cloud providers will require you to specify the platform to match your target architecture
# i.e.: AWS Lightsail requires arm64, therefore you update your FROM statement to: FROM --platform=linux/arm64 motiadev/motia:latest
FROM motiadev/motia:latest

# Install Dependencies
COPY package*.json ./
RUN npm ci --only=production

# Move application files
COPY . .

# Enable the following lines if you are using python steps!!!
# Setup python steps dependencies
# RUN npx motia@latest install

# Expose outside access to the motia project
EXPOSE 3000

# Run your application
CMD ["npm", "run", "start"]
```

<Callout type="info">
  Depending on the cloud provider you will use to deploy your Motia project, you will need to adjust the exposed ports
  and the command to start your application.
</Callout>

## Create a .dockerignore file

Create a .dockerignore file in the root of your project to exclude files that are not needed in the docker image. You can use the following template as a starting point for your .dockerignore file:

```bash
# Git
.git
.gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
ENV/

# Node
node_modules/
npm-debug.log
yarn-debug.log
yarn-error.log

# IDE
.vscode/
.idea/
*.swp
*.swo

# Local development
.env

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db
```

## Build your image

```bash
docker build -t <your-image-name> .
```

## Run your Motia application

Once you've built your image, you can run it using the following command:

```bash
docker run -it --rm -p 3000:3000 <your-image-name>
```

## Motia Docker Resources

- [Docker Registry](https://hub.docker.com/r/motiadev/motia)
- [Github Repo](https://github.com/MotiaDev/motia/packages/docker)
- [Example Motia project with deployment boilerplate for AWS LightSail and Railway](https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-docker)


-   [environment-variables](/docs/concepts/environment-variables): Documentation for environment-variables.
---
title: Environment Variables
description: Store API keys and configuration safely using .env files in your Motia apps.
---

# Environment Variables

Environment variables let you store API keys, database URLs, and other configuration outside your code. This keeps sensitive information secure and makes it easy to use different settings for development and production.

## Quick Setup

### 1. Create a `.env` File

Create a `.env` file in your project root:

```bash title=".env"
# API Keys
OPENAI_API_KEY=sk-your-api-key-here
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook

# Database  
DATABASE_URL=postgresql://user:password@localhost:5432/myapp

# App Settings
NODE_ENV=development
PORT=3000
```

### 2. Add to `.gitignore`

Make sure you never commit your `.env` file:

```bash title=".gitignore"
.env
.env.local
```

### 3. Create Template for Your Team

```bash title=".env.example"
# Copy this to .env and add your actual values
OPENAI_API_KEY=your-api-key-here
DATABASE_URL=postgresql://user:password@localhost:5432/myapp
```

## Using Environment Variables in Steps

### TypeScript/JavaScript

```typescript title="my-step.step.ts"
export const config = {
  type: 'api',
  name: 'chat-with-ai',
  path: '/chat',
  method: 'POST'
}

export const handler = async (req, { logger }) => {
  // Use environment variables with process.env
  const apiKey = process.env.OPENAI_API_KEY
  const webhookUrl = process.env.DISCORD_WEBHOOK_URL
  
  if (!apiKey) {
    return { status: 400, body: { error: 'Missing API key' } }
  }
  
  logger.info('Using OpenAI API', { hasKey: !!apiKey })
  
  // Your logic here...
  return { status: 200, body: { message: 'Success!' } }
}
```

### Python

```python title="my-step.step.py"
import os

config = {
    'type': 'event', 
    'name': 'process-data',
    'subscribes': ['data.received']
}

async def handler(input_data, ctx):
    # Use environment variables with os.environ
    api_key = os.environ.get('OPENAI_API_KEY')
    database_url = os.environ.get('DATABASE_URL')
    
    if not api_key:
        raise ValueError('Missing OPENAI_API_KEY')
    
    ctx.logger.info('Processing with API key', {'has_key': bool(api_key)})
    
    # Your logic here...
    return {'status': 'processed'}
```

## Deployment

When you deploy your app, set environment variables through your hosting platform:

### Motia Cloud
```bash
motia env set OPENAI_API_KEY=sk-your-production-key
motia env set NODE_ENV=production
```

## Important Security Tips

<Callout type="warning">
**üîí Keep Your Keys Safe**

- Never commit `.env` files to git
- Use different API keys for development and production  
- Don't share API keys in code or messages
</Callout>

That's it! Environment variables are simple - just put them in `.env` and use `process.env.VARIABLE_NAME` in your code.


-   [flows-and-visualization](/docs/concepts/flows-and-visualization): Documentation for flows-and-visualization.
---
title: Flows & Visualization
description: Learn how to organize steps into flows and visualize multi-language workflows in the Motia Workbench with real-time debugging and tracing.
---

# Flows & Visualization

**Flows** are logical groupings of steps that work together to accomplish specific business goals. They provide structure, visualization, and observability for your multi-language workflows - making it easy to understand, debug, and maintain complex systems.

## Why Use Flows?

### üéØ **Organization & Clarity**
Group related steps together for better code organization and team understanding

### üëÅÔ∏è **Visual Workflow Management**  
See your entire workflow in the Motia Workbench - from TypeScript APIs to Python processors to JavaScript analytics

### üîç **Enhanced Observability**
- **Flow-based logging** - Filter logs by specific workflows
- **Distributed tracing** - Follow requests across all steps in a flow
- **Real-time monitoring** - Watch data flow through your system live

### üöÄ **Team Collaboration**
Share visual workflow diagrams with stakeholders, making technical processes accessible to non-technical team members

## Creating Multi-Language Flows

Flows are created by tagging your steps with flow names. Each step specifies which flows it belongs to using the `flows` property in its configuration.

### Real-World E-Commerce Flow Example

Here's how to build a complete user onboarding flow using multiple languages:

<Tabs items={["TypeScript API", "Python Processor", "JavaScript Notifier"]}>
<Tab value="TypeScript API">

```typescript title="01-user-registration.step.ts"
import { z } from 'zod'

export const config = {
  type: 'api',
  name: 'user-registration',
  path: '/users/register',
  method: 'POST',
  
  // Schema validation
  bodySchema: z.object({
    email: z.string().email(),
    name: z.string().min(2),
    password: z.string().min(8)
  }),
  
  emits: ['user.registered'],
  flows: ['user-onboarding'] // üéØ Flow association
}

export const handler = async (req, { emit, logger }) => {
  logger.info('New user registration', { email: req.body.email })
  
  // Create user in database
  const user = await createUser(req.body)
  
  // Trigger Python processing
  await emit({
    topic: 'user.registered',
    data: { user, timestamp: new Date() }
  })
  
  return { status: 201, body: { success: true, userId: user.id } }
}
```

</Tab>
<Tab value="Python Processor">

```python title="02-enrich-profile.step.py"
from pydantic import BaseModel

class UserRegistered(BaseModel):
    user: dict
    timestamp: str

config = {
    'type': 'event',
    'name': 'enrich-profile',
    'subscribes': ['user.registered'],
    'emits': ['profile.enriched'],
    'flows': ['user-onboarding'],  # üéØ Same flow name
    'input_schema': UserRegistered
}

async def handler(input_data, ctx):
    """Use Python for complex data enrichment with ML libraries"""
    
    user = input_data.user
    ctx.logger.info("Enriching user profile", {"user_id": user['id']})
    
    # Python-specific processing (geolocation, ML predictions, etc.)
    enriched_profile = {
        'user_id': user['id'],
        'location_data': await get_location_from_ip(user.get('ip')),
        'risk_score': calculate_fraud_risk(user),
        'recommended_categories': get_ml_recommendations(user),
        'enriched_at': ctx.utils.dates.now().isoformat()
    }
    
    # Pass to JavaScript step
    await ctx.emit({
        'topic': 'profile.enriched',
        'data': enriched_profile
    })
    
    return enriched_profile

async def get_location_from_ip(ip):
    # IP geolocation service
    return {"country": "US", "city": "San Francisco"}

def calculate_fraud_risk(user):
    # ML model inference
    return 0.1  # Low risk

def get_ml_recommendations(user):
    # Recommendation engine
    return ["electronics", "books", "sports"]
```

</Tab>
<Tab value="JavaScript Notifier">

```javascript title="03-send-welcome.step.js"
/**
 * @typedef {Object} EnrichedProfile
 * @property {string} user_id
 * @property {Object} location_data
 * @property {number} risk_score
 * @property {string[]} recommended_categories
 */

export const config = {
  type: 'event',
  name: 'send-welcome',
  subscribes: ['profile.enriched'],
  emits: ['welcome.sent'],
  flows: ['user-onboarding'] // üéØ Same flow completes the chain
}

/**
 * @param {EnrichedProfile} input
 */
export const handler = async (input, { emit, logger, state, traceId }) => {
  logger.info('Sending personalized welcome', { userId: input.user_id })
  
  // Get original user data from state
  const originalUser = await state.get(traceId, 'user-registration-data')
  
  // Send personalized notifications based on ML data
  const welcomeData = {
    userId: input.user_id,
    personalizedContent: {
      location: input.location_data.city,
      recommendations: input.recommended_categories,
      riskLevel: input.risk_score < 0.5 ? 'low' : 'high'
    }
  }
  
  // Send multi-channel welcome (email, SMS, push)
  await Promise.all([
    sendWelcomeEmail(originalUser.email, welcomeData),
    sendWelcomeSMS(originalUser.phone, welcomeData),
    sendPushNotification(input.user_id, welcomeData)
  ])
  
  await emit({
    topic: 'welcome.sent',
    data: { userId: input.user_id, channels: 3, sentAt: new Date() }
  })
  
  logger.info('User onboarding complete', { userId: input.user_id })
}
```

</Tab>
</Tabs>

### Flow Best Practices

<Callout type="default">
**üìã Flow Naming Guidelines**

- **Descriptive**: Use clear business process names (`user-onboarding`, `payment-processing`, `order-fulfillment`)
- **Kebab-case**: Use hyphens for readability (`data-pipeline` not `dataPipeline`)
- **Specific**: Keep flows focused on single business processes
- **Multi-flow**: Steps can belong to multiple flows: `flows: ['billing', 'analytics', 'compliance']`
</Callout>

## Visualizing Flows in Motia Workbench

The **Motia Workbench** is your command center for developing, debugging, and monitoring multi-language workflows in real-time.

### Getting Started with Workbench

<Steps>
<Step>
**Start Development Mode**

```bash
# In your Motia project directory
npx motia dev
```

This starts the Motia runtime and opens the Workbench at `http://localhost:3000`

</Step>
<Step>
**Explore Your Flows**

![Motia Workbench Interface](./../img/motia-build-your-app.gif)

- **Left Sidebar**: Browse all your flows and steps
- **Main Canvas**: Interactive visual workflow diagram  
- **Bottom Panel**: Real-time logs and traces
- **Right Panel**: Step configuration and details

</Step>
<Step>
**Interactive Flow Visualization**

Click on your flow name in the sidebar to see:
- **Visual nodes** for each step (colored by language)
- **Event connections** showing data flow between steps
- **Real-time status** indicators during execution

</Step>
<Step>
**Debug and Monitor**

- **Click nodes** to inspect step configurations
- **Watch traces** in the bottom panel as requests flow through
- **Filter logs** by flow, step, or trace ID
- **Move nodes** to organize your visual layout

</Step>
</Steps>

### Workbench Features for Multi-Language Workflows

#### üé® **Language-Coded Visualization**
Steps are visually distinguished by language:
- **Blue nodes** = TypeScript/JavaScript steps
- **Green nodes** = Python steps  
- **Custom colors** for other languages

#### ‚ö° **Real-Time Flow Execution**
Watch your data flow live across languages:
1. API request hits TypeScript step (blue highlight)
2. Data flows to Python step (green highlight)  
3. Results trigger JavaScript step (blue highlight)
4. Complete trace appears in logs panel

#### üîç **Multi-Language Debugging**
- **Unified logging** - All step logs in one place
- **Cross-language tracing** - Follow requests across runtimes
- **Error highlighting** - Instantly spot failing steps
- **State inspection** - View shared data between steps

#### üìä **Performance Monitoring**
- **Execution timing** - See how long each step takes
- **Bottleneck identification** - Spot slow steps in your flow
- **Resource usage** - Monitor memory and CPU per language runtime

### Advanced Workbench Usage

#### Flow Layout Management

The Workbench automatically saves your node positions in `motia-workbench.json`:

```json title="motia-workbench.json (Auto-managed)"
[
  {
    "id": "user-onboarding",
    "config": {
      "steps/01-user-registration.step.ts": {
        "x": -200, "y": 100,
        "sourceHandlePosition": "right"
      },
      "steps/02-enrich-profile.step.py": {
        "x": 100, "y": 100,
        "targetHandlePosition": "left"
      },
      "steps/03-send-welcome.step.js": {
        "x": 400, "y": 100,
        "targetHandlePosition": "left"
      }
    }
  }
]
```

#### Team Collaboration

- **Commit workbench configs** to version control
- **Shared layouts** - Team sees the same visual organization
- **Flow documentation** - Visual diagrams serve as living documentation

<Callout type="default">
**üöÄ Pro Tips for Effective Flow Visualization**

- **Group related flows** - Use consistent naming patterns
- **Organize canvas layout** - Arrange nodes logically (left-to-right for data flow)
- **Use descriptive step names** - Makes flows self-documenting
- **Color-code by domain** - Group similar business logic visually
- **Test flows interactively** - Use the Workbench to trigger and debug flows
</Callout>

## Real-Time Development Workflow

The Workbench supports hot-reload development across all languages:

1. **Edit TypeScript step** ‚Üí Instant reload in browser
2. **Modify Python handler** ‚Üí Automatic restart and reconnection  
3. **Update JavaScript logic** ‚Üí Live updates without losing state
4. **Change flow configuration** ‚Üí Visual diagram updates immediately

This enables a seamless multi-language development experience where you can:
- ‚úÖ **Write each component in the optimal language**
- ‚úÖ **See immediate results across the entire workflow**
- ‚úÖ **Debug issues with full context across languages**
- ‚úÖ **Monitor performance in real-time**

**‚û°Ô∏è [Learn More about Workbench Features](/docs/workbench/overview)**

---

**Ready to build your first REST API?** Check out **[API Endpoints](/docs/getting-started/build-your-first-app/creating-your-first-rest-api)** for a complete hands-on tutorial!


-   [index](/docs/concepts): Documentation for index.
---
title: Core Concepts
description: Understand the fundamental concepts behind Motia - the unified platform for modern backend systems.
---

# Core Concepts

**Motia unifies what used to require 5+ different frameworks:** APIs, background jobs, workflows, AI agents, real-time streams, and state management - all with built-in observability and multi-language support.

## The Unified Backend Vision

Traditional backend development is fragmented. You need one framework for APIs, another for background jobs, separate tools for queues, workflows, AI agents, and real-time features. Each tool has different configs, different deployment strategies, and different observability approaches.

**Motia changes this.** Everything becomes a **Step** - a single primitive that handles all backend patterns with unified state, events, and observability.

<Callout type="info">
**üåç The Multi-Language Advantage** 

Use **TypeScript** for APIs, **Python** for AI/ML, **JavaScript** for frontend logic - all in one unified system. Motia handles type safety, validation, and seamless communication between languages automatically.
</Callout>

## üèóÔ∏è **Core Concept 1:** Steps - The Universal Backend Primitive

**Steps are the building blocks of everything in Motia.** Like React components for the frontend, Steps are composable units that handle any backend pattern.

### The Three Step Types

#### üåê **API Steps** - HTTP Endpoints & REST APIs
Transform any function into a production-ready API endpoint with automatic validation, error handling, and observability.

```typescript title="user-api.step.ts"
import { Handlers } from 'motia'

// Create a REST API endpoint
export const config = {
  type: 'api' as const,
  path: '/users/:id',
  method: 'GET' as const,
  emits: ['user.fetched']
}

// Handler processes the request
export const handler: Handlers['GetUser'] = async (req, { logger, emit }) => {
  const userId = req.pathParams.id
  logger.info('Fetching user', { userId })
  
  // Emit event for next steps
  await emit({
    topic: 'user.fetched',
    data: { userId, status: 'active' }
  })
  
  return { status: 200, body: { message: 'User fetched' } }
}
```

#### ‚ö° **Event Steps** - Background Processing & Workflows  
React to events from other steps. Handle business logic, data processing, AI workflows, and complex orchestration.

```python title="process-user.step.py"
config = {
    'type': 'event',
    'subscribes': ['user.fetched'],
    'emits': ['user.processed']
}

# Process data with Python libraries (pandas, numpy, torch, etc.)
async def handler(user_data, context):
    # Your business logic here
    processed_user = analyze_user_behavior(user_data)
    
    await context.emit({
        'topic': 'user.processed',
        'data': processed_user
    })
```

#### ‚è∞ **Cron Steps** - Scheduled Jobs & Automation
Run tasks on schedules - from simple cleanups to complex data pipelines and AI agent workflows.

```typescript title="daily-report.step.ts"
import { Handlers } from 'motia'

export const config = {
  type: 'cron',
  schedule: '0 9 * * MON-FRI', // Weekdays at 9 AM
  emits: ['report.generated']
}

// Handler runs on schedule
export const handler: Handlers['DailyReport'] = async (input, { logger, emit }) => {
  logger.info('Generating daily report')
  
  const report = {
    date: new Date().toISOString(),
    metrics: { users: 1250, revenue: 15000 }
  }
  
  await emit({
    topic: 'report.generated',
    data: report
  })
}
```

## üîÑ **Core Concept 2:** Flows - Orchestrating Multi-System Workflows

**Flows organize your steps into logical workflows.** Steps connect through topics - when one step emits an event, other steps can subscribe and react. This creates powerful data pipelines that span multiple languages and services.

<Mermaid
  chart="
graph LR
    A[TypeScript API] --> B[Python AI Agent]
    B --> C[JavaScript Analytics]  
    C --> D[TypeScript Notification]
    
    style A fill:#3178c6,color:#fff
    style B fill:#3776ab,color:#fff  
    style C fill:#f7df1e,color:#000
    style D fill:#3178c6,color:#fff"
/>

### Real-World Flow Example

```typescript title="01-api.step.ts"
import { Handlers } from 'motia'

// API receives request ‚Üí triggers AI processing ‚Üí generates analytics ‚Üí sends notifications
export const config = {
  type: 'api',
  path: '/analyze-document',
  emits: ['document.received'],
  flows: ['document-intelligence']
}

export const handler: Handlers['AnalyzeDocument'] = async (req, { logger, emit }) => {
  logger.info('Document received for analysis')
  
  await emit({
    topic: 'document.received',
    data: { document: req.body, timestamp: new Date() }
  })
  
  return { status: 200, body: { message: 'Document queued for analysis' } }
}
```

```python title="02-ai-processor.step.py"
config = {
    'type': 'event',
    'subscribes': ['document.received'],
    'emits': ['document.analyzed'],
    'flows': ['document-intelligence']
}

# Use Python AI libraries (transformers, torch, etc.)
async def handler(document, context):
    analysis = await ai_model.analyze(document.content)
    await context.emit('document.analyzed', analysis)
```

```javascript title="03-analytics.step.js"
// JavaScript handles final processing and notifications
export const config = {
  type: 'event',
  subscribes: ['document.analyzed'],
  emits: ['analytics.complete'],
  flows: ['document-intelligence']
}

export const handler = async (analysis, { logger, emit }) => {
  logger.info('Processing analytics', { documentId: analysis.id })
  
  const metrics = {
    confidence: analysis.confidence,
    processingTime: Date.now() - analysis.startTime,
    categories: analysis.categories.length
  }
  
  await emit({
    topic: 'analytics.complete',
    data: { documentId: analysis.id, metrics }
  })
}
```

## üóÑÔ∏è **Core Concept 3:** State Management - Shared Data Across Languages

**Motia provides built-in state management** that works seamlessly across different programming languages. No need for external databases or complex state synchronization - Motia handles it automatically.

```typescript title="user-state.ts"
export class UserState {
  constructor(private readonly state: InternalStateManager) {}

  async getUser(id: string): Promise<User | null> {
    return this.state.get<User>('user', id)
  }

  async setUser(id: string, user: User) {
    await this.state.set('user', id, user)
  }
}

// In your step handler
export const handler: Handlers['UpdateUser'] = async (req, { state }) => {
  const userState = new UserState(state)
  
  // Update user state
  await userState.setUser('123', {
    status: 'processing',
    lastUpdated: new Date()
  })
}
```

```python title="ai-processor.py"
# Python step reads the same state  
def handler(input_data, context):
    # Access state through context
    user_data = context['state'].get('user', '123')
    print(f"User status: {user_data['status']}")
    
    # Update state from Python
    updated_user = {**user_data, 'aiScore': 0.95}
    context['state'].set('user', '123', updated_user)
```

<Callout type="success">
**üîÑ Automatic State Synchronization**

State changes are automatically synchronized across all steps, regardless of the programming language. TypeScript, Python, and JavaScript steps all share the same state seamlessly.
</Callout>

## üåä **Core Concept 4:** Real-Time Streams - Live Data to Clients

**Streams provide real-time data flow** from your backend to any client application. Define your data structure once, and Motia automatically streams updates to subscribed clients.

```typescript title="user-activity.stream.ts"
import { StreamConfig } from 'motia'
import { z } from 'zod'

const UserActivitySchema = z.object({
  userId: z.string(),
  activity: z.string(),
  timestamp: z.date()
})

export const config: StreamConfig = {
  name: 'userActivity',
  schema: UserActivitySchema,
  baseConfig: { storageType: 'default' }
}
```

```typescript title="update-activity.step.ts"
// Update stream from any step handler
export const handler: Handlers['UpdateActivity'] = async (req, { streams }) => {
  const activityId = crypto.randomUUID()
  
  // Set data in the stream
  await streams.userActivity.set('activity', activityId, {
    userId: '123',
    activity: 'document-processed',
    timestamp: new Date()
  })
}
```

```javascript title="client.js"
// Client automatically receives real-time updates
import { createStreamClient } from '@motia/stream-client'

const client = createStreamClient({ url: 'ws://localhost:8080' })
const stream = client.subscribe('userActivity')

stream.on('data', (update) => {
  console.log(`User ${update.userId}: ${update.activity}`)
})
```

## üìä **Core Concept 5:** Built-in Observability - See Everything

**Motia includes enterprise-grade observability** without any configuration. Every step, flow, and state change is automatically tracked and visualized.

### What You Get Out of the Box:

- **üîç Real-time Flow Visualization** - See your workflows executing live
- **üìä Request Tracing** - Follow data through multi-language steps
- **üìà Performance Metrics** - Automatic monitoring of all steps
- **üêõ Error Tracking** - Centralized error handling and alerting
- **üìù Structured Logging** - Consistent logs across all languages
- **‚ö° State Inspection** - Real-time view of shared state

![Motia Workbench](./../img/new-workbench.png)

## The Developer Experience

### Local Development
```bash
npx motia dev
```
- **Visual Workbench** at `http://localhost:3000`
- **Hot reload** for all languages
- **Real-time debugging** of flows and state
- **API testing** interface built-in

### Production Deployment
```bash
motia cloud deploy --api-key <api-key> --version-name <version> [options]
```
- **Atomic deployments** with one-click rollbacks
- **Multi-language builds** handled automatically
- **Infrastructure abstraction** - no cloud provider lock-in
- **Built-in scaling** for each step independently

## Why This Matters

**Before Motia:**
- API Framework (Express, FastAPI, etc.)
- Background Job System (Celery, Bull, etc.)  
- Workflow Engine (Temporal, Airflow, etc.)
- Message Queue (Redis, RabbitMQ, etc.)
- Real-time System (Socket.io, etc.)
- Observability Tools (DataDog, New Relic, etc.)
- State Management (Database + ORM, etc.)

**With Motia:**
- **One framework** handles everything
- **One config** file per step
- **One deployment** command
- **One observability** interface
- **One state system** across all languages

---

**Ready to see this in action?** Check out [API Endpoints](/docs/getting-started/build-your-first-app/creating-your-first-rest-api) to build a complete REST API in minutes.

-   [Logging & Debugging](/docs/concepts/logging-and-debugging): Documentation for Logging & Debugging.
---
title: Logging & Debugging
---

## Overview

Motia provides an out of the box logging and debugging system that works across different runtime environments. The system offers:

- Real-time log streaming in both terminal and Motia Workbench
- Multiple log levels with contextual information
- Local development debugging tools
- Integrated flow monitoring

## Log Levels and Usage

Motia supports four standard log levels:

| Log Type | Description                                                                        |
| -------- | ---------------------------------------------------------------------------------- |
| info     | General information about step execution, flow progress, and successful operations |
| error    | Critical issues, exceptions, failed operations, and system errors                  |
| debug    | Detailed debugging information and diagnostic data for troubleshooting             |
| warn     | Potential issues, edge cases, or situations requiring attention                    |

### Example Usage

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value='TS'>
    ```typescript
    export const handler: Handlers['StepName'] = async (input, { logger }) => {
      // Basic logging
      logger.info('Starting process')

      // Logging with context
      logger.info('Operation completed', {
        operationId: input.id,
        duration: 1500
      })

      // Error handling
      try {
        await riskyOperation()
      } catch (error) {
        logger.error('Operation failed', {
          error: error.message,
          stack: error.stack
        })
      }

      // Debug logging
      logger.debug('Operation details', {
        rawInput: input,
        timestamp: Date.now()
      })

      // Warning logging
      if (input.amount > 1000) {
        logger.warn('Large operation detected', {
          amount: input.amount,
          threshold: 1000
        })
      }
    }
    ```

  </Tab>
  <Tab value='JS'>
    ```javascript
    export const handler = async (input, { logger }) => {
      // Basic logging
      logger.info('Starting process')

      // Logging with context
      logger.info('Operation completed', {
        operationId: input.id,
        duration: 1500
      })

      // Error handling
      try {
        await riskyOperation()
      } catch (error) {
        logger.error('Operation failed', {
          error: error.message,
          stack: error.stack
        })
      }

      // Debug logging
      logger.debug('Operation details', {
        rawInput: input,
        timestamp: Date.now()
      })

      // Warning logging
      if (input.amount > 1000) {
        logger.warn('Large operation detected', {
          amount: input.amount,
          threshold: 1000
        })
      }
    }
    ```

  </Tab>
  <Tab value='Python'>
    ```python
    async def handler(input, ctx):
        # Basic logging
        ctx.logger.info('Starting process')

        # Logging with context
        ctx.logger.info('Operation completed', {
            'operation_id': input.get("id"),
            'duration': 1500
        })

        # Error handling
        try:
            await risky_operation()
        except Exception as error:
            ctx.logger.error('Operation failed', {
                'error': str(error),
                'stack': traceback.format_exc()
            })

        # Debug logging
        ctx.logger.debug('Operation details', {
            'raw_input': input.__dict__,
            'timestamp': time.time()
        })

        # Warning logging
        if input.amount > 1000:
            ctx.logger.warn('Large operation detected', {
                'amount': input.get("amount"),
                'threshold': 1000
            })
    ```
  </Tab>
</Tabs>

## Running and Debugging

<Steps>
  <Step>
    ### Start the Dev Server

    1. Navigate to your Motia project root folder
    2. Start the development server:

    <Tabs items={['npm', 'yarn', 'pnpm', 'bun']}>
      <Tab value="yarn">```yarn run dev ```</Tab>
      <Tab value="npm">```npm run dev ```</Tab>
      <Tab value="pnpm">```pnpm run dev ```</Tab>
      <Tab value="bun">```bun run dev ```</Tab>
    </Tabs>

    3. You can monitor logs in two ways:
      - Open [Motia Workbench](http://localhost:3000), select your flow, and expand the logs container
      - View logs directly in the terminal where you ran the dev command
  </Step>
  
  <Step>
    ### Trigger and Monitor Flows

    You can trigger flows using either the CLI or an [API step](/docs/concepts/steps/api):

    <Tabs items={['cli', 'api']}>
      <Tab value='cli'>
      ```bash
      npx motia emit --topic <topic> --message '{}'
      ```
      </Tab>
      <Tab value='api'>
      ```bash
      curl -X POST http://localhost:3000/<api-step-path> \
      -H "Content-Type: application/json" \
      -d '{}'
      ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step>
    ### Debug Using Logs

    Each log entry automatically includes:

    - `timestamp`: When the log was generated
    - `traceId`: Unique identifier for the flow execution
    - `flows`: Array of flow names this step belongs to
    - `file`: Source file generating the log
    - `level`: Log level
    - `msg`: Log message
  </Step>
  
  <Step>
    ### Stopping the development server
    Press **Ctrl + C** (or **Cmd + C** on macOS) in your terminal. That's it!
  </Step>
</Steps>

## Best Practices

### Structured Logging

```typescript
// Good - Structured and searchable
logger.info('Payment processed', {
  paymentId: '123',
  amount: 100,
  status: 'success',
})

// Avoid - Harder to parse and search
logger.info(`Payment ${paymentId} processed: amount=${amount}`)
```

### Performance Monitoring

```typescript
export const handler: Handlers['StepName'] = async (input, { logger }) => {
  const startTime = performance.now()

  // Process operation
  const result = await processOperation(input)

  logger.info('Operation completed', {
    duration: performance.now() - startTime,
    memoryUsage: process.memoryUsage().heapUsed,
  })
}
```

### Debugging Tips

1. Add detailed context to error logs:

```typescript
logger.error('Operation failed', {
  error: error.message,
  code: error.code,
  input: JSON.stringify(input),
  stack: error.stack,
})
```

2. Use debug logs for detailed troubleshooting:

```typescript
logger.debug('Operation details', {
  rawInput: input,
  timestamp: Date.now(),
  state: currentState,
})
```

<Callout>
  Remember to stop your development server with Ctrl + C (or Cmd + C on macOS) when you're done debugging.
</Callout>


-   [state-management](/docs/concepts/state-management): Documentation for state-management.
---
title: State Management
description: Learn how to manage state within your Motia.dev workflows for persistent data and cross-step communication.
---

State management is fundamental to building robust and dynamic workflows in Motia.dev. Our system is designed to be powerful yet simple, providing you with everything you need to maintain state across your flows and steps:

‚ú® **Zero Configuration (Default):** In-memory storage out of the box for quick setup. <br />
üîå **Flexible Storage Options:** Choose from Memory, File, and Redis adapters to suit your persistence needs. <br />
üßπ **Automatic State Cleanup:** Optional Time-To-Live (TTL) support for automatic state expiration (Redis). <br />
üîí **Built-in Isolation:** Each flow execution can use its own isolated state, ensuring data separation and security. <br />

## Core Concepts: State Manager Methods

The `state` object, accessible within your step handlers via the `ctx` context, provides the following methods for state management:

| Method    | Parameters                             | Return Type          | Description                                                                                                                                                                                   |
| --------- | -------------------------------------- | -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `get`     | `scope: string, key: string`           | `Promise<T \| null>` | Retrieves a value associated with the given `key` and `scope` from the state store. Returns `null` if the key is not found. The type `T` is inferred based on how you use the returned value. |
| `set`     | `scope: string, key: string, value: T` | `Promise<void>`      | Stores a `value` associated with the given `key` and `scope` in the state store. The type `T` can be any serializable JavaScript/JSON value.                                                  |
| `delete`  | `scope: string, key: string`           | `Promise<void>`      | Removes the key-value pair associated with the given `key` and `scope` from the state store.                                                                                                  |
| `clear`   | `scope: string`                        | `Promise<void>`      | Removes **all** state data associated with the provided `scope`. This is useful for cleaning up state for a specific scope.                                                                   |
| `cleanup` | _(None)_                               | `Promise<void>`      | Performs periodic maintenance tasks, such as removing expired state data (TTL cleanup). The actual implementation depends on the configured state adapter.                                    |

**Important:** State manager methods (`get`, `set`, `delete`, `clear`) **require a `scope` string as the first parameter.** While in most cases, you will use the `traceId` (automatically provided in `ctx.traceId`) as the scope to ensure flow-level isolation, **you can technically use any string value as the scope** to group and manage state data as needed. Using `traceId` is the recommended and most common practice for flow-isolated state.

### State Scope and Isolation

Each flow execution in Motia.dev is assigned a unique `traceId` (a UUID). Using this `traceId` as the **scope** for state management provides automatic isolation, ensuring: _(Revised to clarify `traceId` as scope)_

| Feature        | Description                                                                                                         |
| -------------- | ------------------------------------------------------------------------------------------------------------------- |
| **Isolation**  | Each flow execution operates within its own isolated state space when using `traceId` as the scope.                 |
| **Boundaries** | Clear separation of state data between different flow executions when scoped by `traceId`, preventing interference. |
| **Cleanup**    | State data scoped by `traceId` can be easily cleared using `state.clear(traceId)`.                                  |

### State Structure Example

State data is stored as key-value pairs, namespaced under a scope string. When using `traceId` as the scope, the internal structure might look like this:

```typescript
// Example state structure (internal representation) - using traceId as scope
{
  "motia:state:{traceId-123}": {  // State for flow execution with traceId 'traceId-123' (scope)
    "booking": {                 // Namespaced key 'booking'
      "customer": { ... },
      "venue": { ... }
    },
    "payment": {                 // Namespaced key 'payment'
      "status": "pending",
      "amount": 100
    }
  },
  "motia:state:{traceId-456}": {  // State for another flow execution with traceId 'traceId-456' (different scope)
    // ... different state data for this flow ...
  }
}
```

> **Info:** You can access the `state` manager within any step through the `ctx` (context) argument, which is automatically injected into your [step handler](/docs/concepts/steps/defining-steps#handler). While **`traceId` from `ctx.traceId` is the recommended scope for flow isolation**, remember that **you can use any string as the scope** parameter in `state` methods for more advanced state management scenarios.

## Using State in Steps

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab label="TypeScript">
    
  ```typescript
  import { Handlers } from 'motia'

  interface BookingData {
    customer: { name: string; email: string };
    venue: { id: string; name: string };
  }

  export const handler: Handlers['StepName'] = async (input, { state, traceId }) => { // Get traceId from context
    // Store state (using traceId as scope)
    await state.set<BookingData>(traceId, 'booking', {
      customer: input.customer,
      venue: input.venue,
    });

    // Retrieve state (using traceId as scope)
    const booking = await state.get<BookingData>(traceId, 'booking');

    // Delete specific state (using traceId as scope)
    await state.delete(traceId, 'booking');

    // Clear all state for this flow (using traceId as scope)
    await state.clear(traceId);
  }
  ```

  </Tab>

  <Tab label="JavaScript">
    
  ```javascript
  import { Handlers } from 'motia'

  export const handler: Handlers['StepName'] = async (input, { state, traceId }) => { // Get traceId from context
    // Store state (using traceId as scope)
    await state.set(traceId, 'booking', {
      customer: input.customer,
      venue: input.venue,
    });

    // Retrieve state (using traceId as scope)
    const booking = await state.get(traceId, 'booking');

    // Delete specific state (using traceId as scope)
    await state.delete(traceId, 'booking');

    // Clear all state for this flow (using traceId as scope)
    await state.clear(traceId);
  }
  ```

  </Tab>

  <Tab label="Python">
  
  ```python
  async def handler(input, ctx): # ctx is the context object
      trace_id = ctx.trace_id # Access traceId from context

      # Store state (using traceId as scope)
      await ctx.state.set(trace_id, 'booking', {
          'customer': input.get("customer"),
          'venue': input.get("venue")
      })

      # Retrieve state (using traceId as scope)
      booking = await ctx.state.get(trace_id, 'booking')

      # Delete specific state (using traceId as scope)
      await ctx.state.delete(trace_id, 'booking')

      # Clear all state (using traceId as scope)
      await ctx.state.clear(trace_id)
  ```
  </Tab>
</Tabs>

## Debugging

### Inspecting State

<Tabs items={['Memory', 'File', 'Redis']}>
  <Tab label="Memory">
  > State is only available during runtime in the Node.js process memory. You cannot inspect memory state directly outside of a running step execution. Use logging within your steps to output state values for debugging purposes.
  </Tab>
  <Tab label="File">
  
  To inspect state stored in the **File Adapter**, you can directly view the contents of the state file using the Motia CLI:

  ```bash
  # View state file contents
  motia state list
  ```

  This command will output the entire state file (motia.state.json) content in JSON format to your console, allowing you to examine the stored state data.

  </Tab>
  <Tab label="Redis">
  
  To inspect state stored in **Redis Adapter**, you can use the `redis-cli` command-line tool to interact with your Redis server:

  ```bash
  # List all state keys (under the motia:state prefix)
  redis-cli KEYS "motia:state:*"

  # Get specific state for a given traceId and key
  redis-cli GET "motia:state:{traceId}:booking"
  ```
  **Note:** Replace `{traceId}` in the `redis-cli GET` command with the actual `traceId` of the flow execution you are debugging. Replace `booking` with the specific `key` you want to inspect.

  </Tab>
</Tabs>

## Best Practices

### Namespacing

Use dot notation to organize related state data hierarchically:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab label="TypeScript">
    
  ```typescript
  // Good - Organized hierarchically (using traceId scope)
  await state.set(traceId, 'booking.customer', customerData)
  await state.set(traceId, 'booking.venue', venueData)
  await state.set(traceId, 'payment.status', 'pending')

  // Avoid - Flat structure (using traceId scope)
  await state.set(traceId, 'customer', customerData)
  await state.set(traceId, 'venue', venueData)
  await state.set(traceId, 'paymentStatus', 'pending')
  ```

  </Tab>

  <Tab label="JavaScript">
    
  ```javascript
  // Good - Organized hierarchically (using traceId scope)
  await state.set(traceId, 'booking.customer', customerData)
  await state.set(traceId, 'booking.venue', venueData)
  await state.set(traceId, 'payment.status', 'pending')

  // Avoid - Flat structure (using traceId scope)
  await state.set(traceId, 'customer', customerData)
  await state.set(traceId, 'venue', venueData)
  await state.set(traceId, 'paymentStatus', 'pending')
  ```

  </Tab>

  <Tab label="Python">
    
  ```python
  # Good - Organized hierarchically (using traceId scope)
  await ctx.state.set(trace_id, 'booking.customer', customer_data)
  await ctx.state.set(trace_id, 'booking.venue', venue_data)
  await ctx.state.set(trace_id, 'payment.status', 'pending')

  // Avoid - Flat structure (using traceId scope)
  await ctx.state.set(trace_id, 'customer', customer_data)
  await ctx.state.set(trace_id, 'venue', venue_data)
  await ctx.state.set(trace_id, 'payment_status', 'pending')
  ```

  </Tab>
</Tabs>

### Type Safety

Define types for your state data to ensure consistency:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab label="TypeScript">
    
  ```typescript
  interface CustomerData {
    name: string;
    email: string;
  }

  interface VenueData {
    id: string;
    capacity: number;
  }

  type BookingState = {
    customer: CustomerData;
    venue: VenueData;
    status: 'pending' | 'confirmed';
  }

  const booking = await state.get<BookingState>(traceId, 'booking')
  ```

  </Tab>

{' '}
  <Tab label="JavaScript">
  
  ```javascript 
  // Define types or interfaces as needed for documentation clarity (optional in JS) const booking = await
  state.get(traceId, 'booking') // No type casting in JS example 
  ```
  </Tab>

  <Tab label="Python">
    
  ```python
  from dataclasses import dataclass
  from typing import Literal

  @dataclass
  class CustomerData:
      name: str
      email: str

  @dataclass
  class VenueData:
      id: str
      capacity: int

  @dataclass
  class BookingState:
      customer: CustomerData
      venue: VenueData
      status: Literal['pending', 'confirmed']

  booking = await state.get(traceId, 'booking')
  ```

  </Tab>
</Tabs>

### Cleanup

Always clean up state when you're done with it:

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab label="TypeScript">
      
  ```typescript
  export const handler: Handlers['StepName'] = async (input, { state, traceId }) => {
    try {
      await processBooking(input)
      // Clean up specific keys
      await state.delete(traceId, 'booking.customer')
      // Or clean everything
      await state.clear(traceId)
    } catch (error) {
      // Handle errors
    }
  }
  ```
  </Tab>

  <Tab label="JavaScript">
    
  ```javascript
  export const handler = async (input, { state, traceId }) => {
    try {
      await processBooking(input)
      // Clean up specific keys
      await state.delete(traceId, 'booking.customer')
      // Or clean everything
      await state.clear(traceId)
    } catch (error) {
      // Handle errors
    }
  }
  ```
  </Tab>

  <Tab label="Python">
    
  ```python
  async def handler(input, ctx):
      trace_id = ctx.trace_id
      try:
          await process_booking(input)
          # Clean up specific keys
          await ctx.state.delete(trace_id, 'booking.customer')
          # Or clean everything
          await ctx.state.clear(trace_id)
      except Exception as error:
          # Handle errors
          pass
  ```
  </Tab>
</Tabs>

### Performance Considerations

| Consideration    | Description                                                          |
| ---------------- | -------------------------------------------------------------------- |
| Batch Operations | Group related state updates and use atomic operations when possible  |
| State Size       | Keep state data minimal and consider access patterns                 |
| TTL Management   | Set appropriate TTLs based on flow duration and error recovery needs |

### Custom State Adapters

```typescript title="Custom State Adapter Example"
import { StateAdapter } from 'motia'

class CustomStateAdapter extends StateAdapter {
  async get<T>(traceId: string, key: string): Promise<T | null> {
    // Implementation
    return null
  }

  async set<T>(traceId: string, key: string, value: T): Promise<void> {
    // Implementation
  }

  async delete(traceId: string, key: string): Promise<void> {
    // Implementation
  }

  async clear(traceId: string): Promise<void> {
    // Implementation
  }

  async cleanup(): Promise<void> {
    // Implementation
  }
}
```

### Storage Adapters

Motia.dev offers three built-in storage adapters:

- üìÅ **File (Default):** Persists state to a JSON file in your project (`.motia/motia.state.json`). No configuration needed for basic use.
- üíæ **Memory:** Stores state in-memory. Fastest option, but state is not persistent across server restarts. Useful for development and non-critical data.
- ‚ö° **Redis:** Leverages Redis for persistent and scalable state storage. Ideal for production environments and flows requiring high availability and data durability.

To configure a different state adapter, modify the `config.yml` file in your project root:

```
my-project/
‚îú‚îÄ‚îÄ config.yml
‚îî‚îÄ‚îÄ steps/
    ‚îú‚îÄ‚îÄ step-1.ts
    ‚îî‚îÄ‚îÄ step-2.ts
```

**File Adapter (Default)**

> Default, no configuration required, state is stored into .motia/motia.state.json in your project root

**Memory Adapter**

```yaml title="config.yml"
state:
  adapter: memory
```

> **Warning: Memory Adapter**
> State is stored in-memory and will be lost when the Motia.dev server restarts. Suitable for development and testing.

**Redis Adapter**

```yaml title="config.yml"
state:
  adapter: redis
  host: localhost # Redis server host (e.g., 'localhost' or IP address)
  port: 6379 # Redis server port (default: 6379)
  password: optional # Redis password (if required)
  ttl: 3600 # Optional: State Time-To-Live in seconds (e.g., 3600 seconds = 1 hour)
```

> **Info: Redis Adapter**
> Recommended for production environments. Requires a running Redis server. The `ttl` (Time-To-Live) option is available to automatically expire state data after a specified number of seconds, helping to manage Redis storage.

### Common Issues

| Issue             | Troubleshooting Steps                                                                                                                                                                            |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| State Not Found   | - Verify state adapter configuration\n- Check TTL expiration (Redis)\n- Ensure file permissions (File adapter)\n- **Ensure correct `traceId` is being used in `state.get(traceId, key)` calls.** |
| Persistence       | - Memory adapter: State is lost on process restart\n- File adapter: Check file write permissions\n- Redis: Verify connection and persistence settings                                            |
| Concurrent Access | - Memory/File: Limited concurrent flow support\n- Redis: Use atomic operations and implement retry logic                                                                                         |


-   [API Step](/docs/concepts/steps/api): Documentation for API Step.
---
title: API Step
---

An **API step** is exposed as an HTTP endpoint that acts as an entry point into your sequence of steps, or **flow**. It allows external systems or clients to trigger and interact with your flows through a REST API interface. Like any Motia Step, an API Step can be configured to emit events or wait for events to occur.

## Config

The following properties are specific to the API Step, in addition to the [common step config](/docs/concepts/steps/defining-steps#config).

<DescriptionTable
  type={{
    path: {
      description: 'The HTTP path for the API endpoint',
      type: 'string',
    },
    method: {
      description: 'The HTTP method for the API endpoint (GET, POST, PUT, DELETE, etc.)',
      type: 'string',
    },
    bodySchema: {
      description:
        'Schema for validating the request body. For TypeScript/JavaScript steps, it uses zod schemas. For Python steps, it uses Pydantic models.',
      type: 'object',
    },
    responseSchema: {
      description:
        'Mostly used for documentation, the expected output of an API endpoint. For TypeScript/JavaScript steps, it uses zod schemas. For Python steps, it uses Pydantic models or Dict Json Schema.',
      type: 'object',
    },
    queryParams: {
      description: 'Mostly for documentation, the expected query params',
      type: 'array',
    },
    middleware: {
      description: 'Optional middleware functions to run before the handler',
      type: 'array',
    },
  }}
/>

## Defining an API Step

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'GetMessage',
      description: 'Retrieves a generated message from OpenAI based on the Trace ID returned by the POST /openai endpoint',
      path: '/openai/:traceId',
      method: 'GET',
      emits: ['call-openai'],
      flows: ['openai'],
      responseSchema: {
        // When response code is 200
        200: z.object({ message: z.string({ description: 'The message from OpenAI' }) }),
        // When response code is 400
        400: z.object({ message: z.string({ description: 'The error message' }) })
      },
      queryParams: [
        {
          name: 'includeProps',
          description: 'Whether to include the properties of the message',
        },
      ],
    }

    export const handler: Handlers['GetMessage'] = async (req, { logger }) => {
      logger.info('[Call OpenAI] Received callOpenAi event', req)

      return {
        status: 200,
        body: { message: 'OpenAI response sent' },
      }
    }
    ```

  </Tab>
  <Tab value="JavaScript">
    ```typescript
    const { z } = require('zod')

    export const config = {
      type: 'api',
      name: 'Get Message by Trace ID',
      description: 'Retrieves a generated message from OpenAI based on the Trace ID returned by the POST /openai endpoint',
      path: '/openai/:traceId',
      method: 'GET',
      emits: ['call-openai'],
      flows: ['openai'],
      responseSchema: {
        // When response code is 200
        200: z.object({ message: z.string({ description: 'The message from OpenAI' }) }),
        // When response code is 400
        400: z.object({ message: z.string({ description: 'The error message' }) })
      },
      queryParams: [
        {
          name: 'includeProps',
          description: 'Whether to include the properties of the message',
        },
      ],
    }

    export const handler = async (req, { logger }) => {
      logger.info('[Call OpenAI] Received callOpenAi event', req)

      return {
        status: 200,
        body: { message: 'OpenAI response sent' },
      }
    }
    ```

  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel
    
    # Define a Pydantic model for request body validation
    class RequestBody(BaseModel):
        message: str

    config = {
      "type": "api",
      "name": "Get Message by Trace ID",
      "description": "Retrieves a generated message from OpenAI based on the Trace ID returned by the POST /openai endpoint",
      "path": "/openai/:traceId",
      "method": "GET",
      "emits": ["call-openai"],
      "flows": ["openai"],
      "responseSchema": {
        "200": RequestBody.model_json_schema()
      },
      "queryParams": [
        {
          "name": "includeProps",
          "description": "Whether to include the properties of the message",
        },
      ],
    }

    async def handler(req, context):
      context.logger.info("[Call OpenAI] Received callOpenAi event", {"body": req.get("body")})

      return {
        "status": 200,
        "body": { "message": "OpenAI response sent" },
      }
    ```

  </Tab>
</Tabs>

This should create an endpoint that can be viewed and requested from Workbench UI.

![Endpoint Visualization in Workbench](../../img/endpoints.png)

The following examples showcase how to configure an **API Step**

## Using Middleware

API Steps support middleware functions that can be applied to requests before they reach your handler. Middleware functions are completely framework-agnostic and can perform tasks such as:

- Authentication and authorization
- Request logging
- Rate limiting
- CORS handling
- Request validation
- Response transformation

### Middleware Function Signature

```typescript
type ApiMiddleware = (req: ApiRequest, ctx: FlowContext, next: () => Promise<ApiResponse>) => Promise<ApiResponse>
```

Middleware functions receive:

- `req`: The API request object with body, headers, pathParams, and queryParams
- `ctx`: The flow context with logger, state, emit, and traceId
- `next`: A function to call the next middleware or handler in the chain
  - Call `next()` to continue to the next middleware or handler
  - The return value of `next()` is the response from the next middleware or handler
  - You can modify this response before returning it

### Example Middleware Usage

```typescript
import { ApiMiddleware } from 'motia'

// Logging middleware
const loggingMiddleware: ApiMiddleware = async (req, ctx, next) => {
  ctx.logger.info('Request received', { path: req.pathParams })
  const start = Date.now()

  // Call the next middleware and get its response
  const response = await next()

  const duration = Date.now() - start
  ctx.logger.info('Request completed', { duration, status: response.status })

  return response
}

// Authentication middleware
const authMiddleware: ApiMiddleware = async (req, ctx, next) => {
  const authHeader = req.headers.authorization

  if (!authHeader) {
    // Return early without calling next()
    return {
      status: 401,
      body: { error: 'Unauthorized' },
    }
  }

  // Continue to the next middleware
  return next()
}

export const config = {
  type: 'api',
  name: 'protected-endpoint',
  path: '/api/protected',
  method: 'POST',
  emits: ['USER_ACTION'],
  middleware: [loggingMiddleware, authMiddleware],
}

export const handler = async (req, ctx) => {
  // This handler will only be called if all middleware pass
  return {
    status: 200,
    body: { message: 'Protected data accessed successfully' },
  }
}
```

### Creating Custom Middleware

You can create your own middleware functions:

```typescript
import { ApiMiddleware } from 'motia'

// Request modification middleware
const requestModifierMiddleware: ApiMiddleware = async (req, ctx, next) => {
  // Modify the request before passing it to the next middleware
  req.headers['x-modified-by'] = 'middleware'
  req.body.timestamp = Date.now()

  // Call the next middleware in the chain
  return next()
}

// Response modification middleware
const responseModifierMiddleware: ApiMiddleware = async (req, ctx, next) => {
  // Call the next middleware in the chain
  const response = await next()

  // Modify the response before returning it
  response.headers = {
    ...response.headers,
    'x-powered-by': 'Motia',
  }

  return response
}

// Error handling middleware
const errorHandlingMiddleware: ApiMiddleware = async (req, ctx, next) => {
  try {
    // Call the next middleware in the chain
    return await next()
  } catch (error) {
    ctx.logger.error('Error in handler', { error })
    return {
      status: 500,
      body: { error: 'Internal server error' },
    }
  }
}

// Rate limiter middleware with state
const rateLimiterMiddleware: ApiMiddleware = (() => {
  // Closure to maintain state between requests
  const requests: Record<string, number[]> = {}
  const limit = 100
  const windowMs = 60000 // 1 minute

  return async (req, ctx, next) => {
    const ip = req.headers['x-forwarded-for'] || 'unknown-ip'
    const ipStr = Array.isArray(ip) ? ip[0] : ip

    const now = Date.now()
    if (!requests[ipStr]) {
      requests[ipStr] = []
    }

    // Remove old requests outside the time window
    requests[ipStr] = requests[ipStr].filter((time) => now - time < windowMs)

    if (requests[ipStr].length >= limit) {
      return {
        status: 429,
        body: { error: 'Too many requests, please try again later' },
      }
    }

    // Add current request
    requests[ipStr].push(now)

    return next()
  }
})()
```

<Tabs items={['TypeScript', 'JavaScript', 'Python']}>
  <Tab value="TypeScript">
    ```typescript
      import { ApiRouteConfig, Handlers } from 'motia'
      import { z } from 'zod'

      export const config: ApiRouteConfig = {
        type: 'api',
        name: 'TestStateApiTrigger',
        description: 'test state',
        path: '/test-state',
        method: 'POST',
        emits: ['test-state'],
        bodySchema: z.object({}),
        flows: ['test-state'],
      }

      export const handler: Handlers['TestStateApiTrigger'] = async (req, { logger, emit }) => {
        logger.info('[Test State] Received request', req)

        await emit({
          topic: 'test-state',
          data: req.body
        })

        return {
          status: 200,
          body: { message: 'Success' },
        }
      }
    ```

  </Tab>
  <Tab value="JavaScript">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'Test state api trigger',
      description: 'test state',
      path: '/test-state',
      method: 'POST',
      emits: ['test-state'],
      bodySchema: z.object({}),
      flows: ['test-state'],
    }

    exports.handler = async (req, { logger, emit }) => {
      logger.info('[Test State] Received request', req)

      await emit({
        topic: 'test-state',
        data: req.body
      })

      return {
        status: 200,
        body: { message: 'Success' },
      }
    }
    ```

  </Tab>

  <Tab value="Python">
    ```python
    from typing import Any, Dict, Callable
    from motia import ApiMiddleware
    from datetime import datetime
    import time

    from pydantic import BaseModel

    # Define a Pydantic model for request body validation
    class RequestBody(BaseModel):
        message: str

    # Request modification middleware
    async def request_modifier_middleware(data: Dict[str, Any], ctx: Any, next_fn: Callable):
        # Modify the request before passing it to the next middleware
        data['headers']['x-modified-by'] = 'middleware'
        data['body']['timestamp'] = int(time.time() * 1000)

        # Call the next middleware in the chain
        return await next_fn()

    # Response modification middleware
    async def response_modifier_middleware(data: Dict[str, Any], ctx: Any, next_fn: Callable):
        # Call the next middleware in the chain
        response = await next_fn()

        # Modify the response before returning it
        response['headers'] = {
            **response.get('headers', {}),
            'x-powered-by': 'Motia'
        }

        return response

    # Error handling middleware
    async def error_handling_middleware(data: Dict[str, Any], ctx: Any, next_fn: Callable):
        try:
            # Call the next middleware in the chain
            return await next_fn()
        except Exception as error:
            ctx.logger.error('Error in handler', {'error': str(error)})
            return {
                'status': 500,
                'body': {'error': 'Internal server error'}
            }

    # Rate limiter middleware with state using a closure
    def create_rate_limiter_middleware():
        # Closure to maintain state between requests
        requests: Dict[str, list] = {}
        limit = 100
        window_ms = 60000  # 1 minute

        async def rate_limiter_middleware(data: Dict[str, Any], ctx: Any, next_fn: Callable):
            ip = data['headers'].get('x-forwarded-for', ['unknown-ip'])
            ip_str = ip[0] if isinstance(ip, list) else ip

            now = int(time.time() * 1000)
            if ip_str not in requests:
                requests[ip_str] = []

            # Remove old requests outside the time window
            requests[ip_str] = [t for t in requests[ip_str] if now - t < window_ms]

            if len(requests[ip_str]) >= limit:
                return {
                    'status': 429,
                    'body': {'error': 'Too many requests, please try again later'}
                }

            # Add current request
            requests[ip_str].append(now)

            return await next_fn()

        return rate_limiter_middleware

    config = {
        'type': 'api',
        'name': 'Test state api trigger',
        'description': 'test state',
        'path': '/test-state',
        'method': 'POST',
        'emits': ['test-state'],
        'flows': ['test-state'],
        'bodySchema': RequestBody.model_json_schema(), # We use jsonschema to validate
        'middleware': [
            request_modifier_middleware,
            response_modifier_middleware,
            error_handling_middleware,
            create_rate_limiter_middleware()
        ]
    }

    async def handler(req, context):
        context.logger.info('[Test State] Received request', {'body': req.get("body")})

        await context.emit({
            'topic': 'test-state',
            'data': req.body
        })

        return {
            'status': 200,
            'body': {'message': 'Success'}
        }
    ```

  </Tab>
</Tabs>


-   [Cron Step](/docs/concepts/steps/cron): Documentation for Cron Step.
---
title: Cron Step
---

The **Cron Step** allows you to schedule your steps to run at specified intervals. It is a powerful tool for automating your business logic.

## Config

The following properties are specific to the Cron Step, in addition to the [common step config](/docs/concepts/steps/defining-steps#config).

<DescriptionTable
  type={{
    cron: {
      description: 'The cron schedule expression for your step',
      type: 'string',
    },
  }}
/>

The following examples showcase how to configure an **CRON Step**

<Tabs  items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { CronConfig, Handlers } from 'motia'

    export const config: CronConfig = {
      type: 'cron' as const,
      name: 'PeriodicJob',
      description: 'Runs every minute and emits a timestamp',
      cron: '0 * * * *', // run every hour at minute 0
      emits: ['cron-ticked'],
      flows: ['cron-example'],
    }

    export const handler: Handlers['PeriodicJob'] = async ({ emit }) => {
      await emit({
        topic: 'cron-ticked',
        data: { message: 'Cron job executed' },
      })
    }
    ```

  </Tab>
  <Tab value="JS">
    ```javascript
    const config = {
      type: 'cron',
      name: 'PeriodicJob',
      description: 'Runs every minute and emits a timestamp',
      cron: '0 * * * *', // run every hour at minute 0
      emits: ['cron-ticked'],
      flows: ['cron-example'],
    };

    const handler = async ({ emit }) => {
      await emit({
        topic: 'cron-ticked',
        data: { message: 'Cron job executed' },
      })
    }

    ```

  </Tab>
  <Tab value="Python">
    ```python
    config = {
        "type": "cron",
        "name": "PeriodicJob",
        "description": "Runs every minute and emits a timestamp",
        "cron": "0 * * * *",
        "emits": ["cron-ticked"],
        "flows": ["cron-example"]
    }
  
    async def handler(context):
        await context.emit({
            "topic": "cron-ticked",
            "data": { "message": "Cron job executed" },
        })

    ```
  </Tab>
</Tabs>


-   [defining-steps](/docs/concepts/steps/defining-steps): Documentation for defining-steps.
---
title: Defining Steps
description: Learn how to create powerful, type-safe steps in TypeScript, Python, and JavaScript with automatic validation and observability.
---

# Defining Steps

Steps are the core building blocks of Motia - isolated, composable functions that handle specific pieces of business logic. Each step is **automatically discovered**, **type-safe**, and **observable** across multiple programming languages.

## The Motia Step Pattern

Every step follows a simple, consistent pattern:

1. **üìÅ File Naming**: `*.step.*` or `*_step.*` (e.g., `user-api.step.ts`, `process-data.step.py`, `data_processor_step.py`)
2. **‚öôÔ∏è Configuration**: Export a `config` object defining step behavior
3. **üîß Handler**: Export a `handler` function containing business logic
4. **ü§ñ Auto-Discovery**: Motia automatically finds and registers your steps

<Callout type="info">
**üåç Multi-Language Support**

Write each step in the best language for the job - **TypeScript** for APIs, **Python** for data processing, **JavaScript** for quick scripts. Motia handles type safety and communication automatically.
</Callout>

## Step Capabilities

### **Event-Driven Architecture**
- **Subscribe** to events from other steps
- **Emit** events to trigger subsequent steps
- **Chain** steps together into powerful workflows

### **Type Safety Across Languages**
- **Auto-generated** TypeScript definitions
- **Schema validation** with Zod, Pydantic, JSDoc
- **Runtime validation** for data consistency

### **Built-in Observability**
- **Distributed tracing** across all steps
- **Centralized logging** with step context
- **Visual debugging** in Motia Workbench

## Step Configuration

Each step exports a `config` object that tells Motia how to handle the step. The configuration varies by step type but shares common properties:

### Universal Config Properties

| Property | Type | Description | Required |
|----------|------|-------------|----------|
| `type` | `'api' \| 'event' \| 'cron' \| 'noop'` | The step type | ‚úÖ |
| `name` | `string` | Unique identifier for the step | ‚úÖ |
| `description` | `string` | Documentation for the step | - |
| `subscribes` | `string[]` | Topics this step listens to | - |
| `emits` | `string[]` | Topics this step can emit | - |
| `flows` | `string[]` | Flow identifiers this step belongs to | - |

### Type-Specific Properties

Each step type has additional properties:

- **[API Steps](/docs/concepts/steps/api)**: `path`, `method`, `bodySchema`, `responseSchema`
- **[Event Steps](/docs/concepts/steps/event)**: Event-specific configuration
- **[Cron Steps](/docs/concepts/steps/cron)**: `schedule`, cron expressions

## Configuration Examples

<Tabs items={["TypeScript API", "Python Event", "JavaScript Cron"]}>
<Tab value="TypeScript API">

```typescript title="user-api.step.ts"
import { z } from 'zod'

export const config = {
  type: 'api',
  name: 'user-api',
  path: '/users/:id',
  method: 'GET',
  description: 'Fetch user by ID',
  
  // Schema validation
  bodySchema: z.object({
    userId: z.string().uuid()
  }),
  
  responseSchema: {
    200: z.object({
      user: z.object({
        id: z.string(),
        name: z.string(),
        email: z.string().email()
      })
    })
  },
  
  emits: ['user.fetched'],
  flows: ['user-management']
} as const
```

</Tab>
<Tab value="Python Event">

```python title="process-data.step.py"
from pydantic import BaseModel

class UserData(BaseModel):
    id: str
    name: str
    email: str

config = {
    'type': 'event',
    'name': 'process-data',
    'description': 'Process user data with Python',
    
    'subscribes': ['user.fetched'],
    'emits': ['data.processed'],
    'flows': ['user-management'],
    
    # Pydantic validation
    'input_schema': UserData
}
```

</Tab>
<Tab value="JavaScript Cron">

```javascript title="daily-cleanup.step.js"
export const config = {
  type: 'cron',
  name: 'daily-cleanup',
  description: 'Daily cleanup task',
  
  schedule: '0 2 * * *', // Daily at 2 AM
  
  emits: ['cleanup.completed'],
  flows: ['maintenance']
}
```

</Tab>
</Tabs>

## Step Handlers

The `handler` function contains your step's business logic. Motia automatically calls the handler with validated input data and a context object containing powerful utilities.

### Handler Signature

Every handler receives two parameters:

1. **Input Data** - Validated data from the triggering event (API request, subscription, etc.)
2. **Context Object** - Tools for interacting with the Motia runtime

### Context Object Features

| Tool | Description | Usage |
|------|-------------|-------|
| `emit` | Send events to other steps | `await emit({ topic, data })` |
| `logger` | Centralized logging with trace context | `logger.info('Processing user', { userId })` |
| `state` | Persistent data storage across steps | `await state.set(traceId, key, value)` |
| `traceId` | Unique identifier for request tracing | Flow isolation and debugging |
| `utils` | Helper utilities (dates, crypto, etc.) | Various utility functions |

## Handler Examples with Type Safety

<Tabs items={["TypeScript Handler", "Python Handler", "JavaScript Handler"]}>
<Tab value="TypeScript Handler">

```typescript title="user-api.step.ts"
import { Handlers } from 'motia'
import { z } from 'zod'

// Config with schema validation (from previous example)
export const config = { /* ... */ }

// üéâ Handler gets full type safety from config!
export const handler: Handlers['user-api'] = async (req, { emit, logger, state, traceId }) => {
  logger.info('Processing user request', { userId: req.params.id })
  
  // req.body is automatically typed from bodySchema
  const { userId } = req.body
  
  // Simulate user fetch
  const user = await getUserById(userId)
  
  // Store in state for other steps
  await state.set(traceId, 'current-user', user)
  
  // Emit event to trigger other steps
  await emit({
    topic: 'user.fetched', // ‚úÖ Type-checked against config.emits
    data: { user, timestamp: new Date() }
  })
  
  // Return response matching responseSchema
  return {
    status: 200,
    body: { user } // ‚úÖ Validated against responseSchema
  }
}

async function getUserById(id: string) {
  // Database query or API call
  return { id, name: 'John Doe', email: 'john@example.com' }
}
```

</Tab>
<Tab value="Python Handler">

```python title="process-data.step.py"
from pydantic import BaseModel
import asyncio

# Config with Pydantic validation (from previous example)
config = { # ... }

async def handler(input_data, ctx):
    """
    üéâ Input is fully typed and validated via Pydantic!
    """
    ctx.logger.info("Processing user data", {
        "user_id": input_data.user['id'],
        "trace_id": ctx.trace_id
    })
    
    # Access validated data
    user = input_data.user
    
    # Python-specific processing (ML, data science, etc.)
    processed_data = {
        'user_id': user['id'],
        'processed_name': user['name'].upper(),
        'email_domain': user['email'].split('@')[1],
        'processed_at': ctx.utils.dates.now().isoformat()
    }
    
    # Store in shared state
    await ctx.state.set(ctx.trace_id, 'processed-user', processed_data)
    
    # Emit to next step
    await ctx.emit({
        'topic': 'data.processed',  # ‚úÖ Validated against config
        'data': processed_data
    })
    
    ctx.logger.info("Data processing complete", {
        "processed_user_id": processed_data['user_id']
    })
    
    return processed_data
```

</Tab>
<Tab value="JavaScript Handler">

```javascript title="send-notifications.step.js"
/**
 * @typedef {Object} ProcessedUser
 * @property {string} user_id
 * @property {string} processed_name
 * @property {string} email_domain
 * @property {string} processed_at
 */

// Config (from previous example)
export const config = { /* ... */ }

/**
 * üéâ Handler with JSDoc types for IntelliSense
 * @param {ProcessedUser} input - Processed user data
 * @param {import('motia').FlowContext} ctx - Motia context
 */
export const handler = async (input, { emit, logger, state, traceId }) => {
  logger.info('Sending notifications', { userId: input.user_id })
  
  // Get original user data from state
  const originalUser = await state.get(traceId, 'current-user')
  
  // Send notifications (email, SMS, push, etc.)
  const notifications = await Promise.all([
    sendEmail(originalUser.email, 'Welcome!'),
    sendPushNotification(input.user_id, 'Account processed'),
    // Add more notification channels
  ])
  
  const notificationSummary = {
    userId: input.user_id,
    sentAt: new Date().toISOString(),
    channels: notifications.map(n => n.channel),
    count: notifications.length
  }
  
  // Final emit
  await emit({
    topic: 'notifications.sent', // ‚úÖ Validated against config
    data: notificationSummary
  })
  
  logger.info('All notifications sent', notificationSummary)
  
  // Clean up state
  await state.clear(traceId)
  
  return notificationSummary
}

async function sendEmail(email, subject) {
  // Email service integration
  return { channel: 'email', success: true }
}

async function sendPushNotification(userId, message) {
  // Push notification service
  return { channel: 'push', success: true }
}
```

</Tab>
</Tabs>

## Type Safety Benefits

### Automatic Type Generation

Motia automatically generates TypeScript definitions based on your step configurations:

```typescript title="types.d.ts (Auto-generated)"
declare module 'motia' {
  interface Handlers {
    'user-api': ApiRouteHandler<
      { userId: string }, // From bodySchema
      ApiResponse<200, { user: User }> // From responseSchema
    >
    'process-data': EventHandler<
      { user: User }, // From subscribes topic
      { topic: 'data.processed'; data: ProcessedUser } // From emits
    >
  }
}
```

### Cross-Language Validation

Even in multi-language workflows, Motia ensures data consistency:

1. **TypeScript API** validates input with Zod schemas
2. **Python step** receives validated data via Pydantic models
3. **JavaScript step** gets type hints via JSDoc annotations

<Callout type="default">
**üöÄ Ready to Build?**

Check out **[API Endpoints](/docs/getting-started/build-your-first-app/creating-your-first-rest-api)** to see a complete REST API tutorial in action, or explore specific step types:

- **[API Steps](/docs/concepts/steps/api)** - HTTP endpoints with validation
- **[Event Steps](/docs/concepts/steps/event)** - Async event processing
- **[Cron Steps](/docs/concepts/steps/cron)** - Scheduled tasks
</Callout>


-   [Event Step](/docs/concepts/steps/event): Documentation for Event Step.
---
title: Event Step
---

The **Event Step** lets you define custom logic in response to subscribed events and at the same time trigger other steps by emitting new events. It enables communication between different parts of your flow.

## Config

The following properties are specific to the Event Step, in addition to the [common step config](/docs/concepts/steps/defining-steps#config).

<DescriptionTable
  type={{
    input: {
      description:
        'This is used for input validation. For TypeScript/JavaScript steps, it uses zod schemas. For Python steps, it uses Pydantic models. This validates the input before executing the step handler.',
      type: 'string[]',
    },
  }}
/>

The following examples showcase how to configure an **Event Step**

<Tabs  items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'stepA',
      description: 'Hello from Step A',
      subscribes: ['pms.start'],
      emits: ['pms.stepA.done'],
      input: z.object({ message: z.string() }),
      flows: ['parallel-merge'],
    }

    export const handler: Handlers['stepA'] = async (input, { emit, logger }) => {
      logger.info('Processing message:', input.message)

      await emit({
        topic: 'pms.stepA.done',
        data: {
          result: `Processed: ${input.message}`
        }
      })
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const z = require('zod');

    const config = {
      type: 'event',
      name: 'stepA',
      description: 'Hello from Step A',
      subscribes: ['pms.start'],
      emits: ['pms.stepA.done'],
      input: z.object({ message: z.string() });,
      flows: ['parallel-merge'],
    };

    const handler = async (input, { emit, logger }) => {
      logger.info('Processing message:', input.message)

      await emit({
        topic: 'pms.stepA.done',
        data: {
          result: `Processed: ${input.message}`
        }
      })
    };

    module.exports = { config, handler };
    ```
  </Tab>
  <Tab value="Python">
    ```python
    config = {
      "type": "event",
      "name": "Call OpenAI",
      "subscribes": ["call-openai"], 
      "emits": ["openai-response"],
      "input": {
        "type": "object",
        "properties": { "type": "string" },
      },
      "flows": ["openai"]
    }

    async def handler(input, context):
      context.logger.info("Processing input:", { "input": input })

      await context.emit({
        "topic": "openai-response",
        "data": {
          "result": f"Processed: {input.get("message", "")}"
        }
      })
    ```
  </Tab>
</Tabs>

## Example


-   [streams](/docs/concepts/streams): Documentation for streams.
---
title: Streams 
description: Motia Streams are a way to quickly push updates from your asynchronous workflows to the client without having to implement any sort of polling processes.
---

## How it works

You first need to define a stream in your project

### Defining a stream

To be able to use Motia Sockets, you need to define a stream

Create a file called `open-ai.stream.ts` under `steps/` folder

```typescript
import { StreamConfig } from 'motia'
import { z } from 'zod'

export const config: StreamConfig = {
  /**
   * This will be converted in the property on the FlowContext:
   * 
   * context.streams.openai
   */
  name: 'openai',
  /**
   * Schema is important to define the type of the stream, the API
   * generated to interact with this stream will have the structure defined here
   */  
  schema: z.object({ message: z.string() }),

  /**
   * Base config is used to configure the stream
   */
  baseConfig: {
    /**
     * There are two storage types: default and custom
     * Default will use the default storage to store the data.
     * 
     * Custom will use a custom storage, you need to implement 
     * the StateStream class.
     */
    storageType: 'default',
  },
}
```

Once a stream is created, it should be immediately available in FlowContext (make sure to have motia running on the project)

Then you can simply create records using the streams API in your step

```typescript
import { ApiRouteConfig, Handlers } from 'motia'
import { z } from 'zod'

export const config: ApiRouteConfig = {
  type: 'api',
  name: 'OpenAiApi',
  description: 'Call OpenAI',
  path: '/open-ai',
  method: 'POST',
  emits: ['openai-prompt'],
  flows: ['open-ai'],
  bodySchema: z.object({ message: z.string({ description: 'The message to send to OpenAI' }) }),
  responseSchema: {
    200: z.object({ message: z.string({ description: 'The message from OpenAI' }) }) 
  },
}

export const handler: Handlers['OpenAiApi'] = async (req, { traceId, logger, emit, streams }) => {
  logger.info('[Call OpenAI] Received callOpenAi event', { message: req.body.message })

  /**
   * This creates a record with empty message string to be populated in the next step
   */
  const result = await streams.openai.set(traceId, 'message', { message: '' })

  await emit({
    topic: 'openai-prompt',
    data: { message: req.body.message },
  })

  return { status: 200, body: result }
}
```

The previous step just prepares a message to be created by Open AI via OpenAI SDK stream, which will be populated in the next step

```typescript
import { EventConfig, Handlers } from 'motia'
import { OpenAI } from 'openai'
import { z } from 'zod'

export const config: EventConfig = {
  type: 'event',
  name: 'CallOpenAi',
  description: 'Call OpenAI',
  subscribes: ['openai-prompt'],
  emits: [],
  input: z.object({
    message: z.string({ description: 'The message to send to OpenAI' }),
  }),
  flows: ['open-ai'],
}

export const handler: Handlers['CallOpenAi'] = async (input, context) => {
  const { logger, traceId } = context
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

  logger.info('[Call OpenAI] Received callOpenAi event', input)

  const result = await openai.chat.completions.create({
    messages: [{ role: 'system', content: input.message }],
    model: 'gpt-4o-mini',
    stream: true,
  })

  const messages: string[] = []

  for await (const chunk of result) {
    messages.push(chunk.choices[0].delta.content ?? '')

    /**
     * Now we're populating a previously created message with the streamed data from OpenAI
     */
    await context.streams.openai.set(traceId, 'message', { 
      message: messages.join(''),
    })
  }

  logger.info('[Call OpenAI] OpenAI response', result)
}
```

## Testing Streams in Workbench

We know testing real time events is not easy as a backend developer, so we've added a way to test streams in the Workbench.

Here are the steps to test streams in the Workbench:

1. The API Step that provides a stream item should return the object

```typescript
export const handler: Handlers['OpenAiApi'] = async (req, { traceId, logger, emit, streams }) => {
  logger.info('[Call OpenAI] Received callOpenAi event', { message: req.body.message })

  /**
   * This creates a record with empty message string to be populated in the next step
   */
  const result = await streams.openai.set(traceId, 'message', { message: '' })

  await emit({
    topic: 'openai-prompt',
    data: { message: req.body.message },
  })

  /**
   * Return the entire object received from the create method
   */
  return { status: 200, body: result }
}
```

2. Navigate to [http://localhost:3000/endpoints](http://localhost:3000/endpoints) in your Workbench
3. Open up your endpoint and click on the `Test` button
4. The result will automatically be streamed from the server to the client streaming it's state real-time.

![Stream Test in Workbench](./../img/streams-test-workbench.gif)


## Consuming stream on the browser

```
npm install @motiadev/stream-client-react
```

Then add the provider to the root of your project

```tsx
<MotiaStreamProvider address="ws://localhost:3000">
  ...
</MotiaStreamProvider>
```

then on your component or hook, just use

```typescript
const messageId = '' // get the id back from the API call

// data below will be updated whenever it's updated in the server
const { data } = useStreamItem({ 
  streamName: 'openai',
  groupId: messageId,
  id: 'message'
})
```

-   [testing](/docs/concepts/testing): Documentation for testing.
---
title: Testing
description: Learn how to write and run tests for your Motia components
---

# Testing

Testing is an essential part of building reliable and maintainable Motia applications. Motia provides built-in support for writing and running tests to ensure the correctness of your steps, flows, and event handling logic.

## Writing Tests for Motia Components

Motia uses [Jest](https://jestjs.io/) as its testing framework. You can write tests for your Motia components using Jest's syntax and assertions.

### Step Tests

To test a step, create a test file with the same name as the step file, but with a `.test.ts` or `.test.js` extension. For example, if your step file is named `my-step.step.ts`, create a test file named `my-step.step.test.ts`.

Here's an example of a step test:

```typescript
// my-step.step.test.ts
import { createTestContext } from '@motiadev/testing'
import { handler } from './my-step.step'

describe('MyStep', () => {
  it('should emit an event with the correct data', async () => {
    const { emit, done } = createTestContext()

    await handler({ name: 'John' }, { emit })

    expect(emit).toHaveBeenCalledWith({
      type: 'my-event',
      data: { greeting: 'Hello, John!' },
    })

    done()
  })
})
```

In this example, we use the `createTestContext` function from `@motiadev/testing` to create a test context with mocked `emit` and `done` functions. We then call the step's `handler` function with test input and the mocked context. Finally, we assert that the `emit` function was called with the expected event type and data.

### Flow Tests

To test a flow, create a test file with the flow name and a `.test.ts` or `.test.js` extension. For example, if your flow is named `my-flow`, create a test file named `my-flow.test.ts`.

Here's an example of a flow test:

```typescript
// my-flow.test.ts
import { createTestFlow } from '@motiadev/testing'
import { handler as stepAHandler } from './step-a.step'
import { handler as stepBHandler } from './step-b.step'

describe('MyFlow', () => {
  it('should execute steps in the correct order', async () => {
    const flow = createTestFlow('my-flow')
      .step('step-a', stepAHandler)
      .step('step-b', stepBHandler)

    const result = await flow.execute({ name: 'Alice' })

    expect(result).toEqual({
      greeting: 'Hello, Alice!',
      message: 'Welcome to Motia!',
    })
  })
})
```

In this example, we use the `createTestFlow` function from `@motiadev/testing` to create a test flow with the specified steps. We then execute the flow with test input and assert that the final result matches the expected output.

## Running Tests Locally

To run tests locally, use the following command:

```bash
pnpm test
```

This command will run all the test files in your project and display the test results in the terminal.

You can also run tests in watch mode, which automatically re-runs the tests whenever you make changes to your code:

```bash
pnpm test --watch
```

## Best Practices

- Write tests for each step and flow to ensure comprehensive coverage.
- Use meaningful test case descriptions to clarify the purpose of each test.
- Test edge cases and error scenarios to ensure your components handle them gracefully.
- Keep your tests focused and independent to make them easier to maintain.
- Use mocks and stubs to isolate dependencies and improve test reliability.

By following these best practices and regularly running tests, you can catch bugs early, maintain code quality, and ensure the reliability of your Motia application. 

-   [how-to-contribute](/docs/contribution/how-to-contribute): Documentation for how-to-contribute.
---
title: How to Contribute
description: Guide for developers who want to contribute to Motia
---

# How to Contribute

Thank you for your interest in contributing to Motia! We welcome contributions from the community to help make Motia better. Here are some ways you can contribute:

## Reporting Issues

If you encounter any bugs, have feature requests, or want to discuss improvements, please [open an issue](https://github.com/MotiaDev/motia/issues) on our GitHub repository. When reporting bugs, please provide detailed information about your environment and steps to reproduce the issue.

## Submitting Pull Requests

We appreciate pull requests for bug fixes, enhancements, or new features. To submit a pull request:

1. Fork the [Motia repository](https://github.com/MotiaDev/motia) on GitHub.
2. Create a new branch from the `main` branch for your changes.
3. Make your modifications and ensure that the code follows our coding conventions.
4. Write tests to cover your changes, if applicable.
5. Commit your changes and push them to your forked repository.
6. Open a pull request against the `main` branch of the Motia repository.

Please provide a clear description of your changes in the pull request, along with any relevant information or context.

## Documentation Improvements

Improving the documentation is a great way to contribute to Motia. If you find any errors, typos, or areas that need clarification, please submit a pull request with the necessary changes. The documentation source files are located in the `packages/docs/content` directory.

## Sharing Examples and Use Cases

If you have built something interesting with Motia or have a real-world use case to share, we would love to showcase it in our [Examples](/docs/examples) section. You can contribute your examples by submitting a pull request to the [Motia Examples repository](https://github.com/MotiaDev/motia-examples).

## Spreading the Word

Help spread the word about Motia by sharing it with your friends, colleagues, and the developer community. You can also star our [GitHub repository](https://github.com/MotiaDev/motia), follow us on [Twitter](https://twitter.com/motiadev), and join our [Discord community](https://discord.gg/EnfDRFYW) to stay updated with the latest news and engage with other Motia developers.

We appreciate all forms of contributions and look forward to collaborating with you to make Motia even better! 

-   [Examples](/docs/examples): Documentation for Examples.
---
title: Examples
---

We have curated a few examples to help you get started with Motia.

<Cards>
  <Card
    title="Multi-Language Data Processing"
    href="/docs/examples/multi-language-data-processing"
    description="A real-world example of a multi-language data processing flow"
  />
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Sometimes you don't just want a simple ‚Äúprompt => response.‚Äù Instead, you want the LLM to decide how to proceed A real-world example of a sentiment analysis flow"
  />
  <Card
    title="RAG with Docling and Weaviate"
    href="/docs/examples/rag-docling-weaviate"
    description="A real-world example of a RAG flow using Docling and Weaviate"
  />
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="A real-world example of a uptime monitor flow"
  />
</Cards>


<br/>

## üíª Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example ‚Üí
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).



## Examples
[Examples](/docs/examples): Code example
---
title: Examples
---

We have curated a few examples to help you get started with Motia.

<Cards>
  <Card
    title="Multi-Language Data Processing"
    href="/docs/examples/multi-language-data-processing"
    description="A real-world example of a multi-language data processing flow"
  />
  <Card
    title="Sentiment Analysis"
    href="/docs/examples/sentiment-analysis"
    description="Sometimes you don't just want a simple ‚Äúprompt => response.‚Äù Instead, you want the LLM to decide how to proceed A real-world example of a sentiment analysis flow"
  />
  <Card
    title="RAG with Docling and Weaviate"
    href="/docs/examples/rag-docling-weaviate"
    description="A real-world example of a RAG flow using Docling and Weaviate"
  />
  <Card
    title="Uptime Monitor"
    href="/docs/examples/uptime-discord-monitor"
    description="A real-world example of a uptime monitor flow"
  />
</Cards>


<br/>

## üíª Explore the Source Code

All examples include complete, runnable source code with configuration files, setup instructions, and production-ready implementations:

<div className="not-prose">
  <div className="bg-gradient-to-r from-indigo-50 to-purple-50 border border-indigo-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-indigo-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Motia Examples Repository</h3>
        <p className="text-gray-600 mb-4">Access complete implementations, step-by-step tutorials, and production-ready configurations for all our examples. Perfect for learning, experimentation, and building your own applications.</p>
        <div className="grid grid-cols-1 sm:grid-cols-3 gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-indigo-600 hover:bg-indigo-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Repository
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            RAG Example ‚Üí
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center justify-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Monitor Example ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

## Contribute

We welcome contributions to the examples. Please submit a PR to the [examples repository](https://github.com/motiadev/motia-examples).


-   ['Multi-Language Data Processing: Building Event-Driven Pipelines with TypeScript, Python & JavaScript'](/docs/examples/multi-language-data-processing): Documentation for 'Multi-Language Data Processing: Building Event-Driven Pipelines with TypeScript, Python & JavaScript'.
---
title: 'Multi-Language Data Processing: Building Event-Driven Pipelines with TypeScript, Python & JavaScript'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## The Power of Steps: A Unified Multi-Language Primitive

<div className="my-8">![Multi-Language Data Processing in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, emit events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of five specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python.step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { Handlers } from 'motia'
import { z } from 'zod'
import { StartAppRequest, StartAppResponse, AppData } from '../types'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// Basic app starter - TypeScript API endpoint
export const config = {
  type: 'api',
  name: 'appStarter',
  description: 'Start the basic multi-language app',

  method: 'POST',
  path: '/start-app',

  emits: ['app.started'],
  flows: ['data-processing'],
  
  bodySchema,
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  }
} as const

export const handler: Handlers['appStarter'] = async (req, { logger, emit, traceId }) => {
  logger.info('üöÄ Starting basic app', { body: req.body, traceId })
  
  const validationResult = bodySchema.safeParse(req.body)
  
  if (!validationResult.success) {
    logger.error('Invalid request body', { errors: validationResult.error.errors })
    return { 
      status: 400, 
      body: { 
        message: 'Invalid request body', 
        errors: validationResult.error.errors 
      } 
    }
  }
  
  const appData: AppData = {
    id: Date.now(),
    input: validationResult.data.data || {},
    started_at: new Date().toISOString(),
    traceId: traceId
  }
  
  // Emit to start the app
  await emit({
    topic: 'app.started',
    data: appData
  })
  
  logger.info('app initiated successfully', { appId: appData.id })
  
  const response: StartAppResponse = {
    message: 'Basic app started successfully',
    appId: appData.id,
    traceId: traceId
  }
  
  return {
    status: 200,
    body: response
  }
} 
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { Handlers } from 'motia'
import { AppData, ProcessedResult } from '../types'

// Bridge step to connect app starter to Python processing
export const config = {
  type: 'event',
  name: 'appBridge',
  description: 'Bridge between app start and Python processing',
  
  subscribes: ['app.started'],
  emits: ['data.processed'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['appBridge'] = async (input, { logger, emit }) => {
  logger.info('üåâ Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult: ProcessedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: 'v2.1-ts'
  }
  
  // Send to Python step for async processing
  await emit({
    topic: 'data.processed',
    data: processedResult
  })
  
  logger.info('Data sent to Python step for processing', { dataId: processedResult.original_id })
} 
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem.

```python
# process-data.step.py
config = {
    'type': 'event',
    'name': 'ProcessDataPython',
    'description': 'Process incoming data and emit python.done',
    'subscribes': ['data.processed'],
    'emits': ['python.done'],
    'flows': ['data-processing']
}

async def handler(input_data, context):
    """
    Process data received from TypeScript bridge step
    
    Args:
        input_data: ProcessedResult with original_id, processed_at, result, confidence, model_version
        context: Motia context with emit, logger, etc.
    """
    try:
        # Validate required fields
        required_fields = ['original_id', 'processed_at', 'result']
        for field in required_fields:
            if field not in input_data:
                raise ValueError(f"Missing required field: {field}")
        
        context.logger.info("üêç Processing data", {
            "id": input_data['original_id'],
            "confidence_level": input_data.get('confidence', 'N/A'),
            "model_version": input_data.get('model_version', 'unknown'),
        })

        # Process the data (simulate complex Python processing)
        python_result = {
            'id': input_data['original_id'],
            'python_message': f"Python processed: {input_data['result']}",
            'processed_by': 'python-step',
            'timestamp': input_data['processed_at']
        }

        context.logger.info(f"üêç Processing complete, emitting python.done event")

        # Emit with topic and data in dictionary format
        await context.emit({"topic": "python.done", "data": python_result})

        context.logger.info("üêç Event emitted successfully", { "id": python_result['id'] })

        # Return the payload so Motia passes it along automatically
        return python_result
        
    except Exception as e:
        context.logger.error(f"üêç Error processing data: {str(e)}")
        # Re-raise the exception to let Motia handle it
        raise
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { Handlers } from 'motia'
import { PythonResult, NotificationData } from '../types'

export const config = {
  type: 'event',
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  
  subscribes: ['python.done'],
  emits: ['notification.sent'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['NotificationHandler'] = async (input, { logger, emit }) => {
  logger.info('üìß Sending notifications after Python processing:', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification: NotificationData = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }
  
  // Trigger final step
  await emit({
    topic: 'notification.sent',
    data: notification
  })
  
  logger.info('Notification sent successfully', notification)
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { Handlers } from 'motia'
import { NotificationData, AppSummary } from '../types'

// Final step to complete the app - TypeScript
export const config = {
  type: 'event',
  name: 'appFinalizer',
  description: 'Complete the basic app and log final results',
  
  subscribes: ['notification.sent'],
  emits: ['app.completed'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['appFinalizer'] = async (input, { logger, emit }) => {
  logger.info('üèÅ Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary: AppSummary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'appStarter (TypeScript)',
      'appBridge (TypeScript)', 
      'ProcessDataPython (Python)',
      'NotificationHandler (TypeScript)',
      'appFinalizer (TypeScript)',
      'summaryGenerator (JavaScript)'
    ],
    result: input.message
  }
  
  // Emit completion event
  await emit({
    topic: 'app.completed',
    data: summary
  })
  
  logger.info('‚úÖ Basic app completed successfully', summary)
} 
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  type: 'event',
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  
  subscribes: ['app.completed'],
  emits: ['summary.generated'],
  
  flows: ['data-processing']
}

export const handler = async (input, { logger, emit }) => {
  logger.info('üìä Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = new Date() - new Date(input.completed_at)
  const stepsCount = input.steps_executed.length
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: Math.abs(processingTime),
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Emit final summary
  await emit({
    topic: 'summary.generated',
    data: summary
  })
  
  logger.info('‚ú® Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Key Features & Benefits

### üß© **Step as Universal Primitive**
Every piece of logic‚Äîwhether TypeScript, Python, or JavaScript‚Äîfollows the same step pattern, creating true unification.

### üåê **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### üìä **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### ‚ö° **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### üîÑ **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### üéØ **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create -i
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npx motia dev
```

### Open the Workbench

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the Workbench and run your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
curl -X POST http://localhost:3000/start-app \
  -H "Content-Type: application/json" \
  -d '{"data":{"message":"Hello multi-language world!","value":42}}'
```

Watch in the Workbench as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## üíª Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-emit pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforward‚Äîevery new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!



## Examples
['Multi-Language Data Processing: Building Event-Driven Pipelines with TypeScript, Python & JavaScript'](/docs/examples/multi-language-data-processing): Code example
---
title: 'Multi-Language Data Processing: Building Event-Driven Pipelines with TypeScript, Python & JavaScript'
---

Modern backend development often requires combining the strengths of different programming languages. TypeScript for APIs, Python for data processing and AI, JavaScript for rapid prototyping. Traditional approaches involve complex microservices architectures with intricate communication patterns.

This comprehensive guide explores how to build a unified multi-language data processing pipeline using Motia's **step** primitive. We'll cover:

1. **Steps as Core Primitive**: How steps unify different languages under a single abstraction.
2. **Building the Pipeline**: A step-by-step guide to creating a cohesive multi-language data processing workflow.
3. **Unified Execution Model**: How steps enable seamless communication between different runtime environments.
4. **Hands-On Development**: How to build, run, and observe your unified multi-language pipeline.

Let's build a production-ready data processing system where steps unify TypeScript, Python, and JavaScript into a single cohesive workflow.

---

## The Power of Steps: A Unified Multi-Language Primitive

<div className="my-8">![Multi-Language Data Processing in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

At its core, our data processing pipeline demonstrates how **steps** solve the fundamental challenge of multi-language systems: unifying different programming languages under a single, coherent abstraction. Traditional polyglot architectures require complex inter-process communication and deployment coordination. Motia's **step** primitive unifies everything.

**Steps enable true language unification:**

- **[TypeScript](https://www.typescriptlang.org/)** steps: Strong typing and excellent tooling for APIs and orchestration
- **[Python](https://www.python.org/)** steps: Rich ecosystem for data processing, ML, and scientific computing  
- **[JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript)** steps: Dynamic processing and rapid development
- **[Motia's Step Primitive](https://motia.dev)**: The unifying abstraction that makes all languages work as a single system

Instead of managing multiple services, **steps** provide a single programming model. Whether written in TypeScript, Python, or JavaScript, every step follows the same pattern: receive data, process it, emit events. This unification is what makes multi-language development straightforward.

---

## The Anatomy of Our Multi-Language Pipeline

Our application consists of five specialized steps, each leveraging the optimal language for its specific task. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="01-starter.step.ts" />
  <File name="02-bridge.step.ts" />
  <File name="simple-python.step.py" />
  <File name="notify.step.ts" />
  <File name="04-final.step.ts" />
  <File name="05-summary.step.js" />
</Folder>

<Folder name="types" defaultOpen>
  <File name="index.ts" />
</Folder>

<Tabs items={['api-starter', 'bridge-step', 'python-processor', 'notification-handler', 'finalizer', 'summary-generator']}>
  <Tab value="api-starter">
    The entry point for our multi-language workflow. This TypeScript API endpoint receives data, validates it with Zod schemas, and kicks off the processing pipeline.

```typescript
import { Handlers } from 'motia'
import { z } from 'zod'
import { StartAppRequest, StartAppResponse, AppData } from '../types'

const bodySchema = z.object({
  data: z.record(z.unknown()).optional(),
  message: z.string().optional()
})

// Basic app starter - TypeScript API endpoint
export const config = {
  type: 'api',
  name: 'appStarter',
  description: 'Start the basic multi-language app',

  method: 'POST',
  path: '/start-app',

  emits: ['app.started'],
  flows: ['data-processing'],
  
  bodySchema,
  responseSchema: {
    200: z.object({
      message: z.string(),
      appId: z.number(),
      traceId: z.string()
    })
  }
} as const

export const handler: Handlers['appStarter'] = async (req, { logger, emit, traceId }) => {
  logger.info('üöÄ Starting basic app', { body: req.body, traceId })
  
  const validationResult = bodySchema.safeParse(req.body)
  
  if (!validationResult.success) {
    logger.error('Invalid request body', { errors: validationResult.error.errors })
    return { 
      status: 400, 
      body: { 
        message: 'Invalid request body', 
        errors: validationResult.error.errors 
      } 
    }
  }
  
  const appData: AppData = {
    id: Date.now(),
    input: validationResult.data.data || {},
    started_at: new Date().toISOString(),
    traceId: traceId
  }
  
  // Emit to start the app
  await emit({
    topic: 'app.started',
    data: appData
  })
  
  logger.info('app initiated successfully', { appId: appData.id })
  
  const response: StartAppResponse = {
    message: 'Basic app started successfully',
    appId: appData.id,
    traceId: traceId
  }
  
  return {
    status: 200,
    body: response
  }
} 
```

  </Tab>
  <Tab value="bridge-step">
    A TypeScript bridge that receives the app start event, processes the data, and forwards it to the Python processing step with proper type transformation.

```typescript
import { Handlers } from 'motia'
import { AppData, ProcessedResult } from '../types'

// Bridge step to connect app starter to Python processing
export const config = {
  type: 'event',
  name: 'appBridge',
  description: 'Bridge between app start and Python processing',
  
  subscribes: ['app.started'],
  emits: ['data.processed'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['appBridge'] = async (input, { logger, emit }) => {
  logger.info('üåâ Processing app data and sending to Python', { appId: input.id })
  
  // Process data for Python step
  const processedResult: ProcessedResult = {
    original_id: input.id,
    processed_at: input.started_at,
    result: `Processed: ${JSON.stringify(input.input)}`,
    confidence: 0.95,
    model_version: 'v2.1-ts'
  }
  
  // Send to Python step for async processing
  await emit({
    topic: 'data.processed',
    data: processedResult
  })
  
  logger.info('Data sent to Python step for processing', { dataId: processedResult.original_id })
} 
```

  </Tab>
  <Tab value="python-processor">
    The core data processor written in Python, demonstrating how Python steps integrate seamlessly with the TypeScript workflow while maintaining access to Python's rich ecosystem.

```python
# process-data.step.py
config = {
    'type': 'event',
    'name': 'ProcessDataPython',
    'description': 'Process incoming data and emit python.done',
    'subscribes': ['data.processed'],
    'emits': ['python.done'],
    'flows': ['data-processing']
}

async def handler(input_data, context):
    """
    Process data received from TypeScript bridge step
    
    Args:
        input_data: ProcessedResult with original_id, processed_at, result, confidence, model_version
        context: Motia context with emit, logger, etc.
    """
    try:
        # Validate required fields
        required_fields = ['original_id', 'processed_at', 'result']
        for field in required_fields:
            if field not in input_data:
                raise ValueError(f"Missing required field: {field}")
        
        context.logger.info("üêç Processing data", {
            "id": input_data['original_id'],
            "confidence_level": input_data.get('confidence', 'N/A'),
            "model_version": input_data.get('model_version', 'unknown'),
        })

        # Process the data (simulate complex Python processing)
        python_result = {
            'id': input_data['original_id'],
            'python_message': f"Python processed: {input_data['result']}",
            'processed_by': 'python-step',
            'timestamp': input_data['processed_at']
        }

        context.logger.info(f"üêç Processing complete, emitting python.done event")

        # Emit with topic and data in dictionary format
        await context.emit({"topic": "python.done", "data": python_result})

        context.logger.info("üêç Event emitted successfully", { "id": python_result['id'] })

        # Return the payload so Motia passes it along automatically
        return python_result
        
    except Exception as e:
        context.logger.error(f"üêç Error processing data: {str(e)}")
        # Re-raise the exception to let Motia handle it
        raise
```

  </Tab>
  <Tab value="notification-handler">
    A TypeScript notification handler that processes the Python results and sends notifications, showing seamless data flow between Python and TypeScript.

```typescript
import { Handlers } from 'motia'
import { PythonResult, NotificationData } from '../types'

export const config = {
  type: 'event',
  name: 'NotificationHandler',
  description: 'Send notifications after Python processing',
  
  subscribes: ['python.done'],
  emits: ['notification.sent'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['NotificationHandler'] = async (input, { logger, emit }) => {
  logger.info('üìß Sending notifications after Python processing:', { id: input.id })
  
  // Simulate sending notifications (email, slack, etc.)
  const notification: NotificationData = {
    id: input.id,
    message: `Notification: ${input.python_message}`,
    processed_by: input.processed_by,
    sent_at: new Date().toISOString()
  }
  
  // Trigger final step
  await emit({
    topic: 'notification.sent',
    data: notification
  })
  
  logger.info('Notification sent successfully', notification)
}
```

  </Tab>
  <Tab value="finalizer">
    A TypeScript finalizer that aggregates all the processing results and prepares the final summary data before handing off to JavaScript for metrics generation.

```typescript
import { Handlers } from 'motia'
import { NotificationData, AppSummary } from '../types'

// Final step to complete the app - TypeScript
export const config = {
  type: 'event',
  name: 'appFinalizer',
  description: 'Complete the basic app and log final results',
  
  subscribes: ['notification.sent'],
  emits: ['app.completed'],
  
  flows: ['data-processing']
} as const

export const handler: Handlers['appFinalizer'] = async (input, { logger, emit }) => {
  logger.info('üèÅ Finalizing app', { 
    notificationId: input.id,
    message: input.message 
  })
  
  // Create final app summary
  const summary: AppSummary = {
    appId: input.id,
    status: 'completed',
    completed_at: new Date().toISOString(),
    steps_executed: [
      'appStarter (TypeScript)',
      'appBridge (TypeScript)', 
      'ProcessDataPython (Python)',
      'NotificationHandler (TypeScript)',
      'appFinalizer (TypeScript)',
      'summaryGenerator (JavaScript)'
    ],
    result: input.message
  }
  
  // Emit completion event
  await emit({
    topic: 'app.completed',
    data: summary
  })
  
  logger.info('‚úÖ Basic app completed successfully', summary)
} 
```

  </Tab>
  <Tab value="summary-generator">
    The final step uses JavaScript for dynamic summary generation and metrics calculation, showcasing how all three languages work together in a single workflow.

```javascript
// Final summary step - JavaScript
export const config = {
  type: 'event',
  name: 'summaryGenerator',
  description: 'Generate final summary in JavaScript',
  
  subscribes: ['app.completed'],
  emits: ['summary.generated'],
  
  flows: ['data-processing']
}

export const handler = async (input, { logger, emit }) => {
  logger.info('üìä Generating final summary in JavaScript', { 
    appId: input.appId,
    status: input.status 
  })
  
  // Calculate processing metrics
  const processingTime = new Date() - new Date(input.completed_at)
  const stepsCount = input.steps_executed.length
  
  // Create comprehensive summary
  const summary = {
    appId: input.appId,
    finalStatus: input.status,
    totalSteps: stepsCount,
    processingTimeMs: Math.abs(processingTime),
    languages: ['TypeScript', 'Python', 'JavaScript'],
    summary: `Multi-language app completed successfully with ${stepsCount} steps`,
    result: input.result,
    completedAt: new Date().toISOString(),
    generatedBy: 'javascript-summary-step'
  }
  
  // Emit final summary
  await emit({
    topic: 'summary.generated',
    data: summary
  })
  
  logger.info('‚ú® Final summary generated successfully', summary)
  
  return summary
}
```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your multi-language pipeline, making it easy to trace data flow between TypeScript, Python, and JavaScript steps.

<div className="my-8">![Multi-Language Workflow in Motia Workbench](/docs-images/motia-build-your-app-2.gif)</div>

You can monitor real-time execution, view logs from all languages in a unified interface, and trace the complete data flow from the TypeScript API through Python processing to JavaScript summary generation.

---

## Key Features & Benefits

### üß© **Step as Universal Primitive**
Every piece of logic‚Äîwhether TypeScript, Python, or JavaScript‚Äîfollows the same step pattern, creating true unification.

### üåê **Seamless Language Integration**
Steps eliminate the complexity of multi-language systems by providing a unified programming model.

### üìä **Unified Development Experience**
Write, debug, and monitor all languages through a single interface and shared execution model.

### ‚ö° **Hot Reload Across Languages**
Edit any step in any language and see changes instantly across the entire pipeline.

### üîÑ **Event-Driven Communication**
Steps communicate through events, enabling loose coupling and independent scaling.

### üéØ **Single Deployment Model**
Deploy all languages together as a cohesive system, not as separate microservices.

---

## Trying It Out

Ready to build your first multi-language Motia application? Let's get it running.

<Steps>

### Create Your Motia App

Start by creating a new Motia project with the interactive setup.

```shell
npx motia@latest create -i
```

### Navigate and Start Development

Move into your project directory and start the development server.

```shell
cd my-app  # Replace with your project name
npx motia dev
```

### Open the Workbench

Navigate to [`http://localhost:3000`](http://localhost:3000) to access the Workbench and run your workflow.

### Test the Multi-Language Pipeline

Send a request to your API endpoint to see the multi-language workflow in action:

```shell
curl -X POST http://localhost:3000/start-app \
  -H "Content-Type: application/json" \
  -d '{"data":{"message":"Hello multi-language world!","value":42}}'
```

Watch in the Workbench as your data flows through:
1. **TypeScript** validation and event emission
2. **TypeScript** bridge processing and forwarding  
3. **Python** data processing with rich logging
4. **TypeScript** notification handling
5. **TypeScript** finalization and aggregation
6. **JavaScript** summary generation and metrics

</Steps>

---

## üíª Dive into the Code

Want to explore multi-language workflows further? Check out additional examples and the complete source code:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Multi-Language Examples</h3>
        <p className="text-gray-600 mb-4">Access complete multi-language implementations, configuration examples, and learn how to integrate TypeScript, Python, and JavaScript in production applications.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.30 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            Explore Examples
          </a>
          <a 
            href="/docs/getting-started/quick-start" 
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            Quick Start ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of Unification Through Steps

This multi-language data processing pipeline demonstrates how **steps** fundamentally change multi-language development. By providing a single primitive that works across TypeScript, Python, and JavaScript, we've eliminated the traditional complexity of polyglot architectures.

**The step primitive enables true unification:**
- **Universal Pattern** - Every step, regardless of language, follows the same receive-process-emit pattern
- **Seamless Integration** - Add Ruby, Go, Rust, or any language using the same step abstraction
- **Unified Deployment** - All languages deploy together as a single, coherent system
- **Shared Development Model** - Write, debug, and monitor everything through the same interface

**Key benefits of step-based unification:**
- **Single Mental Model** - Learn the step pattern once, apply it to any language
- **Cohesive System** - All components work together as parts of one application, not separate services
- **Consistent Experience** - Development, debugging, and monitoring work the same way across all languages
- **Natural Scaling** - Each step can scale independently while maintaining system coherence

**Extend your pipeline with more steps:**
- Add specialized processing steps for different data types and business logic
- Integrate machine learning workflows with Python steps for AI processing
- Build real-time analytics with streaming steps for live data processing
- Connect to enterprise systems through database and API integration steps
- Implement scheduled processing with cron steps for batch operations

The **step primitive** makes all extensions natural and straightforward‚Äîevery new capability follows the same unified pattern.

Ready to unify your multi-language systems? Start building with steps today!


-   ['Intelligent Document Processing: Building a RAG Agent with Motia, Docling & Weaviate'](/docs/examples/rag-docling-weaviate): Documentation for 'Intelligent Document Processing: Building a RAG Agent with Motia, Docling & Weaviate'.
---
title: 'Intelligent Document Processing: Building a RAG Agent with Motia, Docling & Weaviate'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## The Power of Intelligent Document Processing

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-docling-weaviate-agent.png)</div>


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      type: 'api',
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      path: '/api/rag/process-pdfs',
      method: 'POST',
      emits: ['rag.read.pdfs'],
      bodySchema: z.object({
        folderPath: z.string().min(1, 'folderPath is required'),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-process-pdfs'] = async (req, { emit, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Emit event to start the processing chain
      await emit({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'init-weaviate',
      subscribes: ['rag.read.pdfs'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers['init-weaviate'] = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'read-pdfs',
      flows: ['rag-workflow'],
      subscribes: ['rag.read.pdfs'],
      emits: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    export const handler: Handlers['read-pdfs'] = async (input, { emit, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await emit({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        emit = context['emit']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Emit chunks for Weaviate ingestion
            emit({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config: EventConfig = {
      type: 'event',
      name: 'load-weaviate',
      subscribes: ['rag.load.weaviate'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        chunks: z.array(ChunkSchema),
        streamId: z.string().optional(),
        totalFiles: z.number().optional(),
        totalChunks: z.number().optional(),
      }),
    }

    export const handler: Handlers['load-weaviate'] = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { Handlers } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      type: 'api',
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      path: '/api/rag/query',
      method: 'POST',
      emits: [],
      bodySchema: z.object({
        query: z.string().min(1, 'Query is required'),
        limit: z.number().min(1).max(10).default(3),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-query-rag'] = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### üöÄ **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### üß† **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### ‚ö° **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### üîÑ **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### üåê **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### üõ°Ô∏è **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3000/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## üíª Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!



## Examples
['Intelligent Document Processing: Building a RAG Agent with Motia, Docling & Weaviate'](/docs/examples/rag-docling-weaviate): Code example
---
title: 'Intelligent Document Processing: Building a RAG Agent with Motia, Docling & Weaviate'
---

In the era of AI-powered applications, the ability to extract insights from documents is crucial. Whether you're building a knowledge base, a research assistant, or a customer support system, you need to transform static PDFs into queryable, intelligent systems. This is where Retrieval-Augmented Generation (RAG) architecture shines, and where the Motia framework provides an elegant solution.

This comprehensive guide explores how to build a production-ready RAG system that intelligently processes PDFs and answers questions about their content. We'll cover:

1.  **The RAG Architecture**: Understanding how document processing, vector storage, and AI generation work together.
2.  **Motia's Event-Driven Approach**: How `steps` create a scalable, maintainable RAG pipeline.
3.  **Building the Workflow**: A detailed walkthrough of our polyglot processing pipeline.
4.  **Advanced Features**: Real-time progress tracking, error handling, and production considerations.
5.  **Hands-On Testing**: How to ingest documents and query your knowledge base.

Let's transform your documents into an intelligent AI assistant.

---

## The Power of Intelligent Document Processing

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-docling-weaviate-agent.png)</div>


At its core, our RAG agent solves a fundamental challenge: how do you make unstructured documents searchable and queryable by AI? Traditional approaches often involve complex, monolithic systems that are difficult to scale and maintain. Our Motia-powered solution breaks this down into discrete, event-driven steps that each handle a specific aspect of the pipeline.

The magic happens through the integration of three powerful technologies:

-   **[Docling](https://github.com/docling-project/docling)**: Advanced PDF parsing with intelligent chunking that preserves document structure
-   **[Weaviate](https://weaviate.io/)**: Cloud-native vector database with built-in OpenAI integration
-   **[Motia](https://motia.dev)**: Event-driven framework that orchestrates the entire pipeline

Instead of a brittle, tightly-coupled system, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our RAG Pipeline

Our application consists of seven specialized steps, each handling a specific part of the document processing and querying workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <Folder name="api-steps" defaultOpen>
    <File name="api-process-pdfs.step.ts" />
    <File name="api-query-rag.step.ts" />
  </Folder>
  <Folder name="event-steps" defaultOpen>
    <File name="init-weaviate.step.ts" />
    <File name="read-pdfs.step.ts" />
    <File name="process-pdfs.step.py" />
    <File name="load-weaviate.step.ts" />
  </Folder>
</Folder>

<Tabs items={['api-process-pdfs', 'init-weaviate', 'read-pdfs', 'process-pdfs', 'load-weaviate', 'api-query-rag']}>
  <Tab value="api-process-pdfs">
    The entry point for document ingestion. This API endpoint receives a folder path, kicks off the processing pipeline, and returns immediately with a tracking ID for real-time progress monitoring.

    ```ts
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { v4 as uuidv4 } from 'uuid'

    export const config = {
      type: 'api',
      name: 'api-process-pdfs',
      description: 'API endpoint to start PDF processing pipeline',
      path: '/api/rag/process-pdfs',
      method: 'POST',
      emits: ['rag.read.pdfs'],
      bodySchema: z.object({
        folderPath: z.string().min(1, 'folderPath is required'),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-process-pdfs'] = async (req, { emit, logger }) => {
      const { folderPath } = req.body
      const streamId = uuidv4()

      logger.info('Starting PDF processing pipeline', { folderPath, streamId })

      // Emit event to start the processing chain
      await emit({
        topic: 'rag.read.pdfs',
        data: { folderPath, streamId },
      })

      return {
        status: 200,
        body: { 
          message: 'PDF processing started',
          streamId,
          status: 'processing'
        },
      }
    }
    ```

  </Tab>
  <Tab value="init-weaviate">
    Ensures the Weaviate vector database is properly configured with the correct schema for our documents. This step creates the "Books" collection with OpenAI embeddings and GPT-4o generation capabilities.

    ```ts
    import weaviate, { WeaviateClient, vectorizer, generative } from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'init-weaviate',
      subscribes: ['rag.read.pdfs'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    const WEAVIATE_SCHEMA = {
      name: 'Books',
      description: 'Document chunks with metadata',
      vectorizers: vectorizer.text2VecOpenAI({
        model: 'text-embedding-3-small',
        sourceProperties: ['text'],
      }),
      generative: generative.openAI({
        model: 'gpt-4o',
        maxTokens: 4096,
      }),
      properties: [
        { name: 'text', dataType: 'text' as const },
        { name: 'title', dataType: 'text' as const },
        { name: 'source', dataType: 'text' as const },
        { name: 'page', dataType: 'number' as const },
      ],
    }

    export const handler: Handlers['init-weaviate'] = async (input, { logger }) => {
      logger.info('Initializing Weaviate client')
      
      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const exists = await client.collections.get('Books').exists()
        if (!exists) {
          logger.info('Creating Books collection with OpenAI integration...')
          await client.collections.create(WEAVIATE_SCHEMA)
          logger.info('Collection created successfully')
        } else {
          logger.info('Books collection already exists')
        }
      } catch (error) {
        logger.error('Error initializing Weaviate', { error })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="read-pdfs">
    Scans the specified folder for PDF files and prepares them for processing. Includes intelligent path resolution to handle various folder structures.

    ```ts
    import { readdir } from 'fs/promises'
    import { join, resolve, basename } from 'path'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: EventConfig = {
      type: 'event',
      name: 'read-pdfs',
      flows: ['rag-workflow'],
      subscribes: ['rag.read.pdfs'],
      emits: [{ topic: 'rag.process.pdfs', label: 'Start processing PDFs' }],
      input: z.object({
        folderPath: z.string(),
        streamId: z.string().optional(),
      }),
    }

    export const handler: Handlers['read-pdfs'] = async (input, { emit, logger }) => {
      const { folderPath: inputFolderPath, streamId } = input
      logger.info(`Reading PDFs from folder: ${inputFolderPath}`)

      // Intelligent path resolution to prevent ENOENT errors
      const currentDirName = basename(process.cwd())
      let resolvedFolderPath = resolve(inputFolderPath)

      // Handle duplicated path segments
      const duplicatedSegment = `${currentDirName}/${currentDirName}`
      if (resolvedFolderPath.includes(duplicatedSegment)) {
        resolvedFolderPath = resolvedFolderPath.replace(duplicatedSegment, currentDirName)
      }

      logger.info(`Resolved folder path: ${resolvedFolderPath}`)

      try {
        const files = await readdir(resolvedFolderPath)
        const pdfFiles = files.filter((file) => file.endsWith('.pdf'))

        logger.info(`Found ${pdfFiles.length} PDF files`)

        const filesInfo = await Promise.all(
          pdfFiles.map(async (pdfFile) => {
            const filePath = join(resolvedFolderPath, pdfFile)
            return {
              filePath,
              fileName: pdfFile,
            }
          })
        )

        await emit({
          topic: 'rag.process.pdfs',
          data: { files: filesInfo, streamId },
        })
      } catch (error) {
        logger.error(`Failed to read PDFs from folder: ${resolvedFolderPath}`, { error })
        throw error
      }
    }
    ```

  </Tab>
  <Tab value="process-pdfs">
    The heart of our document processing pipeline. This Python step uses Docling to intelligently parse and chunk PDFs, preserving document structure and context.

    ```python
    import json
    import os
    from pathlib import Path
    from typing import Any, Dict, List
    from docling.document_converter import DocumentConverter
    from docling.chunking import HybridChunker
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import PdfPipelineOptions
    from docling.document_converter import PdfFormatOption

    def handler(input_data: Dict[str, Any], context: Dict[str, Any]) -> None:
        """Process PDFs using Docling with intelligent chunking"""
        logger = context['logger']
        emit = context['emit']
        
        files = input_data.get('files', [])
        stream_id = input_data.get('streamId')
        
        logger.info(f"Processing {len(files)} PDF files with Docling")
        
        # Configure Docling with optimized settings
        pipeline_options = PdfPipelineOptions(
            do_ocr=True,
            do_table_structure=True,
            table_structure_options={
                "do_cell_matching": True,
            }
        )
        
        doc_converter = DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )
        
        # Initialize the hybrid chunker for intelligent document segmentation
        chunker = HybridChunker(
            tokenizer="cl100k_base",
            max_tokens=512,
            overlap_tokens=50,
            heading_hierarchies=True,
            split_by_page=False
        )
        
        all_chunks = []
        
        for file_info in files:
            file_path = file_info['filePath']
            file_name = file_info['fileName']
            
            logger.info(f"Processing file: {file_name}")
            
            try:
                # Convert PDF to structured document
                result = doc_converter.convert(file_path)
                doc = result.document
                
                logger.info(f"Converted {file_name}: {len(doc.pages)} pages")
                
                # Apply intelligent chunking
                chunks = list(chunker.chunk(doc))
                logger.info(f"Generated {len(chunks)} chunks for {file_name}")
                
                # Prepare chunks for Weaviate
                for i, chunk in enumerate(chunks):
                    chunk_data = {
                        'text': chunk.text,
                        'title': file_name,
                        'source': file_path,
                        'page': getattr(chunk, 'page_no', i + 1),
                        'chunk_id': f"{file_name}_chunk_{i}"
                    }
                    all_chunks.append(chunk_data)
                    
            except Exception as e:
                logger.error(f"Error processing {file_name}: {str(e)}")
                continue
        
        logger.info(f"Total chunks generated: {len(all_chunks)}")
        
        if all_chunks:
            # Emit chunks for Weaviate ingestion
            emit({
                'topic': 'rag.load.weaviate',
                'data': {
                    'chunks': all_chunks,
                    'streamId': stream_id,
                    'totalFiles': len(files),
                    'totalChunks': len(all_chunks)
                }
            })
        else:
            logger.warning("No chunks generated from PDF processing")
    ```

  </Tab>
  <Tab value="load-weaviate">
    Efficiently batches and loads the processed document chunks into Weaviate with progress tracking and error handling.

    ```ts
    import weaviate from 'weaviate-client'
    import { EventConfig, Handlers } from 'motia'
    import { z } from 'zod'

    const ChunkSchema = z.object({
      text: z.string(),
      title: z.string(),
      source: z.string(),
      page: z.number(),
      chunk_id: z.string(),
    })

    export const config: EventConfig = {
      type: 'event',
      name: 'load-weaviate',
      subscribes: ['rag.load.weaviate'],
      emits: [],
      flows: ['rag-workflow'],
      input: z.object({
        chunks: z.array(ChunkSchema),
        streamId: z.string().optional(),
        totalFiles: z.number().optional(),
        totalChunks: z.number().optional(),
      }),
    }

    export const handler: Handlers['load-weaviate'] = async (input, { logger }) => {
      const { chunks, streamId, totalFiles, totalChunks } = input
      
      logger.info('Loading chunks into Weaviate', { 
        chunkCount: chunks.length,
        totalFiles,
        totalChunks,
        streamId 
      })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        const BATCH_SIZE = 100

        // Process chunks in batches for optimal performance
        for (let i = 0; i < chunks.length; i += BATCH_SIZE) {
          const batch = chunks.slice(i, i + BATCH_SIZE)
          const batchNumber = Math.floor(i / BATCH_SIZE) + 1
          const totalBatches = Math.ceil(chunks.length / BATCH_SIZE)

          logger.info(`Inserting batch ${batchNumber}/${totalBatches}`, {
            batchSize: batch.length,
            streamId
          })

          const objects = batch.map(chunk => ({
            properties: {
              text: chunk.text,
              title: chunk.title,
              source: chunk.source,
              page: chunk.page,
            }
          }))

          const result = await collection.data.insertMany(objects)
          
          if (result.hasErrors) {
            logger.error('Batch insertion had errors', { 
              errors: result.errors,
              batchNumber,
              streamId 
            })
          } else {
            logger.info(`Successfully inserted batch ${batchNumber}/${totalBatches}`)
          }
        }

        logger.info('Successfully loaded all chunks into Weaviate', {
          totalChunks: chunks.length,
          streamId
        })

      } catch (error) {
        logger.error('Error loading chunks into Weaviate', { error, streamId })
        throw error
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
  <Tab value="api-query-rag">
    The query interface that performs semantic search and generates contextual answers using Weaviate's integrated OpenAI capabilities.

    ```ts
    import weaviate from 'weaviate-client'
    import { Handlers } from 'motia'
    import { z } from 'zod'

    const RAGResponse = z.object({
      answer: z.string(),
      chunks: z.array(z.object({
        text: z.string(),
        title: z.string(),
        source: z.string(),
        page: z.number(),
      })),
      query: z.string(),
      timestamp: z.string(),
    })

    export const config = {
      type: 'api',
      name: 'api-query-rag',
      description: 'Query the RAG system for answers',
      path: '/api/rag/query',
      method: 'POST',
      emits: [],
      bodySchema: z.object({
        query: z.string().min(1, 'Query is required'),
        limit: z.number().min(1).max(10).default(3),
      }),
      flows: ['rag-workflow'],
    } as const

    export const handler: Handlers['api-query-rag'] = async (req, { logger }) => {
      const { query, limit = 3 } = req.body

      logger.info('Processing RAG query', { query, limit })

      const client = await weaviate.connectToWeaviateCloud(process.env.WEAVIATE_URL!, {
        authCredentials: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY!),
        headers: { 'X-OpenAI-Api-Key': process.env.OPENAI_API_KEY! },
      })

      try {
        const collection = client.collections.get('Books')
        
        // Perform semantic search with AI generation
        const results = await collection.generate.nearText(
          query,
          { limit, distance: 0.6 },
          { 
            singlePrompt: `Answer this question based on the provided context: ${query}. 
                          Be specific and cite the sources when possible.` 
          }
        )

        // Extract the generated answer and source chunks
        const generatedAnswer = results.generated || 'No answer could be generated.'
        
        const chunks = results.objects.map(obj => ({
          text: obj.properties.text as string,
          title: obj.properties.title as string,
          source: obj.properties.source as string,
          page: obj.properties.page as number,
        }))

        const response = RAGResponse.parse({
          answer: generatedAnswer,
          chunks,
          query,
          timestamp: new Date().toISOString(),
        })

        logger.info('RAG query completed successfully', { 
          query, 
          chunksFound: chunks.length,
          answerLength: generatedAnswer.length 
        })

        return {
          status: 200,
          body: response,
        }

      } catch (error) {
        logger.error('Error processing RAG query', { error, query })
        return {
          status: 500,
          body: { error: 'Failed to process query' },
        }
      } finally {
        await client.close()
      }
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your RAG pipeline, making it easy to understand the flow and debug any issues.

<div className="my-8">![RAG Workflow in Motia Workbench](./../img/rag-example.gif)</div>

You can monitor real-time processing, view logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monolithic approaches.

---

## Key Features & Benefits

### üöÄ **Event-Driven Architecture**
Each step is independent and communicates through events, making the system highly scalable and maintainable.

### üß† **Intelligent Document Processing**  
Docling's hybrid chunking preserves document structure while creating optimal chunks for embedding.

### ‚ö° **High-Performance Vector Search**
Weaviate's cloud-native architecture provides fast, scalable similarity search with built-in OpenAI integration.

### üîÑ **Real-Time Progress Tracking**
Monitor document processing progress with detailed logging and status updates.

### üåê **Polyglot Support**
Seamlessly combine Python (Docling) and TypeScript (orchestration) in a single workflow.

### üõ°Ô∏è **Production-Ready**
Built-in error handling, batch processing, and resource cleanup ensure reliability.

---

## Trying It Out

Ready to build your own intelligent document assistant? Let's get the system running.

<Steps>

### Install Dependencies

Install both Node.js and Python dependencies. The prepare script automatically sets up the Python virtual environment.

```shell
npm install
```

### Set Your Environment Variables

You'll need API keys for OpenAI and Weaviate Cloud. Create a `.env` file:

```shell
OPENAI_API_KEY="sk-..."
WEAVIATE_URL="https://your-cluster.weaviate.network"
WEAVIATE_API_KEY="your-weaviate-api-key"
```

### Run the Project

Start the Motia development server to begin processing documents.

```shell
npm run dev
```

### Process Your First Documents

Add some PDF files to the `docs/pdfs/` folder, then start the ingestion pipeline:

```shell
curl -X POST http://localhost:3000/api/rag/process-pdfs \
  -H "Content-Type: application/json" \
  -d '{"folderPath":"docs/pdfs"}'
```

Watch the logs as your documents are processed through the pipeline:
1. **PDF Reading**: Files are discovered and queued
2. **Docling Processing**: Intelligent chunking with structure preservation  
3. **Weaviate Loading**: Chunks are embedded and stored

### Query Your Knowledge Base

Once processing is complete, you can ask questions about your documents:

#### General Query
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What are the main topics covered in these documents?","limit":3}'
```

#### Specific Question
```shell
curl -X POST http://localhost:3000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query":"What methodology was used in the research?","limit":5}'
```

The response includes both a generated answer and the source chunks with page numbers for verification.

</Steps>

---

## Advanced Usage

### Custom Chunking Strategies

Modify the Python processing step to implement custom chunking logic:

```python
# In process-pdfs.step.py
chunker = HybridChunker(
    tokenizer="cl100k_base",
    max_tokens=1024,  # Larger chunks for more context
    overlap_tokens=100,  # More overlap for better continuity
    heading_hierarchies=True,
    split_by_page=True  # Preserve page boundaries
)
```

### Batch Processing Optimization

Adjust batch sizes in the Weaviate loading step for optimal performance:

```ts
// In load-weaviate.step.ts
const BATCH_SIZE = 50  // Smaller batches for large documents
```

### Multi-Collection Support

Extend the system to handle different document types by creating separate Weaviate collections:

```ts
const COLLECTIONS = {
  research: 'ResearchPapers',
  manuals: 'TechnicalManuals', 
  reports: 'BusinessReports'
}
```

---

## Troubleshooting

### Common Issues

**ENOENT Path Errors**: The system automatically handles path normalization, but ensure your `folderPath` is relative to the project root.

**Empty Answers**: Check that documents were successfully processed by examining the logs. Verify your OpenAI API key is valid.

**Weaviate Connection Issues**: Ensure your `WEAVIATE_URL` and `WEAVIATE_API_KEY` are correct and your cluster is running.

### Performance Tips

- **Document Size**: For large PDFs, consider preprocessing to split them into smaller files
- **Batch Size**: Adjust the Weaviate batch size based on your cluster's capacity
- **Chunking Strategy**: Experiment with different chunk sizes and overlap for your specific use case

---

## üíª Dive into the Code

Want to explore the complete RAG implementation? Check out the full source code, including all steps, configuration files, and setup instructions:

<div className="not-prose">
  <div className="bg-gradient-to-r from-purple-50 to-pink-50 border border-purple-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-purple-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete RAG Implementation</h3>
        <p className="text-gray-600 mb-4">Access the full source code for this RAG agent, including Python processing scripts, TypeScript orchestration, and production configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/rag-docling-weaviate-agent" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-purple-600 hover:bg-purple-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.30.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View RAG Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Future of Document Intelligence

This RAG system demonstrates the power of combining best-in-class technologies with Motia's event-driven architecture. By breaking down complex document processing into discrete, manageable steps, we've created a system that's not only powerful but also maintainable and scalable.

The polyglot nature of the solution: Python for document processing, TypeScript for orchestration, shows how Motia enables you to use the right tool for each job without sacrificing integration or maintainability.

From here, you can extend the system by:
- Adding support for other document formats (Word, PowerPoint, etc.)
- Implementing document classification and routing
- Adding real-time document updates and synchronization
- Building a web interface for document management
- Integrating with existing business systems

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing pipeline.

Ready to transform your documents into intelligent, queryable knowledge bases? Start building with Motia today!


-   ['Dynamic Workflows: Building a Sentiment Analyzer with Motia'](/docs/examples/sentiment-analysis): Documentation for 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'.
---
title: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analysis.png)</div>

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.png)</div>

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, emits a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's an API step that listens for `POST` requests, validates the incoming data, and emits an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, emits "openai.analyzeSentimentRequest".
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'api',
      name: 'analyzeSentimentApi',
      description: 'Receives user text and emits an event to trigger sentiment analysis.',
      path: '/api/analyze-sentiment',
      method: 'POST',
      emits: ['openai.analyzeSentimentRequest'],
      bodySchema: z.object({
        text: z.string().min(1, 'text is required'),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['analyzeSentimentApi'] = async (req, { emit, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Emit an event to call OpenAI
      await emit({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It subscribes to the `openai.analyzeSentimentRequest` event, calls the OpenAI API, and then based on the response, emits either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    // 1) Create an OpenAI client (newer syntax)
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      type: 'event',
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and emits corresponding events.',
      subscribes: ['openai.analyzeSentimentRequest'],
      // We'll emit different events: "openai.positiveSentiment" or "openai.negativeSentiment"
      emits: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      input: z.object({ text: z.string() }),
      flows: ['sentiment-demo'],
    } as const

    // 3) Provide the code that runs on each event
    export const handler: Handlers['openAiSentimentAnalyzer'] = async (input, { emit, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await emit({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await emit({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      subscribes: ['openai.positiveSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handlePositive'] = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      subscribes: ['openai.negativeSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handleNegative'] = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

You can explore the workflow in the Workbench.

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, debug your architecture directly in the Workbench.

<div className="my-8">![Workbench](./../img/sentimental-analyzer-workbench.gif)</div>

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## üíª Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!


## Examples
['Dynamic Workflows: Building a Sentiment Analyzer with Motia'](/docs/examples/sentiment-analysis): Code example
---
title: 'Dynamic Workflows: Building a Sentiment Analyzer with Motia'
---

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analysis.png)</div>

In modern application development, workflows are rarely linear. Whether you're building a simple "prompt => response" system or a complex, multi-stage data processing pipeline, you often need your application to make decisions and route data dynamically. This is where the power of event-driven architecture shines, and where the Motia framework provides a clear path forward.

This guide explores how to build a dynamic sentiment analysis application that uses an LLM to determine how to proceed. We'll cover:

1.  **The Motia Philosophy**: How `steps` as a core primitive simplify complex architectures.
2.  **Building the Workflow**: A step-by-step guide to creating the four key components of our application.
3.  **Visualizing the Flow**: How events chain together to create a cohesive, dynamic system.
4.  **Hands-On with the API**: How to run and test your new sentiment analyzer.

Let's dive in.

---

## A Step at a Time

<div className="my-8">![motia workbench for sentiment analysis](./../img/sentimental-analyzer-workbench.png)</div>

At the heart of the Motia framework is a simple but powerful idea: the **`step`**. A step is a self-contained, independent unit of logic that listens for an event, performs a task, and, optionally, emits a new event. This concept is the core primitive that allows you to break down even the most complex architectures into a series of simple, manageable components.

Instead of a monolithic application where business logic is tightly coupled, Motia encourages a decoupled, event-driven approach. This has several key advantages:

-   **Clarity**: Each step has a single responsibility, making the application easier to understand and reason about.
-   **Scalability**: Steps can be scaled independently, so you can allocate resources where they're needed most.
-   **Extensibility**: Adding new functionality is as simple as creating a new step and subscribing it to an existing event.
-   **Resilience**: The decoupled nature of steps means that a failure in one part of the system doesn't necessarily bring down the entire application.

In this project, we'll see this philosophy in action as we build a sentiment analyzer with four distinct steps, each with its own clear purpose.

---

## The Anatomy of Our Sentiment Analyzer

Our application will be composed of four steps. Let's explore each one.

<Folder name="steps" defaultOpen>
  <File name="analyzeSentimentApi.step.ts" />
  <File name="openAiAnalyzeSentiment.step.ts" />
  <File name="handlePositive.step.ts" />
  <File name="handleNegative.step.ts" />
</Folder>

<Tabs items={['analyzeSentimentApi', 'openAiAnalyzeSentiment', 'handlePositive', 'handleNegative']}>
  <Tab value="analyzeSentimentApi">
    This is the entry point to our workflow. It's an API step that listens for `POST` requests, validates the incoming data, and emits an `openai.analyzeSentimentRequest` event.

    ```ts
    // Receives user text, emits "openai.analyzeSentimentRequest".
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'api',
      name: 'analyzeSentimentApi',
      description: 'Receives user text and emits an event to trigger sentiment analysis.',
      path: '/api/analyze-sentiment',
      method: 'POST',
      emits: ['openai.analyzeSentimentRequest'],
      bodySchema: z.object({
        text: z.string().min(1, 'text is required'),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['analyzeSentimentApi'] = async (req, { emit, logger }) => {
      const { text } = req.body

      logger.info('[AnalyzeSentimentAPI] Received text', { text })

      // Emit an event to call OpenAI
      await emit({
        topic: 'openai.analyzeSentimentRequest',
        data: { text },
      })

      // Return right away
      return {
        status: 200,
        body: { status: 'Accepted', message: 'Your text is being analyzed' },
      }
    }
    ```

  </Tab>
  <Tab value="openAiAnalyzeSentiment">
    This step is the brains of our operation. It subscribes to the `openai.analyzeSentimentRequest` event, calls the OpenAI API, and then based on the response, emits either a `openai.positiveSentiment` or `openai.negativeSentiment` event. This is where the dynamic routing happens.

    ```ts
    // Calls OpenAI, instructing it to ONLY return JSON like {"sentiment":"positive","analysis":"..."}
    import { Handlers } from 'motia'
    import { z } from 'zod'
    import { OpenAI } from 'openai'

    // 1) Create an OpenAI client (newer syntax)
    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })

    export const config = {
      type: 'event',
      name: 'openAiSentimentAnalyzer',
      description: 'Calls OpenAI to analyze sentiment and emits corresponding events.',
      subscribes: ['openai.analyzeSentimentRequest'],
      // We'll emit different events: "openai.positiveSentiment" or "openai.negativeSentiment"
      emits: ['openai.positiveSentiment', 'openai.negativeSentiment'],
      input: z.object({ text: z.string() }),
      flows: ['sentiment-demo'],
    } as const

    // 3) Provide the code that runs on each event
    export const handler: Handlers['openAiSentimentAnalyzer'] = async (input, { emit, logger }) => {
      logger.info('[OpenAI Sentiment Analyzer] Prompting OpenAI...', { text: input.text })

      try {
        // We'll ask the model to ONLY return JSON with a "sentiment" field
        const systemPrompt =
          'You are an assistant that returns only JSON: {"sentiment":"positive|negative","analysis":"..."}'
        const userPrompt = `Analyze the sentiment of this text: "${input.text}". Return JSON with keys "sentiment" and "analysis".`

        // 4) Use the new openai syntax:
        const response = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt },
          ],
        })

        // 5) Log and parse the response
        const content = response.choices[0]?.message?.content || ''
        logger.info('[OpenAI Sentiment Analyzer] Raw response', { content })

        let parsed: { sentiment?: string; analysis?: string } = {}
        try {
          parsed = JSON.parse(content.trim())
        } catch (err) {
          logger.error('[OpenAI Sentiment Analyzer] Unable to parse JSON', { error: err })
          // If it's not JSON, we bail or handle differently
          return
        }

        // 6) Decide how to route the event
        if (parsed.sentiment) {
          if (parsed.sentiment.toLowerCase() === 'positive') {
            await emit({
              topic: 'openai.positiveSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          } else {
            // default to negative
            await emit({
              topic: 'openai.negativeSentiment',
              data: { ...parsed, sentiment: parsed.sentiment },
            })
          }
        } else {
          logger.error('[OpenAI Sentiment Analyzer] Sentiment is missing from the parsed response', { parsed })
        }
      } catch (err) {
        if (err instanceof Error) {
          logger.error('[OpenAI Sentiment Analyzer] Error calling OpenAI', { error: err.message })
        } else {
          logger.error('[OpenAI Sentiment Analyzer] An unknown error occurred while calling OpenAI', { error: err })
        }
      }
    }
    ```
  </Tab>
  <Tab value="handlePositive">
    A specialized responder that listens for the `openai.positiveSentiment` event and logs a confirmation message. In a real-world application, this could trigger a Slack notification, send an email, or kick off another workflow.

    ```ts
    // Handles "openai.positiveSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handlePositive',
      description: 'Handles positive sentiment responses.',
      subscribes: ['openai.positiveSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handlePositive'] = async (input, { logger }) => {
      logger.info('[Positive Responder] The sentiment is positive!', { analysis: input.analysis })
      // Maybe notify a Slack channel: "All good vibes here!"
    }
    ```

  </Tab>
  <Tab value="handleNegative">
    Similar to the positive handler, this step listens for the `openai.negativeSentiment` event. This is where you could implement logic to escalate a customer complaint, create a support ticket, or alert the on-call team.

    ```ts
    // Handles "openai.negativeSentiment"
    import { Handlers } from 'motia'
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'handleNegative',
      description: 'Handles negative or unknown sentiment responses.',
      subscribes: ['openai.negativeSentiment'],
      emits: [],
      input: z.object({
        sentiment: z.string(),
        analysis: z.string().optional(),
      }),
      flows: ['sentiment-demo'],
    } as const

    export const handler: Handlers['handleNegative'] = async (input, { logger }) => {
      logger.info('[Negative Responder] The sentiment is negative or unknown.', { analysis: input.analysis })
      // Could escalate to a service, or respond gently, etc.
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

You can explore the workflow in the Workbench.

<div className="my-8">![Flow](./../img/sentimental-analyzer.png)</div>

You can also read your files and watch logs, traces, debug your architecture directly in the Workbench.

<div className="my-8">![Workbench](./../img/sentimental-analyzer-workbench.gif)</div>

---

## Trying It Out

Ready to see it in action? Let's get the project running.

<Steps>

### Install Dependencies

First, install the necessary npm packages.

```shell
npm install
```

### Set Your Environment Variables

You'll need an OpenAI API key for this project. Export it as an environment variable.

```shell
export OPENAI_API_KEY="sk-..."
```

### Run the Project

Start the Motia development server.

```shell
npm run dev
```

### Test the API

Now you can send requests to your API and see the workflow in action.

#### Positive Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"I absolutely love this new device! It is amazing and works perfectly."}'
```

Check your logs, and you should see the `[Positive Responder]` has been triggered.

#### Negative Sentiment

```shell
curl -X POST http://localhost:3000/api/analyze-sentiment \
  -H "Content-Type: application/json" \
  -d '{"text":"This is the worst product I have ever used. It broke after one day."}'
```

This time, the `[Negative Responder]` will fire.

</Steps>

---

## üíª Dive into the Code

Want to explore the complete implementation? Check out the full source code and additional examples in our GitHub repository:

<div className="not-prose">
  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-blue-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Explore More Examples</h3>
        <p className="text-gray-600 mb-4">Get hands-on with the complete source code, configuration files, and additional examples to accelerate your learning.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/sentimental-analysis" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Sentiment Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: The Power of a Simple Primitive

This sentiment analysis application is a powerful demonstration of the Motia philosophy. By embracing the `step` as a core primitive, we've turned a potentially complex, branching workflow into a series of simple, understandable, and scalable components.

This is just the beginning. From here, you can extend the application by adding new steps to handle neutral sentiment, send notifications, or store results in a database. The event-driven architecture of Motia makes it easy to add new functionality without disrupting the existing flow.

We encourage you to explore, experiment, and see for yourself how Motia can simplify your most complex backend challenges. Happy coding!

-   ['Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'](/docs/examples/uptime-discord-monitor): Documentation for 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'.
---
title: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor-architecture.png)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically emits check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';

    export const config = {
      type: 'cron',
      name: 'UptimeCronTrigger',
      cron: envConfig.cron,
      emits: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        // Emit one check.requested event per configured site URL
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);
          
          await context.emit({ 
            topic: 'check.requested', 
            data: { url: url } 
          });
          
          context.logger.info(`Successfully emitted for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then emits results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and emits results',
      subscribes: ['check.requested'],
      emits: ['check.result', 'status.stream'],
      input: z.object({
        url: z.string().url('Must be a valid URL')
      }),
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, emit }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      // Emit results to both alerter and dashboard
      await emit({ topic: 'check.result', data: result })
      await emit({ topic: 'status.stream', data: result })

      logger.info('Check results emitted successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      type: 'event',
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      subscribes: ['check.result'],
      emits: [],
      input: z.object({
        url: z.string().url(),
        status: z.enum(['UP', 'DOWN']),
        code: z.number().nullable(),
        responseTime: z.number(),
        checkedAt: z.string(),
        error: z.string().nullable()
      }),
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? 'üü¢' : 'üî¥'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} ‚Üí ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      type: 'api',
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      method: 'GET',
      path: '/healthz',
      emits: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '*/1 * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor in Motia Workbench](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### ‚ö° **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### üéØ **Smart Status Detection**  
Only triggers alerts when status actually changes (UP ‚Üî DOWN), eliminating noise from temporary fluctuations.

### üö® **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### üìä **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### üîß **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### üé® **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** ‚Üí Emits `check.requested` events for each configured site
2. **Website Checker** ‚Üí Receives `check.requested`, performs HTTP check
3. **Status Update** ‚Üí Checker emits `check.result` with result
4. **Alert Processing** ‚Üí Alerter receives `check.result`, detects status changes
5. **Discord Notification** ‚Üí Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** ‚Üí Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="*/1 * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** ‚Üí **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3000/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="*/5 * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 */6 * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="* 9-17 * * 1-5"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? '‚úÖ' : '‚ùå'
  const urgency = responseTime > 5000 ? 'üêå SLOW' : '‚ö° FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: '‚è±Ô∏è Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: 'üìä Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3000/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3000/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3000/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## üíª Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with event steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!



## Examples
['Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'](/docs/examples/uptime-discord-monitor): Code example
---
title: 'Real-Time Uptime Monitoring: Building a Resilient Website Monitor with Motia'
---

In today's modern era, website uptime is critical for business success. Whether you're monitoring a personal blog or enterprise applications, you need a reliable system that can detect outages, send alerts, and provide visibility into your site's health. Traditional monitoring solutions often involve complex infrastructure and vendor lock-in, but there's a better way.

This comprehensive guide explores how to build a production-ready uptime monitoring system using Motia's event-driven architecture. We'll cover:

1.  **Event-Driven Monitoring**: How Motia's `steps` create a scalable, maintainable monitoring pipeline.
2.  **Building the Architecture**: A detailed walkthrough of our five-component monitoring system.
3.  **Smart Alerting**: Implementing rate limiting and status change detection to prevent spam.

Let's build a monitoring system that actually works for you.

---

## The Power of Event-Driven Monitoring

<div className="my-8">![Uptime Monitor Architecture](./../img/uptime-monitor-architecture.png)</div>

At its core, our uptime monitoring system solves a fundamental challenge: how do you continuously monitor multiple websites without creating a brittle, monolithic application? Traditional monitoring tools often suffer from tight coupling, making them difficult to scale and customize. Our Motia-powered solution breaks this down into discrete, event-driven components that each handle a specific aspect of monitoring.

The magic happens through the integration of proven technologies and patterns:

-   **[Cron-Based Scheduling](https://en.wikipedia.org/wiki/Cron)**: Configurable check intervals using familiar cron expressions
-   **[Discord Webhooks](https://discord.com/developers/docs/resources/webhook)**: Instant notifications with rich formatting
-   **[Token Bucket Rate Limiting](https://en.wikipedia.org/wiki/Token_bucket)**: Intelligent alert throttling to prevent spam
-   **[Motia Framework](https://motia.dev)**: Event-driven orchestration with built-in observability

Instead of a monolithic monitoring daemon, we get a resilient architecture where each component can be scaled, modified, or replaced independently.

---

## The Anatomy of Our Monitoring System

Our application consists of five specialized steps, each handling a specific part of the monitoring workflow. Let's explore the complete architecture.

<Folder name="steps" defaultOpen>
  <File name="cron.step.js" />
  <File name="checker.step.js" />
  <File name="alerter.step.js" />
  <File name="health.step.js" />
</Folder>

<Folder name="lib" defaultOpen>
  <File name="env.js" />
  <File name="rate-limiter.js" />
  <File name="streams.js" />
</Folder>

<Tabs items={['cron', 'checker', 'alerter', 'health', 'utilities']}>
  <Tab value="cron">
    The heartbeat of our monitoring system. This cron-triggered step periodically emits check requests for all configured websites, acting as the central scheduler.

    ```js
    import { config as envConfig } from '../lib/env.js';

    export const config = {
      type: 'cron',
      name: 'UptimeCronTrigger',
      cron: envConfig.cron,
      emits: ['check.requested'],
      flows: ['uptime-monitoring']
    };

    export async function handler(context) {
      context.logger.info(`Starting uptime checks for ${envConfig.sites.length} sites`);
      context.logger.info(`Sites configured: ${JSON.stringify(envConfig.sites)}`);

      try {
        // Emit one check.requested event per configured site URL
        for (const url of envConfig.sites) {
          context.logger.info(`Scheduling check for: ${url}`);
          
          await context.emit({ 
            topic: 'check.requested', 
            data: { url: url } 
          });
          
          context.logger.info(`Successfully emitted for: ${url}`);
        }

        context.logger.info(`Successfully scheduled checks for all ${envConfig.sites.length} sites`);
      } catch (error) {
        context.logger.error('Error during cron execution:', error);
        throw error;
      }
    }
    ```

  </Tab>
  <Tab value="checker">
    The core monitoring component that performs HTTP checks on websites. It handles timeouts, errors, and response code analysis, then emits results for further processing.

    ```js
    import { z } from 'zod'

    export const config = {
      type: 'event',
      name: 'WebsiteChecker',
      description: 'Performs HTTP checks on websites and emits results',
      subscribes: ['check.requested'],
      emits: ['check.result', 'status.stream'],
      input: z.object({
        url: z.string().url('Must be a valid URL')
      }),
      flows: ['uptime-monitoring'],
    }

    export const handler = async (input, { logger, emit }) => {
      const { url } = input
      
      logger.info('Starting website check', { url })

      const startTime = performance.now()
      let result

      try {
        // Validate URL format before making request
        const urlObj = new URL(url)
        if (!['http:', 'https:'].includes(urlObj.protocol)) {
          throw new Error('Only HTTP and HTTPS protocols are supported')
        }

        // Perform HTTP request with timeout handling
        const controller = new AbortController()
        const timeoutId = setTimeout(() => controller.abort(), 10000) // 10 second timeout

        const response = await fetch(url, {
          method: 'GET',
          signal: controller.signal,
          headers: {
            'User-Agent': 'Motia-Uptime-Monitor/1.0',
            'Accept': '*/*',
            'Cache-Control': 'no-cache'
          },
          redirect: 'manual'
        })

        clearTimeout(timeoutId)
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        // Determine status: 2xx and 3xx as UP, everything else as DOWN
        const status = (response.status >= 200 && response.status < 400) ? 'UP' : 'DOWN'

        result = {
          url,
          status,
          code: response.status,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: null
        }

        logger.info('Website check completed', {
          url,
          status,
          code: response.status,
          responseTime
        })

      } catch (error) {
        const endTime = performance.now()
        const responseTime = Math.round(endTime - startTime)

        let errorMessage = error.message

        // Handle specific error types with detailed messages
        if (error.name === 'AbortError') {
          errorMessage = 'Request timeout (10s)'
        } else if (error.name === 'TypeError' && error.message.includes('fetch')) {
          errorMessage = 'Network error - unable to connect'
        } else if (error.code === 'ENOTFOUND') {
          errorMessage = 'DNS resolution failed'
        } else if (error.code === 'ECONNREFUSED') {
          errorMessage = 'Connection refused'
        }

        result = {
          url,
          status: 'DOWN',
          code: null,
          responseTime,
          checkedAt: new Date().toISOString(),
          error: errorMessage
        }

        logger.error('Website check failed', {
          url,
          error: errorMessage,
          responseTime,
          originalError: error.code || error.name
        })
      }

      // Emit results to both alerter and dashboard
      await emit({ topic: 'check.result', data: result })
      await emit({ topic: 'status.stream', data: result })

      logger.info('Check results emitted successfully', { url, status: result.status })
    }
    ```

  </Tab>
  <Tab value="alerter">
    The intelligent alerting system that detects status changes, applies rate limiting, and sends Discord notifications. Only triggers alerts when status actually changes, preventing noise.

    ```js
    import { z } from 'zod'
    import { getPreviousStatus } from '../lib/streams.js'
    import { createRateLimiter } from '../lib/rate-limiter.js'
    import { config as envConfig } from '../lib/env.js'

    // Create a rate limiter instance for Discord alerts
    const rateLimiter = createRateLimiter({
      burst: envConfig.alertBurst,
      windowSec: envConfig.alertWindowSec
    })

    export const config = {
      type: 'event',
      name: 'DiscordAlerter',
      description: 'Sends Discord notifications when website status changes',
      subscribes: ['check.result'],
      emits: [],
      input: z.object({
        url: z.string().url(),
        status: z.enum(['UP', 'DOWN']),
        code: z.number().nullable(),
        responseTime: z.number(),
        checkedAt: z.string(),
        error: z.string().nullable()
      }),
      flows: ['uptime-monitoring'],
    }

    function createDiscordMessage(result, previousStatus) {
      const { url, status, code, responseTime, checkedAt, error } = result

      const isUp = status === 'UP'
      const emoji = isUp ? 'üü¢' : 'üî¥'
      const color = isUp ? 0x00ff00 : 0xff0000

      const content = `${emoji} ${url} is ${status}${code ? ` (${code})` : ''}`

      const fields = [
        {
          name: 'Response Time',
          value: `${responseTime}ms`,
          inline: true
        }
      ]

      if (code !== null) {
        fields.push({
          name: 'Status Code',
          value: code.toString(),
          inline: true
        })
      }

      if (error) {
        fields.push({
          name: 'Error',
          value: error,
          inline: false
        })
      }

      fields.push({
        name: 'Previous Status',
        value: previousStatus,
        inline: true
      })

      return {
        content,
        embeds: [{
          title: `Website Status Change: ${status}`,
          description: `${url} changed from ${previousStatus} to ${status}`,
          color,
          timestamp: checkedAt,
          fields
        }]
      }
    }

    export const handler = async (input, { logger }) => {
      const { url, status } = input

      // Get the previous status for comparison
      const previousResult = getPreviousStatus(url)

      // Handle first-time checks
      if (!previousResult) {
        logger.info('First-time check for site, no alert needed', { url, status })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      const previousStatus = previousResult.status

      // Only trigger alerts when status actually changes
      if (status === previousStatus) {
        logger.debug('Status unchanged, no alert needed', { url, status, previousStatus })
        const { updateLastStatus } = await import('../lib/streams.js')
        updateLastStatus(input)
        return
      }

      // Status has changed - check rate limiting
      logger.info('Status change detected', {
        url,
        previousStatus,
        newStatus: status,
        transition: `${previousStatus} ‚Üí ${status}`
      })

      if (!rateLimiter.consume(url)) {
        const timeUntilNext = rateLimiter.getTimeUntilNextToken(url)
        logger.warn('Alert rate limited', {
          url,
          status,
          previousStatus,
          timeUntilNextMs: timeUntilNext,
          tokensRemaining: rateLimiter.getTokenCount(url)
        })
        return
      }

      // Send Discord notification
      const message = createDiscordMessage(input, previousStatus)
      
      try {
        const response = await fetch(envConfig.discordWebhook, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'User-Agent': 'Motia-Uptime-Monitor/1.0'
          },
          body: JSON.stringify(message)
        })

        if (response.ok) {
          logger.info('Discord alert sent successfully', { url, status, previousStatus })
        } else {
          const errorText = await response.text().catch(() => 'Unknown error')
          logger.error('Discord webhook failed', {
            status: response.status,
            error: errorText
          })
        }
      } catch (error) {
        logger.error('Failed to send Discord webhook', {
          error: error.message
        })
      }

      // Update status store after sending alert
      const { updateLastStatus } = await import('../lib/streams.js')
      updateLastStatus(input)
    }
    ```

  </Tab>
  <Tab value="health">
    A health check endpoint that provides system status and monitoring metrics. Essential for monitoring the monitor itself and integrating with external health check services.

    ```js
    import { z } from 'zod'
    import { getSnapshot } from '../lib/streams.js'
    import { config as envConfig } from '../lib/env.js'

    export const config = {
      type: 'api',
      name: 'HealthCheck',
      description: 'Provides system health status endpoint',
      method: 'GET',
      path: '/healthz',
      emits: [],
      responseSchema: {
        200: z.object({
          status: z.literal('ok'),
          sitesConfigured: z.number(),
          lastKnown: z.record(z.any()),
          now: z.string()
        })
      },
      flows: ['uptime-monitoring'],
    }

    export const handler = async (_, { logger }) => {
      logger.info('Health check endpoint accessed')
      
      try {
        const now = new Date().toISOString()
        const sitesConfigured = envConfig.sites.length
        const lastKnown = getSnapshot()
        
        const response = {
          status: 'ok',
          sitesConfigured,
          lastKnown,
          now
        }
        
        logger.info('Health check completed successfully', { 
          sitesConfigured,
          sitesWithStatus: Object.keys(lastKnown).length
        })
        
        return {
          status: 200,
          body: response
        }
        
      } catch (error) {
        logger.error('Health check failed', { 
          error: error.message,
          stack: error.stack
        })
        
        return {
          status: 200,
          body: {
            status: 'ok',
            sitesConfigured: 0,
            lastKnown: {},
            now: new Date().toISOString(),
            error: error.message
          }
        }
      }
    }
    ```

  </Tab>
  <Tab value="utilities">
    Three essential utility libraries that power the monitoring system: environment validation, rate limiting, and persistent status storage.

    **Environment Configuration (`lib/env.js`)**
    ```js
    // Validates Discord webhook URLs
    function isValidDiscordWebhook(url) {
      if (!url || typeof url !== 'string') return false;
      
      try {
        const parsed = new URL(url);
        return parsed.hostname === 'discord.com' || parsed.hostname === 'discordapp.com';
      } catch {
        return false;
      }
    }

    // Parses and validates the SITES environment variable
    function parseSites(sitesJson) {
      if (!sitesJson) {
        throw new Error('SITES environment variable is required');
      }

      let sites;
      try {
        sites = JSON.parse(sitesJson);
      } catch (error) {
        throw new Error(`Invalid SITES JSON format: ${error.message}`);
      }

      if (!Array.isArray(sites) || sites.length === 0) {
        throw new Error('SITES must be a non-empty JSON array of URLs');
      }

      // Validate each URL
      sites.forEach(site => {
        if (typeof site !== 'string') {
          throw new Error(`Invalid site URL: ${site} (must be string)`);
        }
        try {
          new URL(site);
        } catch {
          throw new Error(`Invalid site URL format: ${site}`);
        }
      });

      return sites;
    }

    export const config = {
      discordWebhook: process.env.DISCORD_WEBHOOK,
      sites: parseSites(process.env.SITES),
      cron: process.env.CHECK_INTERVAL_CRON || '*/1 * * * *',
      alertBurst: parseInt(process.env.ALERT_BURST) || 3,
      alertWindowSec: parseInt(process.env.ALERT_WINDOW_SEC) || 300
    };
    ```

    **Rate Limiter (`lib/rate-limiter.js`)**
    ```js
    // Token bucket rate limiter with per-site isolation
    export function createRateLimiter({ burst, windowSec }) {
      const buckets = new Map()
      const refillRate = burst / (windowSec * 1000)

      function consume(siteUrl) {
        const bucket = getBucket(siteUrl)
        refillBucket(bucket)
        
        if (bucket.tokens >= 1) {
          bucket.tokens -= 1
          return true
        }
        
        return false
      }

      function getBucket(siteUrl) {
        if (!buckets.has(siteUrl)) {
          buckets.set(siteUrl, {
            tokens: burst,
            lastRefill: Date.now()
          })
        }
        return buckets.get(siteUrl)
      }

      function refillBucket(bucket) {
        const now = Date.now()
        const timePassed = now - bucket.lastRefill
        
        if (timePassed > 0) {
          const tokensToAdd = timePassed * refillRate
          bucket.tokens = Math.min(burst, bucket.tokens + tokensToAdd)
          bucket.lastRefill = now
        }
      }

      return { consume, /* other methods */ }
    }
    ```

    **Status Storage (`lib/streams.js`)**
    ```js
    // File-based persistent storage for site status
    import { readFileSync, writeFileSync, existsSync } from 'fs'

    const STORE_FILE = join(process.cwd(), '.motia', 'status-store.json')

    export function updateLastStatus(result) {
      // Validate input
      if (!result?.url || !['UP', 'DOWN'].includes(result.status)) {
        throw new Error('Invalid result object')
      }

      const store = loadStatusStore()
      store[result.url] = { ...result }
      saveStatusStore(store)
    }

    export function getPreviousStatus(url) {
      const store = loadStatusStore()
      const result = store[url]
      return result ? { ...result } : null
    }

    export function getSnapshot() {
      const store = loadStatusStore()
      const snapshot = {}
      
      for (const [url, result] of Object.entries(store)) {
        snapshot[url] = { ...result }
      }
      
      return snapshot
    }
    ```

  </Tab>
</Tabs>

---

## Explore the Workbench

The Motia Workbench provides a visual representation of your monitoring pipeline, making it easy to understand the event flow and debug issues in real-time.

<div className="my-8">![Uptime Monitor in Motia Workbench](./../img/uptime-monitor.gif)</div>

You can monitor real-time status checks, view Discord alert logs, and trace the execution of each step directly in the Workbench interface. This makes development and debugging significantly easier compared to traditional monitoring solutions.

---

## Key Features & Benefits

### ‚ö° **Event-Driven Architecture**
Each component is independent and communicates through events, making the system highly scalable and maintainable.

### üéØ **Smart Status Detection**  
Only triggers alerts when status actually changes (UP ‚Üî DOWN), eliminating noise from temporary fluctuations.

### üö® **Intelligent Rate Limiting**
Token bucket algorithm prevents alert spam during site flapping while ensuring critical alerts get through.

### üìä **Built-in Observability**
Comprehensive logging, health checks, and real-time status tracking with persistent storage.

### üîß **Production-Ready**
Robust error handling, timeout management, and configurable check intervals ensure reliability.

### üé® **Rich Discord Alerts**
Beautiful embedded messages with response times, error details, and status transitions.

---

## Data Flow & Event Architecture

![Uptime Monitor Event Flow](./../img/uptime-monitor-flow.png)

### Event Flow
1. **Cron Trigger** ‚Üí Emits `check.requested` events for each configured site
2. **Website Checker** ‚Üí Receives `check.requested`, performs HTTP check
3. **Status Update** ‚Üí Checker emits `check.result` with result
4. **Alert Processing** ‚Üí Alerter receives `check.result`, detects status changes
5. **Discord Notification** ‚Üí Alerter sends webhook if status changed and rate limit allows
6. **Status Storage** ‚Üí Status is persisted for health endpoint and future comparisons

---

## Trying It Out

Ready to build your own production-ready monitoring system? Let's get it running.

<Steps>

### Install Dependencies

Install the necessary npm packages and set up the development environment.

```shell
npm install
```

### Configure Environment Variables

Create a `.env` file with your monitoring configuration. You'll need a Discord webhook URL and the sites you want to monitor.

```shell
# Required: Discord webhook for alerts
DISCORD_WEBHOOK="https://discord.com/api/webhooks/123456789/your-webhook-token"

# Required: JSON array of URLs to monitor
SITES='["https://example.com", "https://api.yourdomain.com", "https://blog.yoursite.org"]'

# Optional: Check frequency (default: every minute)
CHECK_INTERVAL_CRON="*/1 * * * *"

# Optional: Rate limiting (default: 3 alerts per 5 minutes)
ALERT_BURST="3"
ALERT_WINDOW_SEC="300"
```

### Set Up Discord Webhook

Create a Discord webhook to receive alerts:

1. Go to your Discord server settings
2. Navigate to **Integrations** ‚Üí **Webhooks**
3. Click **New Webhook**
4. Copy the webhook URL and add it to your `.env` file

### Run the Monitoring System

Start the Motia development server to begin monitoring your websites.

```shell
npm run dev
```

### Check System Health

Verify your monitoring system is working correctly:

```shell
curl http://localhost:3000/healthz
```

You should see a response with your configured sites and their current status:

```json
{
  "status": "ok",
  "sitesConfigured": 3,
  "lastKnown": {
    "https://example.com": {
      "url": "https://example.com",
      "status": "UP",
      "code": 200,
      "responseTime": 245,
      "checkedAt": "2024-01-15T10:30:00.000Z",
      "error": null
    }
  },
  "now": "2024-01-15T10:35:00.000Z"
}
```

### Monitor the Logs

Watch the logs to see your monitoring system in action:

- **Cron triggers**: Check scheduling for all configured sites
- **Website checks**: HTTP requests and response analysis  
- **Status changes**: UP/DOWN transitions and Discord alerts
- **Rate limiting**: Alert suppression during site flapping

</Steps>

---

## Advanced Configuration

### Custom Check Intervals

Modify the cron expression to change monitoring frequency:

```shell
# Every 5 minutes
CHECK_INTERVAL_CRON="*/5 * * * *"

# Every hour
CHECK_INTERVAL_CRON="0 * * * *"

# Every 6 hours
CHECK_INTERVAL_CRON="0 */6 * * *"

# Business hours only (9 AM - 5 PM, Mon-Fri)
CHECK_INTERVAL_CRON="* 9-17 * * 1-5"
```

### Alert Rate Limiting

Fine-tune the rate limiting to match your needs:

```shell
# Very strict: 1 alert per 10 minutes
ALERT_BURST="1"
ALERT_WINDOW_SEC="600"

# More permissive: 5 alerts per 2 minutes
ALERT_BURST="5"  
ALERT_WINDOW_SEC="120"
```

### Multi-Environment Monitoring

Set up different monitoring configurations for different environments:

```shell
# Production sites
SITES='["https://app.production.com", "https://api.production.com"]'

# Staging sites  
SITES='["https://app.staging.com", "https://api.staging.com"]'

# Development sites
SITES='["https://app.dev.com", "http://localhost:8080"]'
```

### Custom Discord Alert Formatting

Modify the `createDiscordMessage` function in `alerter.step.js` to customize alert appearance:

```js
function createDiscordMessage(result, previousStatus) {
  const { url, status, code, responseTime } = result
  
  // Custom colors for your brand
  const color = status === 'UP' ? 0x2ecc71 : 0xe74c3c
  
  // Custom emoji and formatting
  const emoji = status === 'UP' ? '‚úÖ' : '‚ùå'
  const urgency = responseTime > 5000 ? 'üêå SLOW' : '‚ö° FAST'
  
  return {
    content: `${emoji} **${url}** is ${status}`,
    embeds: [{
      title: `${urgency} Website ${status}`,
      description: `**${url}** changed from ${previousStatus} to ${status}`,
      color,
      timestamp: result.checkedAt,
      fields: [
        {
          name: '‚è±Ô∏è Response Time',
          value: `${responseTime}ms`,
          inline: true
        },
        {
          name: 'üìä Status Code', 
          value: code?.toString() || 'N/A',
          inline: true
        }
      ]
    }]
  }
}
```

---

## Troubleshooting

### Common Issues

**Sites not being checked:**
- Verify `SITES` environment variable is valid JSON
- Check cron expression syntax using [crontab.guru](https://crontab.guru)
- Review logs for parsing errors

**Discord alerts not working:**
- Verify `DISCORD_WEBHOOK` URL is correct
- Test webhook manually: `curl -X POST $DISCORD_WEBHOOK -H "Content-Type: application/json" -d '{"content":"Test message"}'`
- Check Discord webhook permissions

**High memory usage:**
- Monitor status store size with health endpoint
- Consider implementing status history cleanup
- Reduce check frequency for many sites

**False positive alerts:**
- Increase timeout values in checker step
- Implement retry logic before marking as DOWN
- Adjust rate limiting to reduce noise

### Performance Tips

- **Large Site Lists**: Consider sharding across multiple instances
- **Slow Sites**: Implement custom timeout values per site
- **High Frequency**: Use Redis for status storage instead of file system
- **Alert Fatigue**: Implement escalation policies and alert grouping

### Monitoring the Monitor

Set up monitoring for your monitoring system:

```shell
# Monitor the health endpoint itself
curl -f http://localhost:3000/healthz || echo "Monitor is down!"

# Check for recent status updates
curl http://localhost:3000/healthz | jq '.lastKnown | to_entries | map(select(.value.checkedAt > (now - 300)))'

# Verify all sites are being checked
curl http://localhost:3000/healthz | jq '.sitesConfigured == (.lastKnown | length)'
```

---

## üíª Dive into the Code

Want to explore the complete monitoring implementation? Check out the full source code, including all steps, utilities, and configuration examples:

<div className="not-prose">
  <div className="bg-gradient-to-r from-green-50 to-emerald-50 border border-green-200 rounded-lg p-6 my-6">
    <div className="flex items-start space-x-4">
      <div className="flex-shrink-0">
        <svg className="w-8 h-8 text-green-600" fill="currentColor" viewBox="0 0 20 20">
          <path fillRule="evenodd" d="M12.316 3.051a1 1 0 01.633 1.265l-4 12a1 1 0 11-1.898-.632l4-12a1 1 0 011.265-.633zM5.707 6.293a1 1 0 010 1.414L3.414 10l2.293 2.293a1 1 0 11-1.414 1.414l-3-3a1 1 0 010-1.414l3-3a1 1 0 011.414 0zm8.586 0a1 1 0 011.414 0l3 3a1 1 0 010 1.414l-3 3a1 1 0 11-1.414-1.414L16.586 10l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
        </svg>
      </div>
      <div className="flex-1">
        <h3 className="text-lg font-semibold text-gray-900 mb-2">Complete Uptime Monitor</h3>
        <p className="text-gray-600 mb-4">Access the full implementation with event steps, utility libraries, Discord integration, and production-ready configuration.</p>
        <div className="flex flex-col sm:flex-row gap-3">
          <a 
            href="https://github.com/MotiaDev/motia-examples/tree/main/examples/motia-uptime-monitor" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-green-600 hover:bg-green-700 text-white font-medium rounded-md transition-colors duration-200"
          >
            <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 0C5.374 0 0 5.373 0 12 0 17.302 3.438 21.8 8.207 23.387c.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23A11.509 11.509 0 0112 5.803c1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576C20.566 21.797 24 17.3 24 12c0-6.627-5.373-12-12-12z"/>
            </svg>
            View Monitor Example
          </a>
          <a 
            href="https://github.com/MotiaDev/motia-examples" 
            target="_blank" 
            rel="noopener noreferrer"
            className="inline-flex items-center px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-800 font-medium rounded-md transition-colors duration-200"
          >
            More Examples ‚Üí
          </a>
        </div>
      </div>
    </div>
  </div>
</div>

---

## Conclusion: Monitoring That Actually Works

This uptime monitoring system demonstrates the power of event-driven architecture for infrastructure monitoring. By breaking down monitoring into discrete, specialized components, we've created a system that's not only reliable but also extensible and maintainable.

The event-driven approach means you can easily:
- **Add new notification channels** (Slack, PagerDuty, email) by creating new steps
- **Implement custom health checks** (database connectivity, API endpoints, SSL certificates)
- **Scale monitoring** across multiple regions or environments
- **Integrate with existing systems** without disrupting the core monitoring loop

Key architectural benefits:
- **Resilience**: Component failures don't bring down the entire system
- **Observability**: Built-in logging and tracing at every step
- **Flexibility**: Easy to modify check intervals, alert logic, or add new features
- **Testing**: Each component can be tested in isolation

From here, you can extend the system by:
- Adding support for different check types (TCP, database, custom health endpoints)
- Implementing escalation policies and on-call rotations
- Building a web dashboard for historical data and trends
- Adding integration with incident management systems
- Implementing multi-region monitoring with failover

The event-driven architecture makes all of these extensions straightforward to implement without disrupting the existing monitoring pipeline.

Ready to build monitoring infrastructure that scales with your business? Start building with Motia today!


-   [creating-your-first-rest-api](/docs/getting-started/build-your-first-app/creating-your-first-rest-api): Documentation for creating-your-first-rest-api.
---
title: API Endpoints
description: Learn how to build a complete REST API with CRUD operations using Motia. This guide covers HTTP endpoints, request validation, and response handling.
---
If you haven't already, follow the [Quick Start Guide](/docs/getting-started/quick-start) to create a Motia project. This tutorial assumes you have a working project with the development server running.

REST APIs are one of the fundamental foundations of most modern web architectures, especially for client-server communication. They allow clients to interact with your backend through standard HTTP methods like GET, POST, PUT, and DELETE. In Motia, creating APIs is straightforward, you define endpoints as API Steps.
This guide will walk you through building a complete REST API in Motia. You'll learn how to create HTTP endpoints, validate requests, handle responses, and implement full CRUD operations for a pet store application.

## REST API Concepts You'll Use

Before we start building, let's cover the key concepts for creating REST APIs in Motia:

- **API Step** ‚Äì A file that defines an HTTP endpoint with validation schemas and request handling logic.
- **HTTP Methods** ‚Äì GET (retrieve), POST (create), PUT (update), DELETE (remove) operations on resources.
- **Response Handling** ‚Äì Returning proper HTTP status codes and structured JSON responses.
- **Path Parameters** ‚Äì Dynamic URL segments like `/pets/:id` to identify specific resources.

## API Step Structure

Every API endpoint in Motia consists of two parts that work together:

| Component | Type | Description |
|-----------|------|-------------|
| **`ApiRouteConfig`** | `object` | Configuration object that defines the HTTP endpoint structure, including the path, method, and validation schemas. This is where you specify what your API endpoint looks like and how it validates requests. |
| **`Handlers[StepName]`** | `function` | The handler function that contains your business logic. It receives the HTTP request and returns an HTTP response with the appropriate status code and data. |

## Building a Pet Store REST API

Now that you understand the core parts of an API endpoint, let's build a complete REST API for a pet store.

We'll create a Pet Store API with full CRUD operations:
- `GET /pet` - List all pets
- `POST /pets` - Create a new pet
- `GET /pets/:id` - Get a specific pet by ID
- `PUT /pets/:id` - Update a pet's information
- `DELETE /pets/:id` - Remove a pet

This covers all the essential REST API patterns you'll use in real applications.

## Create Your First API Endpoint

Let's start by creating a simple endpoint to add new pets to our store.

### Creating the Add Pet API

We'll create a `POST /pets` endpoint that accepts pet information and stores it. This endpoint will demonstrate key REST API concepts like request validation and response handling.

Create a new file for your first endpoint:

**File:** `steps/create-pet.step.ts`

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'CreatePet',
      description: 'Create a new pet in the store',
      method: 'POST',
      path: '/pets',
      
      bodySchema: z.object({
        name: z.string(),
        breed: z.string(),
        age: z.number(),
      }),

      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
      },
    }

    export const handler: Handlers['CreatePet'] = async (req, { logger }) => {
      logger.info('Creating new pet', { body: req.body })

      // In a real app, you will save to a database
      const newPet = {
        id: Date.now().toString(),
        ...req.body,
      }

      return {
        status: 200,
        body: newPet,
      }
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'CreatePet',
      description: 'Create a new pet in the store',
      method: 'POST',
      path: '/pets',
      
      bodySchema: z.object({
        name: z.string(),
        breed: z.string(),
        age: z.number(),
      }),

      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
      },
    }

    exports.handler = async (req, { logger }) => {
      logger.info('Creating new pet', { body: req.body })

      // In a real app, you will save to a database
      const newPet = {
        id: Date.now().toString(),
        ...req.body,
      }

      return {
        status: 200,
        body: newPet,
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel
    import time

    class PetRequest(BaseModel):
        name: str
        breed: str
        age: int

    class PetResponse(BaseModel):
        id: str
        name: str
        breed: str
        age: int

    config = {
        'type': 'api',
        'name': 'CreatePet',
        'description': 'Create a new pet in the store',
        'method': 'POST',
        'path': '/pets',
        'bodySchema': PetRequest.model_json_schema(),
        'responseSchema': {
            '200': PetResponse.model_json_schema()
        }
    }

    async def handler(req, context):
        context.logger.info('Creating new pet', {'body': req.get('body')})
        
        # In a real app, you will save to a database
        new_pet = {
            'id': str(int(time.time() * 1000)),
            **req.get('body')
        }
        
        return {
            'status': 200,
            'body': new_pet
        }
    ```
  </Tab>
</Tabs>

The most fundamental part of any API endpoint is defining what HTTP method it accepts and where it lives:

```typescript
method: 'POST',
path: '/pets',
```
This configuration tells Motia to create a POST endpoint at /pets. When your development server is running, users can send requests to http://localhost:3000/pets to create new pets. The POST method is the standard HTTP method for creating new resources in REST APIs.

![Pet Creation](./../../img/pet-creation.png)

##  Adding More CRUD Operations

Now that we have a working POST endpoint, let's build out the complete REST API with all CRUD operations. We'll add endpoints to retrieve, update, and delete pets.

### Get All Pets - `GET /pets`

Create a new file to list all pets in the store:

**File:** `steps/get-pets.step.ts`

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'GetPets',
      description: 'Get all pets in the store',
      method: 'GET',
      path: '/pets',
      
      responseSchema: {
        200: z.array(z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        })),
      },
    }

    export const handler: Handlers['GetPets'] = async (req, { logger }) => {
      logger.info('Retrieving all pets')

      // In a real app, you'd fetch from a database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      return {
        status: 200,
        body: pets,
      }
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'GetPets',
      description: 'Get all pets in the store',
      method: 'GET',
      path: '/pets',
      
      responseSchema: {
        200: z.array(z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        })),
      },
    }

    exports.handler = async (req, { logger }) => {
      logger.info('Retrieving all pets')

      // In a real app, you'd fetch from a database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      return {
        status: 200,
        body: pets,
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel
    from typing import List

    class PetResponse(BaseModel):
        id: str
        name: str
        breed: str
        age: int

    config = {
        'type': 'api',
        'name': 'GetPets',
        'description': 'Get all pets in the store',
        'method': 'GET',
        'path': '/pets',
        'responseSchema': {
            '200': {
                'type': 'array',
                'items': PetResponse.model_json_schema()
            }
        }
    }

    async def handler(req, context):
        context.logger.info('Retrieving all pets')
        
        # In a real app, you'd fetch from a database
        pets = [
            {'id': '1', 'name': 'Buddy', 'breed': 'Golden Retriever', 'age': 3},
            {'id': '2', 'name': 'Max', 'breed': 'German Shepherd', 'age': 5},
        ]
        
        return {
            'status': 200,
            'body': pets
        }
    ```
  </Tab>
</Tabs>

![Get All Pets](./../../img/get-all-pets.png)

### Get Pet by ID - `GET /pets/:id`

Create a new file to retrieve a specific pet:

**File:** `steps/get-pet-by-id.step.ts`

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'GetPetById',
      description: 'Get a specific pet by ID',
      method: 'GET',
      path: '/pets/:id',
      
      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    export const handler: Handlers['GetPetById'] = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Retrieving pet by ID', { petId })

      // In a real app, you'd search your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const pet = pets.find(p => p.id === petId)

      if (!pet) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      return {
        status: 200,
        body: pet,
      }
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'GetPetById',
      description: 'Get a specific pet by ID',
      method: 'GET',
      path: '/pets/:id',
      
      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    exports.handler = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Retrieving pet by ID', { petId })

      // In a real app, you'd search your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const pet = pets.find(p => p.id === petId)

      if (!pet) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      return {
        status: 200,
        body: pet,
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel

    class PetResponse(BaseModel):
        id: str
        name: str
        breed: str
        age: int

    class ErrorResponse(BaseModel):
        error: str

    config = {
        'type': 'api',
        'name': 'GetPetById',
        'description': 'Get a specific pet by ID',
        'method': 'GET',
        'path': '/pets/:id',
        'responseSchema': {
            '200': PetResponse.model_json_schema(),
            '404': ErrorResponse.model_json_schema()
        }
    }

    async def handler(req, context):
        pet_id = req.get('pathParams', {}).get('id')
        context.logger.info('Retrieving pet by ID', {'petId': pet_id})
        
        # In a real app, you'd search your database
        pets = [
            {'id': '1', 'name': 'Buddy', 'breed': 'Golden Retriever', 'age': 3},
            {'id': '2', 'name': 'Max', 'breed': 'German Shepherd', 'age': 5},
        ]
        
        pet = next((p for p in pets if p['id'] == pet_id), None)
        
        if not pet:
            return {
                'status': 404,
                'body': {'error': 'Pet not found'}
            }
        
        return {
            'status': 200,
            'body': pet
        }
    ```
  </Tab>
</Tabs>
![Get One Pet](./../../img/get-one-pet.png)

### Update Pet - `PUT /pets/:id`

Create a new file to update existing pets:

**File:** `steps/update-pet.step.ts`

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'UpdatePet',
      description: 'Update a pet by ID',
      method: 'PUT',
      path: '/pets/:id',
      
      bodySchema: z.object({
        name: z.string(),
        breed: z.string(),
        age: z.number(),
      }),

      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    export const handler: Handlers['UpdatePet'] = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Updating pet', { petId, body: req.body })

      // In a real app, you'd update your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const petIndex = pets.findIndex(p => p.id === petId)

      if (petIndex === -1) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      const updatedPet = {
        id: petId,
        ...req.body,
      }

      return {
        status: 200,
        body: updatedPet,
      }
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'UpdatePet',
      description: 'Update a pet by ID',
      method: 'PUT',
      path: '/pets/:id',
      
      bodySchema: z.object({
        name: z.string(),
        breed: z.string(),
        age: z.number(),
      }),

      responseSchema: {
        200: z.object({
          id: z.string(),
          name: z.string(),
          breed: z.string(),
          age: z.number(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    exports.handler = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Updating pet', { petId, body: req.body })

      // In a real app, you'd update your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const petIndex = pets.findIndex(p => p.id === petId)

      if (petIndex === -1) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      const updatedPet = {
        id: petId,
        ...req.body,
      }

      return {
        status: 200,
        body: updatedPet,
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel

    class PetRequest(BaseModel):
        name: str
        breed: str
        age: int

    class PetResponse(BaseModel):
        id: str
        name: str
        breed: str
        age: int

    class ErrorResponse(BaseModel):
        error: str

    config = {
        'type': 'api',
        'name': 'UpdatePet',
        'description': 'Update a pet by ID',
        'method': 'PUT',
        'path': '/pets/:id',
        'bodySchema': PetRequest.model_json_schema(),
        'responseSchema': {
            '200': PetResponse.model_json_schema(),
            '404': ErrorResponse.model_json_schema()
        }
    }

    async def handler(req, context):
        pet_id = req.get('pathParams', {}).get('id')
        context.logger.info('Updating pet', {'petId': pet_id, 'body': req.get('body')})
        
        # In a real app, you'd update your database
        pets = [
            {'id': '1', 'name': 'Buddy', 'breed': 'Golden Retriever', 'age': 3},
            {'id': '2', 'name': 'Max', 'breed': 'German Shepherd', 'age': 5},
        ]
        
        pet_index = next((i for i, p in enumerate(pets) if p['id'] == pet_id), -1)
        
        if pet_index == -1:
            return {
                'status': 404,
                'body': {'error': 'Pet not found'}
            }
        
        updated_pet = {
            'id': pet_id,
            **req.get('body')
        }
        
        return {
            'status': 200,
            'body': updated_pet
        }
    ```
  </Tab>
</Tabs>

### Delete Pet - `DELETE /pets/:id`

Create a new file to remove pets from the store:

**File:** `steps/delete-pet.step.ts`

<Tabs items={['TS', 'JS', 'Python']}>
  <Tab value="TS">
    ```typescript
    import { ApiRouteConfig, Handlers } from 'motia'
    import { z } from 'zod'

    export const config: ApiRouteConfig = {
      type: 'api',
      name: 'DeletePet',
      description: 'Delete a pet by ID',
      method: 'DELETE',
      path: '/pets/:id',
      
      responseSchema: {
        200: z.object({
          message: z.string(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    export const handler: Handlers['DeletePet'] = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Deleting pet', { petId })

      // In a real app, you'd remove from your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const petExists = pets.some(p => p.id === petId)

      if (!petExists) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      return {
        status: 200,
        body: { message: `Pet with ID ${petId} has been deleted` },
      }
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const { z } = require('zod')

    exports.config = {
      type: 'api',
      name: 'DeletePet',
      description: 'Delete a pet by ID',
      method: 'DELETE',
      path: '/pets/:id',
      
      responseSchema: {
        200: z.object({
          message: z.string(),
        }),
        404: z.object({
          error: z.string(),
        }),
      },
    }

    exports.handler = async (req, { logger }) => {
      const petId = req.pathParams.id
      logger.info('Deleting pet', { petId })

      // In a real app, you'd remove from your database
      const pets = [
        { id: "1", name: "Buddy", breed: "Golden Retriever", age: 3 },
        { id: "2", name: "Max", breed: "German Shepherd", age: 5 },
      ]

      const petExists = pets.some(p => p.id === petId)

      if (!petExists) {
        return {
          status: 404,
          body: { error: 'Pet not found' },
        }
      }

      return {
        status: 200,
        body: { message: `Pet with ID ${petId} has been deleted` },
      }
    }
    ```
  </Tab>
  <Tab value="Python">
    ```python
    from pydantic import BaseModel

    class DeleteResponse(BaseModel):
        message: str

    class ErrorResponse(BaseModel):
        error: str

    config = {
        'type': 'api',
        'name': 'DeletePet',
        'description': 'Delete a pet by ID',
        'method': 'DELETE',
        'path': '/pets/:id',
        'responseSchema': {
            '200': DeleteResponse.model_json_schema(),
            '404': ErrorResponse.model_json_schema()
        }
    }

    async def handler(req, context):
        pet_id = req.get('pathParams', {}).get('id')
        context.logger.info('Deleting pet', {'petId': pet_id})
        
        # In a real app, you'd remove from your database
        pets = [
            {'id': '1', 'name': 'Buddy', 'breed': 'Golden Retriever', 'age': 3},
            {'id': '2', 'name': 'Max', 'breed': 'German Shepherd', 'age': 5},
        ]
        
        pet_exists = any(p['id'] == pet_id for p in pets)
        
        if not pet_exists:
            return {
                'status': 404,
                'body': {'error': 'Pet not found'}
            }
        
        return {
            'status': 200,
            'body': {'message': f'Pet with ID {pet_id} has been deleted'}
        }
    ```
  </Tab>
</Tabs>

![Delete One Pet](./../../img/delete-pet.png)

## Testing the Complete REST API
You now have a full CRUD REST API. Here are all the endpoints you can test:

- `POST /pets` - Create a new pet
- `GET /pets` - List all pets
- `GET /pets/:id` - Get a specific pet
- `PUT /pets/:id` - Update a pet
- `DELETE /pets/:id` - Delete a pet

You can test each endpoint using the Workbench interface or with curl commands. This covers all the essential patterns you'll need for building REST APIs.

-   [quick-start](/docs/getting-started/quick-start): Documentation for quick-start.
---
title: Quick Start
description: Get up and running with a new Motia project in just a few seconds.
---
<Steps>

<Step>
### 1. Create Your Project

Use `npx` to create a new Motia project. This single command will scaffold a new application and install all necessary dependencies.

```bash
npx motia@latest create -i
```

![Create App Command](/docs-images/motia-build-your-app-1.gif)

The installer will guide you through a few questions to set up your project. Once it's done, you will have a new project directory ready to go.

</Step>

<Step>
### 2. Start the Development Server

Navigate into your new project directory and start the Motia development server.

```bash
cd <your-project-name> # If you've created a new folder for the project, navigate into it

npx motia dev
```

![run dev command](/docs-images/motia-build-your-app-2.png)

<Callout>
The `create` command uses `npm` by default. If you chose a different package manager during setup, use `pnpm dev`, `yarn dev`, or `bun dev`.
</Callout>

This command starts the Motia runtime and the Workbench, a powerful UI for developing and debugging your workflows. By default, it's available at [`http://localhost:3000`](http://localhost:3000).

</Step>

<Step>
### 3. Run Your First Flow

The starter project comes with a pre-built `default` flow. Let's run it.

1.  **Open the Workbench** in your browser at [`http://localhost:3000`](http://localhost:3000).
2.  **Select the `default` flow** from the left top panel.
3.  **Run the flow.** You'll see a visual diagram of the workflow. Find the first node (the API Step) and click the **Start** button on it. This will trigger the flow.
4.  **Observe the execution.** Watch the trace unfold in real-time in the bottom panel. You can inspect the logs, traces and state for each step as it completes.
5.  **Explore the Workbench.** You can also read your files directly from the Workbench.

![run starter app](/docs-images/motia-build-your-app.gif)

</Step>

<Step>
### Next Steps

Congratulations! You've successfully created, run, and observed your first Motia workflow.

- To build a multi-language application from scratch, follow our **[Multi-Language Data Processing](/docs/examples/multi-language-data-processing)** guide.
- To learn how to build REST APIs with Motia, check out our **[Creating Your First REST API](/docs/getting-started/build-your-first-app/creating-your-first-rest-api)** guide.
- To learn about Motia, dive into our **[Welcome to Motia](/docs)**.

</Step>
</Steps>


-   [index](/docs/): Documentation for index.
---
title: Welcome to Motia
description: Motia is an all-in-one framework for modern backend systems. Out of the box support for API endpoints, background jobs, scheduled tasks and agentic workflow orchestration through a unified runtime. Thanks to its event driven architecture you can run tasks in parallel, stream data to clients, or allow for seamless orchestration of flows. What used to take 5 frameworks to build now comes out of the box with Motia.
---

## Why use Motia

Today, backend engineers and software architects face several recurring problems. Motia was created to simplify these common backend engineering challenges in a flexible and elegant way to provide world class developer experience while ensuring robust, event-driven infrastructure.

- Unified vs. Fragmented backend
  - Working with multiple Languages
- Scalability
- Observability
- Fault tolerance
- Building and shipping
  - Rollbacks and deployment strategies
- Real-time data streaming

## How Motia simplifies all of this?

Similar to how React simplified frontend development where everything is a component, Motia simplifies backend development where everything is a Step. In Motia, every backend pattern becomes a group of compensable steps with unified state, events and observability. In this way, engineers only have to learn a few concepts about how a Motia Step works, and they get an enterprise-grade event-driven system out of the box.

- Steps represent a distinct entry point
- Steps can have different triggers
  - API Call _(Triggered by an HTTP request)_
  - Event _(Triggered by an event from another Step)_
  - CRON Job _(Triggered by a cron schedule)_
  - More will come soon (Check the [Roadmap](https://github.com/orgs/MotiaDev/projects/2?pane=issue&itemId=121129696&issue=MotiaDev%7Cmotia%7C477))
- Steps are composable and can be chained together

![Motia](./img/what-is-motia/motia.gif)

## Unified vs. Fragmented backend

Modern software engineering is splintered. APIs live in one framework, background jobs in another, queues have their own tooling, and AI agents are springing up in yet more isolated runtimes. Motia exists to unify all of these concerns API endpoints, automations & workflows, background tasks, queues, and AI agents into a single, coherent system with shared observability and developer experience.

To read more about this, check out our [manifesto](/manifesto).

### Working with multiple Languages

The rapid advancement of AI has reshaped the software industry‚Äîmany cutting-edge AI tools are available only in specific programming languages, this forces companies to decide if they either change their team's skillset to a different language or not leveraging these technologies at all.

Motia removes this limitation by allowing each Step to be written in any language, while still sharing a common state.

![Multi-language](./img/what-is-motia/multi-language.png)

_Each rectangle in the diagram above represents a Step, some of them are in TypeScript and others in Python._

## Scalability

One of the biggest dilemmas in backend development is choosing between scalability and development velocity. In startup environments, speed often takes priority, resulting in systems that don't scale well and become problematic under increased load.

Motia addresses scalability by leveraging the core primitive of **Steps**: Each step can scale independently avoiding the bottlenecks common in monolithic architectures.

![Scalable](./img/what-is-motia/scalable.png)

## Observability

Observability in traditional backends often demands significant engineering effort to implement logging, alerting, and tracing. Typically, these tools are only configured for cloud environments, local development is generally neglected‚Äîleading to low productivity and poor dev experience.

Motia offers a complete observability toolkit available in both cloud and local environments, including:

- Logs visualization
- Tracing tool to quickly visualize the flow of requests through the system
- State visualization
- Diagram representation of dependencies between steps and how they are connected

_The image below shows the Workbench interface available when you run `motia dev`. On the top panel you can see a workflow diagram with multiple steps connected.
On the bottom panel you can see the trace view of a single request and what happened in each step._

![Motia Workbench](./img/new-workbench.png)

## Fault tolerance

With the rise of AI, many backend tasks have become less deterministic and more error-prone. These scenarios require robust error handling and retry mechanisms. In traditional systems, developers often need to set up and maintain queue infrastructures to ensure resilience, especially when dealing with unreliable responses from LLMs.

Motia provides fault tolerance out of the box, eliminating the need to manually spin up queue infrastructure.

- Using Event Steps, you get retry mechanisms out of the box
- Configuration of queue infrastructure is abstracted away

## Building and Shipping

Building and deploying backends is inherently complex‚Äîespecially in polyglot environments. Shipping production systems requires tight collaboration between developers and operations, and automation often takes weeks to get right.

Beyond that, cloud provider lock-in, complicated deployment strategies (e.g., rollbacks, blue/green deployments), and a lack of deployment tooling increase the risk of failure.

Motia abstracts these concerns by providing:

- True cloud-provider agnosticism
- Atomic blue/green deployments and one-click rollbacks via Motia Cloud (canary support coming soon)
- First-class polyglot backend support (currently Node.js and Python, with more on the way)

![Deployments](./img/what-is-motia/deployments.png)

_The image above shows several Steps being build to a single Motia deployable that are ultimately deployed to a cloud provider of your choice. 
Currently we're supporting AWS and Kubernetes, more Cloud providers coming soon. Check our [roadmap](https://github.com/orgs/MotiaDev/projects/2/views/4?filterQuery=title%3A+BYOC) for more details._

### Rollbacks and deployment strategies

Deploying cloud-native, fault-tolerant applications often involves modifying queue systems and other infrastructure components. 
These changes can introduce incompatibilities and lead to runtime failures.

Motia Cloud solves this with **Atomic Deployments**, which:

- Each deployment spins up a new isolated service that shares the same data layer
- Ensures safe, rollback-capable deployments without risking service downtime
- Instant rollbacks with one click since each deployment is isolated

## Real-time data streaming

Handling real-time data is one of the most common‚Äîand complex‚Äîchallenges in backend development. It's necessary when building event-driven applications, 
and it typically requires setting up and maintaining a significant amount of infrastructure.

Motia provides what we call _Streams_: Developers define the structure of the data‚Äîany changes to these objects are streamed to all subscribed clients in real-time.

![Real-time data streaming](./img/what-is-motia/streams.png)

_The image above shows a Stream definition, a Node.js Step mutating the data and a client subscribing to the stream receiving real-time updates._

-   [project-structure](/docs/project-structure): Documentation for project-structure.
---
title: Project Structure
description: Learn about Motia's project structure, file organization, and automatic step discovery system for building scalable workflow applications.
---

# Project Structure

Understanding how to organize your Motia project is crucial for building maintainable and scalable workflow applications. This guide covers the directory structure, file naming conventions, and Motia's automatic step discovery system.

## Basic Project Structure

Here's what a typical Motia project looks like:

<Folder name="my-motia-project" defaultOpen>
  <Folder name="steps" defaultOpen>
    <File name="01-api-gateway.step.ts" />
    <File name="02-data-processor.step.py" />  
    <File name="03-send-notification.step.js" />
    <File name="custom-ui.step.tsx" />
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
  <File name="types.d.ts" />
  <File name="motia-workbench.json" />
  <File name="config.yml" />
</Folder>

### File Descriptions

| File | Purpose | Type | Auto-Generated |
|------|---------|------|----------------|
| `01-api-gateway.step.ts` | TypeScript API endpoint | User Code | - |
| `02-data-processor.step.py` | Python data processing | User Code | - |
| `03-send-notification.step.js` | JavaScript automation | User Code | - |
| `custom-ui.step.tsx` | Optional UI component | User Code | - |
| `package.json` | Node.js dependencies (if using JS/TS) | Config | - |
| `requirements.txt` | Python dependencies (if using Python) | Config | - |
| `tsconfig.json` | TypeScript config (if using TypeScript) | Config | - |
| `types.d.ts` | **Type definitions for your project** | **Generated** | **‚úÖ By TypeScript** |
| `motia-workbench.json` | **ü§ñ Visual workflow positioning** | **Generated** | **‚úÖ By Motia** |
| `config.yml` | Optional Motia configuration | Config | - |

<Callout type="info">
The `steps/` directory is the heart of your Motia application - this is where all your workflow logic lives. Motia automatically discovers and registers any file following the naming pattern.
</Callout>

## Automatic Step Discovery

<Callout type="default">
**Key Concept: Automatic Discovery** 

Motia will automatically discover and register **any file** that follows the `.step.` naming pattern as a workflow step. You don't need to manually register steps - just create a file with the right naming pattern and Motia will find it.
</Callout>

### Discovery Rules

Motia scans your `steps/` directory and automatically registers files as steps based on these rules:

1. **File must contain `.step.` or `_step.` in the filename** (e.g., `my-task.step.ts`, `my_task_step.py`)
2. **File must export a `config` object** defining the step configuration
3. **File must export a `handler` function** containing the step logic
4. **File extension determines the runtime** (`.ts` = TypeScript, `.py` = Python, `.js` = JavaScript)

When you run `motia dev`, Motia will:
- Scan the `steps/` directory recursively
- Find all files matching `*.step.*`
- Parse their `config` exports to understand step types and connections
- Register them in the workflow engine
- Make them available in the Workbench

## File Naming Convention

Motia uses this specific pattern for automatic step discovery:

```
[prefix-]descriptive-name.step.[extension]
```

<Callout type="warning">
The `.step.` part in the filename is **required** - this is how Motia identifies which files are workflow steps during automatic discovery.
</Callout>

### Supported Languages & Extensions

| Language | Extension | Example Step File | Runtime |
|----------|-----------|-------------------|---------|
| **TypeScript** | `.ts` | `user-registration.step.ts` | Node.js with TypeScript |
| **Python** | `.py` | `data-analysis.step.py` | Python interpreter |
| **JavaScript** | `.js` | `send-notification.step.js` | Node.js |

### Naming Examples by Step Type

| Step Type | TypeScript | Python | JavaScript |
|-----------|------------|---------|-----------|
| **API Endpoint** | `01-auth-api.step.ts` | `01-auth-api.step.py` or `auth_api_step.py` | `01-auth-api.step.js` |
| **Event Handler** | `process-order.step.ts` | `process-order.step.py` or `process_order_step.py` | `process-order.step.js` |
| **Cron Job** | `daily-report.step.ts` | `daily-report.step.py` or `daily_report_step.py` | `daily-report.step.js` |
| **Data Processing** | `transform-data.step.ts` | `ml-analysis.step.py` or `ml_analysis_step.py` | `data-cleanup.step.js` |

## Step Organization Patterns

<Tabs items={["Sequential", "Feature-Based", "Language-Specific"]}>
<Tab value="Sequential">

### Sequential Flow Organization
Perfect for linear workflows where order matters:

<Folder name="steps" defaultOpen>
  <File name="01-api-start.step.ts" />
  <File name="02-validate-data.step.py" />
  <File name="03-process-payment.step.js" />
  <File name="04-send-confirmation.step.ts" />
  <File name="05-cleanup.step.py" />
</Folder>

| Step | Language | Purpose |
|------|----------|---------|
| `01-api-start.step.ts` | TypeScript | API endpoint |
| `02-validate-data.step.py` | Python | Data validation |
| `03-process-payment.step.js` | JavaScript | Payment processing |
| `04-send-confirmation.step.ts` | TypeScript | Email service |
| `05-cleanup.step.py` | Python | Cleanup tasks |

</Tab>
<Tab value="Feature-Based">

### Feature-Based Organization
Organize by business domains for complex applications:

<Folder name="steps" defaultOpen>
  <Folder name="authentication" defaultOpen>
    <File name="login.step.ts" />
    <File name="verify-token.step.py" />
    <File name="logout.step.js" />
  </Folder>
  <Folder name="payment" defaultOpen>
    <File name="process-payment.step.ts" />
    <File name="fraud-detection.step.py" />
    <File name="webhook.step.js" />
  </Folder>
  <Folder name="notification" defaultOpen>
    <File name="email.step.py" />
    <File name="sms.step.js" />
    <File name="push.step.ts" />
  </Folder>
</Folder>

**Benefits:**
- Logical grouping by business domain
- Easy to locate related functionality
- Team ownership by feature area
- Independent scaling and deployment

</Tab>
<Tab value="Language-Specific">

### Language-Specific Organization
Group by programming language for team specialization:

<Folder name="steps" defaultOpen>
  <Folder name="typescript" defaultOpen>
    <File name="api-gateway.step.ts" />
    <File name="user-management.step.ts" />
    <File name="data-validation.step.ts" />
  </Folder>
  <Folder name="python" defaultOpen>
    <File name="ml-processing.step.py" />
    <File name="data-analysis.step.py" />
    <File name="image-processing.step.py" />
  </Folder>
  <Folder name="javascript" defaultOpen>
    <File name="automation.step.js" />
    <File name="webhook-handlers.step.js" />
    <File name="integrations.step.js" />
  </Folder>
</Folder>

**Benefits:**
- Team specialization by language
- Consistent tooling and patterns
- Easy onboarding for language experts
- Shared libraries and utilities

</Tab>
</Tabs>

## Language-Specific Configuration

### TypeScript/JavaScript Projects

For Node.js-based steps, you'll need:

```json title="package.json"
{
  "name": "my-motia-app",
  "version": "1.0.0",
  "scripts": {
    "dev": "motia dev",
    "build": "motia build",
    "start": "motia start"
  },
  "dependencies": {
    "motia": "^0.5.12-beta.121",
    "zod": "^3.24.4"
  },
  "devDependencies": {
    "typescript": "^5.7.3",
    "@types/node": "^20.0.0"
  }
}
```

```json title="tsconfig.json (for TypeScript)"
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "ESNext",
    "moduleResolution": "Node",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true
  },
  "include": ["**/*.ts", "**/*.tsx"],
  "exclude": ["node_modules", "dist"]
}
```

### Python Projects

For Python-based steps:

```text title="requirements.txt"
# Core Motia dependency
motia>=0.5.12

# Common dependencies
requests>=2.28.0
pydantic>=1.10.0

# Data processing (if needed)
pandas>=1.5.0
numpy>=1.21.0
```

## Step Discovery Examples

Let's see how Motia discovers different step types:

### Example 1: TypeScript API Step

```typescript title="steps/user-api.step.ts"
import { ApiRouteConfig, Handlers } from 'motia'
import { z } from 'zod'

// Motia discovers this file because:
// 1. Filename contains '.step.'
// 2. Exports 'config' object
// 3. Has .ts extension -> uses TypeScript runtime
export const config: ApiRouteConfig = {
  type: 'api',
  name: 'user-api',
  path: '/users',
  method: 'GET',
  emits: ['users.fetched'],
  flows: ['user-management']
}

export const handler: Handlers['user-api'] = async (req, { emit }) => {
  await emit({
    topic: 'users.fetched', 
    data: { users: [] }
  })
  
  return {
    status: 200,
    body: { message: 'Users retrieved' }
  }
}
```

### Example 2: Python Event Step

```python title="steps/data-processor.step.py"
# Motia discovers this file because:
# 1. Filename contains '.step.'  
# 2. Exports 'config' dict
# 3. Has .py extension -> uses Python runtime

config = {
    "type": "event",
    "name": "data-processor",
    "description": "Process incoming data with Python",
    "subscribes": ["users.fetched"],
    "emits": ["data.processed"],
    "flows": ["user-management"]
}

async def handler(input_data, ctx):
    """Process the data"""
    processed_data = {
        "original": input_data,
        "processed_at": ctx.utils.dates.now().isoformat(),
        "count": len(input_data.get("users", []))
    }
    
    await ctx.emit({
        "topic": "data.processed",
        "data": processed_data
    })
```

### Example 3: JavaScript Automation Step

```javascript title="steps/send-notifications.step.js"
// Motia discovers this file because:
// 1. Filename contains '.step.'
// 2. Exports 'config' object  
// 3. Has .js extension -> uses Node.js runtime

export const config = {
  type: 'event',
  name: 'send-notifications',
  description: 'Send notifications via multiple channels',
  subscribes: ['data.processed'],
  emits: ['notifications.sent'],
  flows: ['user-management']
}

export const handler = async (input, { emit, logger }) => {
  logger.info('Sending notifications', { data: input })
  
  // Send email, SMS, push notifications, etc.
  const results = await Promise.all([
    sendEmail(input),
    sendSMS(input),
    sendPush(input)
  ])
  
  await emit({
    topic: 'notifications.sent',
    data: { 
      results,
      sent_at: new Date().toISOString() 
    }
  })
}

async function sendEmail(data) { /* implementation */ }
async function sendSMS(data) { /* implementation */ }  
async function sendPush(data) { /* implementation */ }
```

## Auto-Generated Files

Some files in your Motia project are automatically generated:

- `types.d.ts` - TypeScript generates this for type definitions
- `motia-workbench.json` - Motia manages visual node positions in the Workbench

## Multi-Language Project Example

Here's a real-world example showing how the three languages work together:

<Folder name="ecommerce-platform" defaultOpen>
  <Folder name="steps" defaultOpen>
    <Folder name="api" defaultOpen>
      <File name="product-catalog.step.ts" />
      <File name="user-auth.step.ts" />
      <File name="order-management.step.ts" />
    </Folder>
    <Folder name="processing" defaultOpen>
      <File name="inventory-sync.step.py" />
      <File name="recommendation.step.py" />
      <File name="fraud-detection.step.py" />
    </Folder>
    <Folder name="automation" defaultOpen>
      <File name="email-campaigns.step.js" />
      <File name="order-fulfillment.step.js" />
      <File name="customer-support.step.js" />
    </Folder>
    <Folder name="integrations" defaultOpen>
      <File name="payment-webhook.step.ts" />
      <File name="warehouse-sync.step.py" />
      <File name="social-media.step.js" />
    </Folder>
  </Folder>
  <File name="package.json" />
  <File name="requirements.txt" />
  <File name="tsconfig.json" />
  <File name="config.yml" />
</Folder>

### Architecture Breakdown

| Layer | Language | Purpose | Examples |
|-------|----------|---------|----------|
| **API Layer** | TypeScript | Fast API responses, type safety | Product catalog, user auth, order management |
| **Processing Layer** | Python | Data processing, ML, analytics | Inventory sync, recommendations, fraud detection |
| **Automation Layer** | JavaScript | Business automation, workflows | Email campaigns, fulfillment, customer support |
| **Integration Layer** | Multi-language | External system connections | Payment webhooks, ERP sync, social media |

## Language Strengths & When to Use

| Language | Best For | Common Step Types | Example Use Cases |
|----------|----------|-------------------|------------------|
| **TypeScript** | API endpoints, type safety, web integrations | API, Event, UI | REST APIs, webhooks, data validation |
| **Python** | Data science, ML, automation, integrations | Event, Cron | Data analysis, AI models, file processing |
| **JavaScript** | Automation, integrations, general scripting | Event, Cron | Email automation, webhooks, social media |

## Discovery Troubleshooting

If Motia isn't discovering your steps:

### Common Issues

<Tabs items={["Filename Issues", "Export Issues", "Location Issues"]}>
<Tab value="Filename Issues">

**Missing `.step.` in filename**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
‚ùå **Won't be discovered:**
<Folder name="steps" defaultOpen>
  <File name="user-handler.ts" />
  <File name="data-processor.py" />
  <File name="webhook.js" />
</Folder>
</div>
<div>
‚úÖ **Will be discovered:**
<Folder name="steps" defaultOpen>
  <File name="user-handler.step.ts" />
  <File name="data-processor.step.py" />
  <File name="webhook.step.js" />
</Folder>
</div>
</div>

</Tab>
<Tab value="Export Issues">

**Missing config export**

```typescript title="‚ùå Won't be discovered"
// No config export
export const handler = async () => {
  console.log('This won't be found by Motia')
}
```

```typescript title="‚úÖ Will be discovered"
// Proper exports
export const config = {
  type: 'event',
  name: 'my-step',
  subscribes: ['my-topic'],
  emits: ['my-output'],
  flows: ['my-flow']
}

export const handler = async (input, ctx) => {
  // Motia will discover and register this step
}
```

</Tab>
<Tab value="Location Issues">

**File outside steps/ directory**

<div className="grid grid-cols-1 md:grid-cols-2 gap-4">
<div>
‚ùå **Won't be discovered:**
<Folder name="project-root" defaultOpen>
  <Folder name="src">
    <File name="user-handler.step.ts" />
  </Folder>
  <Folder name="lib">
    <File name="processor.step.py" />
  </Folder>
</Folder>
</div>
<div>
‚úÖ **Will be discovered:**
<Folder name="project-root" defaultOpen>
  <Folder name="steps" defaultOpen>
    <File name="user-handler.step.ts" />
    <File name="processor.step.py" />
  </Folder>
</Folder>
</div>
</div>

</Tab>
</Tabs>

### Discovery Verification

Check if your steps are discovered:

```bash
# Run Motia in development mode
motia dev

# Look for discovery logs:
# ‚úÖ Discovered step: user-api (TypeScript)
# ‚úÖ Discovered step: data-processor (Python)  
# ‚úÖ Discovered step: send-notifications (JavaScript)
```

## Next Steps

Now that you understand how Motia discovers and organizes steps:

- Learn about [Core Concepts](/docs/concepts) to understand how steps work together
- Explore [Defining Steps](/docs/concepts/steps/defining-steps) for detailed step creation
- Check out [API Steps](/docs/concepts/steps/api) for creating HTTP endpoints
- Dive into [Event Steps](/docs/concepts/steps/event) for workflow orchestration

-   [ai-deep-research-agent](/docs/real-world-use-cases/ai-deep-research-agent): Documentation for ai-deep-research-agent.
---
title: AI Deep Research Agent
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

## Let's build a AI Deep Research Agent that:

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Tabs items={['analyze-content', 'compile-report', 'extract-content', 'follow-up-research', 'generate-queries', 'report-api', 'research-api', 'search-web', 'status-api']}>
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="analyze-content" value="analyze-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="compile-report" value="compile-report" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="extract-content" value="extract-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="follow-up-research" value="follow-up-research" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="generate-queries" value="generate-queries" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="report-api" value="report-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="research-api" value="research-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="search-web" value="search-web" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="status-api" value="status-api" />
</Tabs>

## üöÄ Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## üìã Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## üõ†Ô∏è Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## üèóÔ∏è Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## üö¶ API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## üèÉ‚Äç‚ôÇÔ∏è Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3000/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## üôè Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API


## Use Cases
[ai-deep-research-agent](/docs/real-world-use-cases/ai-deep-research-agent): Real world use case
---
title: AI Deep Research Agent
description: A powerful research assistant that leverages the Motia Framework to perform comprehensive web research on any topic and any question.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

## Let's build a AI Deep Research Agent that:

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-content.step.ts" />
  <File name="compile-report.step.ts" />
  <File name="extract-content.step.ts" />
  <File name="follow-up-research.step.ts" />
  <File name="generate-queries.step.ts" />
  <File name="report-api.step.ts" />
  <File name="research-api.step.ts" />
  <File name="search-web.step.ts" />
  <File name="status-api.step.ts" />
</Folder>

<Tabs items={['analyze-content', 'compile-report', 'extract-content', 'follow-up-research', 'generate-queries', 'report-api', 'research-api', 'search-web', 'status-api']}>
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="analyze-content" value="analyze-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="compile-report" value="compile-report" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="extract-content" value="extract-content" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="follow-up-research" value="follow-up-research" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="generate-queries" value="generate-queries" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="report-api" value="report-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="research-api" value="research-api" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="search-web" value="search-web" />
  <CodeFetcher path="examples/ai-deep-research-agent/steps" tab="status-api" value="status-api" />
</Tabs>

## üöÄ Features

- **Deep Web Research**: Automatically searches the web, extracts content, and synthesizes findings
- **Iterative Research Process**: Supports multiple layers of research depth for comprehensive exploration
- **Event-Driven Architecture**: Built using Motia Framework's event system for robust workflow management
- **Parallel Processing**: Efficiently processes search results and content extraction
- **API Endpoints**: REST API access for initiating research and retrieving reports
- **Stateful Processing**: Maintains research state throughout the entire process

## üìã Prerequisites

- Node.js v18 or later
- npm or pnpm
- API keys for:
  - [OpenAI](https://platform.openai.com/) (AI analysis)
  - [Firecrawl](https://www.firecrawl.dev/) (Web Crawler)

## üõ†Ô∏è Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/ai-deep-research-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   # Required
   OPENAI_API_KEY=your-openai-api-key-here
   FIRECRAWL_API_KEY=your-firecrawl-api-key-here

   # Optional
   # OPENAI_MODEL=gpt-4o
   # FIRECRAWL_BASE_URL=http://your-firecrawl-instance-url
   ```

## üèóÔ∏è Architecture

![AI Deep Research Agent](../img/ai-deep-research-agent.png)


## üö¶ API Endpoints

### Start Research

```
POST /research
Content-Type: application/json

{
  "query": "The research topic or question",
  "breadth": 4,  // Number of search queries to generate (1-10)
  "depth": 2     // Depth of research iterations (1-5)
}
```

Response:
```json
{
  "message": "Research process started",
  "requestId": "unique-trace-id"
}
```

### Check Research Status

```
GET /research/status?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research status retrieved successfully",
  "requestId": "unique-trace-id",
  "originalQuery": "The research topic or question",
  "status": "in-progress",
  "progress": {
    "currentDepth": 1,
    "totalDepth": 2,
    "percentComplete": 50
  },
  "reportAvailable": false
}
```

### Get Research Report

```
GET /research/report?requestId=unique-trace-id
```

Response:
```json
{
  "message": "Research report retrieved successfully",
  "report": {
    "title": "Research Report Title",
    "overview": "Executive summary...",
    "sections": [
      {
        "title": "Section Title",
        "content": "Section content..."
      }
    ],
    "keyTakeaways": [
      "Key takeaway 1",
      "Key takeaway 2"
    ],
    "sources": [
      {
        "title": "Source Title",
        "url": "Source URL"
      }
    ],
    "originalQuery": "The research topic or question",
    "metadata": {
      "depthUsed": 2,
      "completedAt": "2025-03-18T16:45:30Z"
    }
  },
  "requestId": "unique-trace-id"
}
```

## üèÉ‚Äç‚ôÇÔ∏è Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl --request POST \
   --url http://localhost:3000/research \
   --header 'Content-Type: application/json' \
   --data '{
      "query": "Advancements in renewable energy storage",
      "depth": 1,
      "breadth": 1
   }'
   ```
## üôè Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [OpenAI](https://platform.openai.com/) for AI analysis 
- [Firecrawl](https://www.firecrawl.dev/) for Web search and content extraction API

-   [finance-agent](/docs/real-world-use-cases/finance-agent): Documentation for finance-agent.
---
title: Finance Agent
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Tabs items={['finance-data', 'openai-analysis', 'query-api', 'response-coordinator', 'result-api', 'save-result', 'web-search']}>
  <CodeFetcher path="examples/finance-agent/steps" tab="finance-data" value="finance-data" />
  <CodeFetcher path="examples/finance-agent/steps" tab="openai-analysis" value="openai-analysis" />
  <CodeFetcher path="examples/finance-agent/steps" tab="query-api" value="query-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="response-coordinator" value="response-coordinator" />
  <CodeFetcher path="examples/finance-agent/steps" tab="result-api" value="result-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="save-result" value="save-result" />
  <CodeFetcher path="examples/finance-agent/steps" tab="web-search" value="web-search" />
</Tabs>

## üöÄ Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## üìã Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## üõ†Ô∏è Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## üèóÔ∏è Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## üö¶ API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## üèÉ‚Äç‚ôÇÔ∏è Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl -X POST http://localhost:3000/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## üôè Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 


## Use Cases
[finance-agent](/docs/real-world-use-cases/finance-agent): Real world use case
---
title: Finance Agent
description: A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis to provide comprehensive investment insights.
---

import { CodeFetcher } from '../../../components/CodeFetcher'

## Let's build a finance agent that:

- Real-time Financial Analysis: Combines multiple data sources for comprehensive insights
- AI-Powered Insights: Leverages OpenAI GPT-4 for intelligent market analysis
- Web Search Integration: Aggregates latest market news and analysis
- Financial Data Integration: Real-time stock and company information

## The Steps

<Folder name="steps" defaultOpen>
  <File name="finance-data.step.ts" />
  <File name="openai-analysis.step.ts" />
  <File name="query-api.step.ts" />
  <File name="response-coordinator.step.ts" />
  <File name="result-api.step.ts" />
  <File name="save-result.step.ts" />
  <File name="web-search.step.ts" />
</Folder>

<Tabs items={['finance-data', 'openai-analysis', 'query-api', 'response-coordinator', 'result-api', 'save-result', 'web-search']}>
  <CodeFetcher path="examples/finance-agent/steps" tab="finance-data" value="finance-data" />
  <CodeFetcher path="examples/finance-agent/steps" tab="openai-analysis" value="openai-analysis" />
  <CodeFetcher path="examples/finance-agent/steps" tab="query-api" value="query-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="response-coordinator" value="response-coordinator" />
  <CodeFetcher path="examples/finance-agent/steps" tab="result-api" value="result-api" />
  <CodeFetcher path="examples/finance-agent/steps" tab="save-result" value="save-result" />
  <CodeFetcher path="examples/finance-agent/steps" tab="web-search" value="web-search" />
</Tabs>

## üöÄ Features

- **Real-time Financial Analysis**: Combines multiple data sources for comprehensive insights
- **AI-Powered Insights**: Leverages OpenAI GPT-4 for intelligent market analysis
- **Event-Driven Architecture**: Built on Motia's robust event system for reliable processing
- **Web Search Integration**: Aggregates latest market news and analysis
- **Financial Data Integration**: Real-time stock and company information
- **Persistent Storage**: Stores analysis results for future reference
- **RESTful API**: Easy integration with existing systems

## üìã Prerequisites

- Node.js v16+
- npm or pnpm
- API keys for:
  - [Alpha Vantage](https://www.alphavantage.co/) (financial data)
  - [SerperDev](https://serper.dev/) (web search)
  - [OpenAI](https://platform.openai.com/) (AI analysis)

## üõ†Ô∏è Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/MotiaDev/motia-examples
   cd examples/finance-agent
   ```

2. Install dependencies:
   ```bash
   pnpm install
   # or
   npm install
   ```

3. Configure environment variables:
   ```bash
   cp .env.example .env
   ```

   Update `.env` with your API keys:
   ```bash
   ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
   SERPER_API_KEY=your_serper_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   ```

## üèóÔ∏è Architecture

The workflow consists of several specialized steps that work together to provide comprehensive financial analysis:

![Finance Agent](../img/finance-agent.gif)


## üö¶ API Endpoints

### Query Endpoint

```http
POST /finance-query
Content-Type: application/json

{
  "query": "Latest information about AAPL and MSFT"
}
```

Response:
```json
{
  "message": "Query received and processing started",
  "traceId": "abc123def456"
}
```

### Results Endpoint

```http
GET /finance-result/:traceId
```

Response:
```json
{
  "query": "Latest information about AAPL and MSFT",
  "timestamp": "2023-06-15T12:34:56.789Z",
  "response": {
    "summary": "Results for \"Latest information about AAPL and MSFT\"",
    "webResources": [...],
    "financialData": [...],
    "aiAnalysis": {...}
  },
  "status": "success"
}
```

## üèÉ‚Äç‚ôÇÔ∏è Running the Application

1. Start the development server:
   ```bash
   pnpm dev
   ```

2. Access the Motia Workbench:
   ```
   http://localhost:3000
   ```

3. Make a test request:
   ```bash
   curl -X POST http://localhost:3000/finance-query \
     -H "Content-Type: application/json" \
     -d '{"query": "Latest information about AAPL and MSFT"}'
   ```
## üôè Acknowledgments

- [Motia Framework](https://motia.dev) for the event-driven workflow engine
- [Alpha Vantage](https://www.alphavantage.co/) for financial data
- [SerperDev](https://serper.dev/) for web search capabilities
- [OpenAI](https://platform.openai.com/) for AI analysis 

-   [github-integration-workflow](/docs/real-world-use-cases/github-integration-workflow): Documentation for github-integration-workflow.
---
title: GitHub Integration Workflow
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Tabs items={['issue-webhook', 'issue-classifier', 'label-assigner', 'assignee-selector']}>
  <GitHubWorkflowTab tab="issue-webhook" value="github-webhook" folder="issue-triage" />
  <GitHubWorkflowTab tab="issue-classifier" value="issue-classifier" folder="issue-triage" />
  <GitHubWorkflowTab tab="label-assigner" value="label-assigner" folder="issue-triage" />
  <GitHubWorkflowTab tab="assignee-selector" value="assignee-selector" folder="issue-triage" />
</Tabs>

<Tabs items={['pr-webhook', 'pr-classifier', 'pr-reviewer', 'pr-monitor']}>
  <GitHubWorkflowTab tab="pr-webhook" value="pr-webhook" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-classifier" value="pr-classifier" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-reviewer" value="pr-reviewer-assigner" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-monitor" value="pr-test-monitor" folder="pr-classifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** ‚Üí Captures GitHub events
2. **Issue/PR Classification** ‚Üí Analyzes content with AI
3. **Automated Labeling** ‚Üí Applies appropriate labels
4. **Smart Assignment** ‚Üí Suggests reviewers and assignees
5. **Status Monitoring** ‚Üí Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow).
</Callout> 


## Use Cases
[github-integration-workflow](/docs/real-world-use-cases/github-integration-workflow): Real world use case
---
title: GitHub Integration Workflow
description: Build an automated GitHub issue and PR management system with AI-powered classification and routing
---

## Let's build a GitHub automation system that:

1. Automatically triages and classifies new issues
2. Intelligently assigns labels based on content
3. Suggests appropriate assignees and reviewers
4. Monitors PR test status
5. Generates contextual comments

## Workflow Structure

The GitHub integration workflow is organized into two main components:

- **Issue Triage**: Handles the management of GitHub issues
- **PR Classifier**: Manages pull request workflows

## The Steps

<Folder name="steps" defaultOpen>
  <Folder name="issue-triage" defaultOpen>
    <File name="github-webhook.step.ts" />
    <File name="issue-classifier.step.ts" />
    <File name="label-assigner.step.ts" />
    <File name="assignee-selector.step.ts" />
    <File name="handle-new-issue.step.ts" />
    <File name="handle-issue-update.step.ts" />
    <File name="handle-issue-closure.step.ts" />
  </Folder>
  <Folder name="pr-classifier" defaultOpen>
    <File name="pr-webhook.step.ts" />
    <File name="pr-classifier.step.ts" />
    <File name="pr-label-assigner.step.ts" />
    <File name="pr-reviewer-assigner.step.ts" />
    <File name="pr-test-monitor.step.ts" />
  </Folder>
</Folder>

<Tabs items={['issue-webhook', 'issue-classifier', 'label-assigner', 'assignee-selector']}>
  <GitHubWorkflowTab tab="issue-webhook" value="github-webhook" folder="issue-triage" />
  <GitHubWorkflowTab tab="issue-classifier" value="issue-classifier" folder="issue-triage" />
  <GitHubWorkflowTab tab="label-assigner" value="label-assigner" folder="issue-triage" />
  <GitHubWorkflowTab tab="assignee-selector" value="assignee-selector" folder="issue-triage" />
</Tabs>

<Tabs items={['pr-webhook', 'pr-classifier', 'pr-reviewer', 'pr-monitor']}>
  <GitHubWorkflowTab tab="pr-webhook" value="pr-webhook" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-classifier" value="pr-classifier" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-reviewer" value="pr-reviewer-assigner" folder="pr-classifier" />
  <GitHubWorkflowTab tab="pr-monitor" value="pr-test-monitor" folder="pr-classifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: GitHub Issue Workflow](../img/github-issue-workflow.png)</div>
<div className="my-8">![Flow: GitHub PR Workflow](../img/github-pr-workflow.png)</div>

1. **Webhook Reception** ‚Üí Captures GitHub events
2. **Issue/PR Classification** ‚Üí Analyzes content with AI
3. **Automated Labeling** ‚Üí Applies appropriate labels
4. **Smart Assignment** ‚Üí Suggests reviewers and assignees
5. **Status Monitoring** ‚Üí Tracks PR test status

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- GitHub account with personal access token
- Node.js installed
- OpenAI API key (for AI classification)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/github-integration-workflow
```

### Install Dependencies

```bash
npm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
GITHUB_TOKEN=your_github_token_here
OPENAI_API_KEY=your_openai_api_key
```

### Set Up GitHub Webhook

1. Go to your GitHub repository settings
2. Navigate to Webhooks and add a new webhook
3. Set the Payload URL to your Motia server endpoint
4. Select content type as `application/json`
5. Choose which events to trigger the webhook (Issues, Pull requests)
6. Save the webhook

### Run the Application

```bash
npm run dev
```

### Test the Flow

1. Create a new issue in your GitHub repository
2. Watch as it gets automatically classified and labeled
3. Create a new PR to see the reviewer assignment in action
4. Check the PR comments for test status updates

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/github-integration-workflow).
</Callout> 

-   [gmail-automation](/docs/real-world-use-cases/gmail-automation): Documentation for gmail-automation.
---
title: Gmail Automation
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

import { GmailTab } from '../../../components/GmailCodeFetcher'

## Let's build a Gmail automation system that:

- üìä Smart email classification by category (work, personal, social, promotion, spam, update)
- üö® Urgency detection (high, medium, low) with prioritization
- üí¨ Intelligent automated responses based on email context
- üè∑Ô∏è Automatic email organization (labeling, archiving)
- üìà Daily summary reports via Discord
- üîí Secure Gmail API integration with OAuth2 authentication flow
- ‚ö° Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Tabs items={['webhook', 'analyze-email', 'auto-responder', 'daily-summary', 'fetch-email', 'organize-email']}>
  <GmailTab tab="webhook" value="gmail-webhook" />
  <GmailTab tab="analyze-email" value="analyze-email" fileExtension="py" />
  <GmailTab tab="auto-responder" value="auto-responder" />
  <GmailTab tab="daily-summary" value="daily-summary" />
  <GmailTab tab="fetch-email" value="fetch-email" />
  <GmailTab tab="organize-email" value="organize-email" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## üåä Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (API Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Emits**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (API Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Event Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Subscribes to**: `gmail.email.received`
- **Emits**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Event Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Subscribes to**: `gmail.email.fetched`
- **Emits**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Event Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Event Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Emits**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## üìã Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## üöÄ Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the Motia Workbench**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to access the workflow UI.

## üîß Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the Motia Workbench
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## üìÅ Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## üì¶ Dependencies

### Node.js Dependencies
- **@motiadev/core**, **@motiadev/workbench**, **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## üõ†Ô∏è Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## üìù Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```



## Use Cases
[gmail-automation](/docs/real-world-use-cases/gmail-automation): Real world use case
---
title: Gmail Automation
description: Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
---

import { GmailTab } from '../../../components/GmailCodeFetcher'

## Let's build a Gmail automation system that:

- üìä Smart email classification by category (work, personal, social, promotion, spam, update)
- üö® Urgency detection (high, medium, low) with prioritization
- üí¨ Intelligent automated responses based on email context
- üè∑Ô∏è Automatic email organization (labeling, archiving)
- üìà Daily summary reports via Discord
- üîí Secure Gmail API integration with OAuth2 authentication flow
- ‚ö° Real-time email monitoring with webhook notifications

## The Steps

<Folder name="steps" defaultOpen>
  <File name="analyze-email.step.py" />
  <File name="auto-responder.step.ts" />
  <File name="daily-summary.step.ts" />
  <File name="fetch-email.step.ts" />
  <File name="gmail-webhook.step.ts" />
  <File name="organize-email.step.ts" />
</Folder>

<Tabs items={['webhook', 'analyze-email', 'auto-responder', 'daily-summary', 'fetch-email', 'organize-email']}>
  <GmailTab tab="webhook" value="gmail-webhook" />
  <GmailTab tab="analyze-email" value="analyze-email" fileExtension="py" />
  <GmailTab tab="auto-responder" value="auto-responder" />
  <GmailTab tab="daily-summary" value="daily-summary" />
  <GmailTab tab="fetch-email" value="fetch-email" />
  <GmailTab tab="organize-email" value="organize-email" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Gmail Automation Steps](../img/gmail-automation.png)</div>

## üåä Workflow Architecture

The Gmail Account Manager workflow consists of the following steps:

### 1. Gmail Authentication (Multi-Step Flow)
- **Files**: 
  - `steps/gmail-get-auth-url.step.ts`: Generates OAuth2 authorization URL
  - `steps/gmail-auth.step.ts`: Handles authorization code exchange
  - `steps/gmail-token-status.step.ts`: Checks token validity and refreshes if needed

### 2. Gmail Webhook (API Step)
- **File**: `steps/gmail-webhook.step.ts`
- **Purpose**: Receives notifications from Gmail when new emails arrive
- **Emits**: `gmail.new_email` event with message details
- **Endpoint**: `POST /api/gmail-webhook`

### 3. Gmail Watch (API Step)
- **File**: `steps/gmail-watch.step.ts`
- **Purpose**: Sets up push notifications for the Gmail account
- **Endpoint**: `GET /api/watch`

### 4. Fetch Email (Event Step)
- **File**: `steps/fetch-email.step.ts`
- **Purpose**: Retrieves the full email content from Gmail API
- **Subscribes to**: `gmail.email.received`
- **Emits**: `gmail.email.fetched` with complete email data
- **Key Functions**: Authenticates with Gmail API, fetches message content, parses attachments

### 5. Analyze Email (Event Step)
- **File**: `steps/analyze-email.step.py`
- **Purpose**: Uses Hugging Face models to analyze email content
- **Subscribes to**: `gmail.email.fetched`
- **Emits**: `gmail.email.analyzed` with analysis results
- **Analysis Performed**: 
  - Category classification
  - Urgency detection
  - Sentiment analysis
  - Key information extraction

### 6. Organize Email (Event Step)
- **File**: `steps/organize-email.step.ts`
- **Purpose**: Applies labels and organization based on analysis
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `[gmail.email.organized, gmail.email.archived]`
- **Actions**: Creates/applies labels, archives certain emails, marks importance

### 7. Auto-Respond to Email (Event Step)
- **File**: `steps/auto-responder.step.ts`
- **Purpose**: Generates and sends appropriate responses for certain emails
- **Subscribes to**: `gmail.email.analyzed`
- **Emits**: `gmail.email.responded`
- **Features**: 
  - Template selection based on email context
  - Personalization of responses
  - Auto-reply for urgent messages
  - Follow-up scheduling

### 8. Daily Summary (Cron Step)
- **File**: `steps/daily-summary.step.ts`
- **Purpose**: Compiles and sends daily email activity summary
- **Schedule**: Runs daily at 6:00 PM
- **Emits**: `gmail.summary.sent`
- **Delivery**: Sends report to Discord via webhook

## Try It Out

<Steps>
## üìã Prerequisites

- **Node.js** (v18+)
- **Python** (v3.8+)
- **Gmail API credentials** (client_id and client_secret)
- **Google Cloud project** with Pub/Sub API enabled
- **Hugging Face API token**
- **Discord webhook URL** (for daily summaries)

## üöÄ Quick Start

1. **Clone this repository**
   ```bash
   git clone https://github.com/yourusername/gmail-flow.git
   cd gmail-flow
   ```

2. **Install Node.js dependencies**
   ```bash
   pnpm install
   ```

3. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```
   Then edit the `.env` file with your credentials (see setup sections below).

5. **Start the development server**
   ```bash
   pnpm dev
   ```

6. **Open the Motia Workbench**
   
   Navigate to [http://localhost:3000](http://localhost:3000) to access the workflow UI.

## üîß Detailed Setup

### Setting up Google Cloud Project and Gmail API

Before you can use the Gmail Account Manager, you need to set up a Google Cloud project with the Gmail API and Pub/Sub:

1. **Create a Google Cloud Project**:
   - Go to [Google Cloud Console](https://console.cloud.google.com/)
   - Click on "New Project" and follow the steps to create a new project
   - Note your project ID for later use

2. **Enable the Gmail API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Gmail API" and click on it
   - Click "Enable"

3. **Enable the Pub/Sub API**:
   - In your project, go to "APIs & Services" > "Library"
   - Search for "Cloud Pub/Sub API" and click on it
   - Click "Enable"

4. **Create OAuth Credentials**:
   - Go to "APIs & Services" > "Credentials"
   - Click "Create Credentials" > "OAuth client ID"
   - Set the application type to "Desktop app"
   - Click "Create"
   - Note your Client ID and Client Secret for your `.env` file:
     ```
     GOOGLE_CLIENT_ID=your_client_id
     GOOGLE_CLIENT_SECRET=your_client_secret
     ```

### Setting up Google Pub/Sub for Gmail Notifications

To enable real-time email notifications, you need to set up a Google Cloud Pub/Sub topic and subscription:

1. **Create a Pub/Sub Topic**:
   - In your Google Cloud Console, go to "Pub/Sub" > "Topics"
   - Click "Create Topic"
   - Name your topic (e.g., `gmail-notifications`)
   - Add the service account `gmail-api-push@system.gserviceaccount.com` as a Topic Publisher to allow Gmail to publish notifications
   - Click "Create"
   - Note the full topic name (usually `projects/your-project-id/topics/gmail-notifications`) for your `.env` file:
     ```
     GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications
     ```

2. **Create a Pub/Sub Subscription**:
   - Once your topic is created, click "Create Subscription"
   - Name your subscription (e.g., `gmail-notifications-push`)
   - Set the Delivery Type to "Push"
   - Set the Endpoint URL to your webhook URL (e.g., `https://your-domain.com/api/gmail-webhook`)
     - For local development, you'll need to use a tool like ngrok to expose your local server
   - Click "Create"

3. **Set up Domain Verification** (if needed):
   - If you're using a custom domain for your webhook endpoint, you may need to verify domain ownership
   - Follow the instructions in Google Cloud Console for domain verification

### Gmail API Authentication

This project includes a complete OAuth2 authentication flow for the Gmail API:

1. Start the development server: `pnpm dev`
2. Navigate to the authentication workflow in the Motia Workbench
3. The workflow will generate an authorization URL
4. Open the URL in your browser and authorize the application
5. The application will receive and store your authentication tokens

### Discord Webhook Configuration

To receive daily email summaries in Discord, follow these steps to set up a webhook:

1. **Create a Discord Server** (skip if you already have one):
   - Open Discord and click the "+" icon on the left sidebar
   - Select "Create My Own" and follow the setup wizard

2. **Create a Channel for Notifications**:
   - Right-click on your server name and select "Server Settings"
   - Go to "Channels" and click "Create Channel"
   - Name it (e.g., "email-summaries") and click "Create"

3. **Create a Webhook**:
   - Right-click on your new channel and select "Edit Channel"
   - Go to "Integrations" tab
   - Click "Create Webhook"
   - Give it a name (e.g., "Gmail Summary Bot")
   - Optionally, customize the avatar
   - Click "Copy Webhook URL"

4. **Add Webhook URL to Environment Variables**:
   - Open your `.env` file
   - Add or update the Discord webhook URL:
     ```
     DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url
     ```

5. **Test the Webhook**:
   - You can test if your webhook is working correctly with this curl command:
     ```bash
     curl -X POST -H "Content-Type: application/json" \
     -d '{"content": "Testing Gmail Account Manager webhook"}' \
     https://discord.com/api/webhooks/your-webhook-url
     ```
   - You should see the message appear in your Discord channel

### Hugging Face Setup

1. **Create a Hugging Face Account**:
   - Sign up at [Hugging Face](https://huggingface.co/join)

2. **Generate an API Token**:
   - Go to your [Hugging Face account settings](https://huggingface.co/settings/tokens)
   - Create a new API token
   - Copy the token to your `.env` file:
     ```
     HUGGINGFACE_API_TOKEN=your_api_token
     ```

</Steps>

## üìÅ Project Structure

- `steps/` - Contains all workflow steps
  - `gmail-get-auth-url.step.ts` - Generates OAuth2 URL
  - `gmail-auth.step.ts` - Handles OAuth2 flow
  - `gmail-token-status.step.ts` - Manages token refresh
  - `gmail-webhook.step.ts` - Webhook endpoint for Gmail notifications
  - `gmail-watch.step.ts` - Sets up Gmail push notifications
  - `fetch-email.step.ts` - Fetches email content from Gmail API
  - `analyze-email.step.py` - Python step for email analysis using Hugging Face
  - `organize-email.step.ts` - Organizes emails (labels, archives)
  - `auto-responder.step.ts` - Generates appropriate responses
  - `daily-summary.step.ts` - Sends daily summary to Discord
- `services/` - Shared service modules
- `config/` - Configuration files
- `.motia/` - Motia framework configuration

## üì¶ Dependencies

### Node.js Dependencies
- **@motiadev/core**, **@motiadev/workbench**, **motia**: Motia framework
- **googleapis**, **google-auth-library**: Google API integration
- **gmail-api-parse-message-ts**: Gmail message parsing
- **axios**: HTTP client
- **zod**: Schema validation
- **react**: UI components

### Python Dependencies
- **transformers**, **torch**: Machine learning models
- **scikit-learn**, **numpy**, **pandas**: Data processing
- **huggingface_hub**: Access to Hugging Face models
- **python-dotenv**: Environment variable loading

## üõ†Ô∏è Troubleshooting

- **Python Module Errors**: Ensure you've installed all required Python packages with `pip install -r requirements.txt`
- **Authentication Errors**: Verify your API credentials and follow the authentication flow
- **Webhook Issues**: Make sure the webhook endpoint is publicly accessible or properly configured for testing
- **Token Refresh Errors**: Check that your OAuth tokens are valid and that the refresh flow is working properly
- **Pub/Sub Not Working**: Verify that your Pub/Sub topic and subscription are properly configured and that your service account has the necessary permissions

## üìù Environment Variables

Create a `.env` file with the following variables:

```
# Google API Configuration
GOOGLE_CLIENT_ID=your_client_id
GOOGLE_CLIENT_SECRET=your_client_secret
GOOGLE_PUBSUB_TOPIC=projects/your-project-id/topics/gmail-notifications

# HuggingFace Configuration
HUGGINGFACE_API_TOKEN=your_huggingface_token

# Discord Integration
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/your-webhook-url

# Auto-Responder Configuration
AUTO_RESPONDER_NAME=Your Name
AUTO_RESPONDER_EMAIL=your-email@example.com
```


-   [index](/docs/real-world-use-cases): Documentation for index.
---
title: Real-World Use Cases
description: See how Motia is used to solve real problems
---

# Real-World Use Cases

Explore these practical examples of Motia in action:

- [Gmail Automation](./real-world-use-cases/gmail-automation) - Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
- [GitHub Integration Workflow](./real-world-use-cases/github-integration-workflow) - Build an automated GitHub issue and PR management system with AI-powered classification and routing
- [Finance Agent](./real-world-use-cases/finance-agent) - A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis
- [AI Deep Research Agent](./real-world-use-cases/ai-deep-research-agent) - A powerful research assistant that leverages the Motia Framework to perform comprehensive web research
- [Trello Card Automation](./real-world-use-cases/trello-automation) - Build an automated card progression system for Trello boards with AI-powered summaries

Have a great use case to share? [Contribute it here](https://github.com/MotiaDev/motia-examples/tree/main/examples). 


## Use Cases
[index](/docs/real-world-use-cases): Real world use case
---
title: Real-World Use Cases
description: See how Motia is used to solve real problems
---

# Real-World Use Cases

Explore these practical examples of Motia in action:

- [Gmail Automation](./real-world-use-cases/gmail-automation) - Build an automated email system with smart labeling, auto-responses, and AI-powered filtering
- [GitHub Integration Workflow](./real-world-use-cases/github-integration-workflow) - Build an automated GitHub issue and PR management system with AI-powered classification and routing
- [Finance Agent](./real-world-use-cases/finance-agent) - A powerful event-driven financial analysis workflow that combines web search, financial data, and AI analysis
- [AI Deep Research Agent](./real-world-use-cases/ai-deep-research-agent) - A powerful research assistant that leverages the Motia Framework to perform comprehensive web research
- [Trello Card Automation](./real-world-use-cases/trello-automation) - Build an automated card progression system for Trello boards with AI-powered summaries

Have a great use case to share? [Contribute it here](https://github.com/MotiaDev/motia-examples/tree/main/examples). 

-   [trello-automation](/docs/real-world-use-cases/trello-automation): Documentation for trello-automation.
---
title: Trello Card Automation
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

import { TrelloTab, TrelloCodeContent } from '../../../components/TrelloCodeFetcher'

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Tabs items={['webhook', 'validation', 'requirements', 'assigned', 'review', 'completion', 'overdue', 'slack']}>
  <TrelloTab tab="webhook" value="trello-webhook" />
  <TrelloTab tab="validation" value="trello-webhook-validation" />
  <TrelloTab tab="requirements" value="validate-card-requirements" />
  <TrelloTab tab="assigned" value="start-assigned-card" />
  <TrelloTab tab="review" value="mark-card-for-review" />
  <TrelloTab tab="completion" value="complete-approved-card" />
  <TrelloTab tab="overdue" value="check-overdue-cards" />
  <TrelloTab tab="slack" value="slack-notifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](../img/trello-automation.png)</div>

1. **Card Validation** ‚Üí Checks for required information
2. **Progress Tracking** ‚Üí Moves cards between lists
3. **Review Process** ‚Üí Generates AI summaries and notifies reviewers
4. **Completion Handling** ‚Üí Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow).
</Callout>{' '}



## Use Cases
[trello-automation](/docs/real-world-use-cases/trello-automation): Real world use case
---
title: Trello Card Automation
description: Build an automated card progression system for Trello boards with AI-powered summaries
---

import { TrelloTab, TrelloCodeContent } from '../../../components/TrelloCodeFetcher'

## Let's build a Trello automation system that:

1. Automatically progresses cards across board lists
2. Validates card completeness
3. Generates AI-powered summaries for code review
4. Integrates with Slack for notifications
5. Monitors due dates and sends overdue alerts

## Board Structure

The Trello board is organized into four main lists:

- **New Cards**: Entry point for all new cards
- **In Progress**: Active development stage
- **Needs Review**: Code review stage with AI summaries
- **Completed**: Successfully reviewed and approved cards

## The Steps

<Folder name="steps" defaultOpen>
  <File name="trello-webhook.step.ts" />
  <File name="trello-webhook-validation.step.ts" />
  <File name="validate-card-requirements.step.ts" />
  <File name="start-assigned-card.step.ts" />
  <File name="mark-card-for-review.step.ts" />
  <File name="complete-approved-card.step.ts" />
  <File name="check-overdue-cards.step.ts" />
  <File name="slack-notifier.step.ts" />
</Folder>

<Tabs items={['webhook', 'validation', 'requirements', 'assigned', 'review', 'completion', 'overdue', 'slack']}>
  <TrelloTab tab="webhook" value="trello-webhook" />
  <TrelloTab tab="validation" value="trello-webhook-validation" />
  <TrelloTab tab="requirements" value="validate-card-requirements" />
  <TrelloTab tab="assigned" value="start-assigned-card" />
  <TrelloTab tab="review" value="mark-card-for-review" />
  <TrelloTab tab="completion" value="complete-approved-card" />
  <TrelloTab tab="overdue" value="check-overdue-cards" />
  <TrelloTab tab="slack" value="slack-notifier" />
</Tabs>

## Visual Overview

Here's how the automation flow works:

<div className="my-8">![Flow: Trello Automation Steps](../img/trello-automation.png)</div>

1. **Card Validation** ‚Üí Checks for required information
2. **Progress Tracking** ‚Üí Moves cards between lists
3. **Review Process** ‚Üí Generates AI summaries and notifies reviewers
4. **Completion Handling** ‚Üí Processes approved cards

## Try It Out

<Steps>

### Prerequisites

Make sure you have:

- Trello account with API access
- Node.js installed
- Slack workspace (for notifications)
- OpenAI API key (for AI summaries)

### Clone the Repository

```bash
git clone git@github.com:MotiaDev/motia-examples.git
cd examples/trello-flow
```

### Install Dependencies

```bash
pnpm install
```

### Configure Environment Variables

Create a `.env` file by copying the example:

```bash
cp .env.example .env
```

Update your `.env` with the following credentials:

```bash
TRELLO_API_KEY=your_trello_api_key
TRELLO_TOKEN=your_trello_token

OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=your_openai_model

SLACK_WEBHOOK_URL=your_slack_webhook_url

TRELLO_NEW_TASKS_LIST_ID=your_new_tasks_list_id
TRELLO_IN_PROGRESS_LIST_ID=your_in_progress_list_id
TRELLO_NEEDS_REVIEW_LIST_ID=your_needs_review_list_id
TRELLO_COMPLETED_LIST_ID=your_completed_list_id
```

### Set Up Trello Board

1. Create a new Trello board with these lists:

   - New Tasks
   - In Progress
   - Needs Review
   - Completed

2. Add a custom field:
   - Status (dropdown: Todo, In Progress, Done)

### Run the Application

```bash
pnpm dev
```

### Test the Flow

1. Create a new card in the "New Tasks" list
2. Assign a member to see it move to "In Progress"
3. Add an "approved" comment to see it move to "Completed"
4. Check Slack for notifications

</Steps>

<Callout type="info">
  For more detailed setup instructions and configuration options, check out the [full
  documentation](https://github.com/MotiaDev/motia-examples/tree/main/examples/trello-flow).
</Callout>{' '}


-   [NOOP Steps](/docs/workbench/noop-steps): Documentation for NOOP Steps.
---
title: NOOP Steps
---

NOOP (No Operation) steps are a powerful feature in Motia that serve multiple purposes:

1. Modeling external processes, webhooks and integrations
2. Representing human-in-the-loop activities
3. Creating custom visualizations in the workbench
4. Testing flows during development

## File Structure

NOOP steps require two files with the same base name:
- `stepName.step.ts` - Contains the step configuration
- `stepName.step.tsx` - Contains the UI component (optional)

### Step Configuration File (.ts)

<Tabs items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    // myStep.step.ts
    import { NoopConfig } from 'motia'

    export const config: NoopConfig = {
      type: 'noop',
      name: 'My NOOP Step',
      description: 'Description of what this step simulates',
      virtualEmits: ['event.one', 'event.two'],
      virtualSubscribes: [], // Required even if empty
      flows: ['my-flow'],
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    // myStep.step.js
    const config = {
      type: 'noop',
      name: 'My NOOP Step',
      description: 'Description of what this step simulates',
      virtualEmits: ['event.one', 'event.two'],
      virtualSubscribes: [], // Required even if empty
      flows: ['my-flow'],
    }

    module.exports = { config }
    ```
  </Tab>
</Tabs>

### UI Component File (.tsx)

<Tabs items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    // myStep.step.tsx
    import React from 'react'
    import { BaseHandle, Position } from 'motia/workbench'

    export default function MyStep() {
      return (
        <div className="p-4 bg-gray-800 rounded-lg border border-gray-600 text-white">
          <div className="text-sm font-medium">My Step UI</div>
          {/* Your custom UI elements */}
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    // myStep.step.jsx
    import React from 'react'
    import { BaseHandle, Position } from 'motia/workbench'

    export default function MyStep() {
      return (
        <div className="p-4 bg-gray-800 rounded-lg border border-gray-600 text-white">
          <div className="text-sm font-medium">My Step UI</div>
          {/* Your custom UI elements */}
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }
    ```
  </Tab>
</Tabs>

## Example: Webhook Testing

Here's a complete example of a NOOP step that simulates webhook events:

<Tabs items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    // test-webhook.step.ts
    import { NoopConfig } from 'motia'

    export const config: NoopConfig = {
      type: 'noop',
      name: 'Webhook Simulator',
      description: 'Simulates incoming webhook events',
      virtualEmits: ['webhook.received'],
      virtualSubscribes: [],
      flows: ['webhook-flow'],
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    // test-webhook.step.js
    const config = {
      type: 'noop',
      name: 'Webhook Simulator',
      description: 'Simulates incoming webhook events',
      virtualEmits: ['webhook.received'],
      virtualSubscribes: [],
      flows: ['webhook-flow'],
    }

    module.exports = { config }
    ```
  </Tab>
</Tabs>

<Tabs items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    // test-webhook.step.tsx
    import React from 'react'
    import { BaseHandle, Position } from 'motia/workbench'

    export default function WebhookSimulator() {
      return (
        <div className="p-4 bg-gray-800 rounded-lg border border-gray-600 text-white">
          <div className="text-sm font-medium mb-2">Webhook Simulator</div>
          <button 
            onClick={() => {
              fetch('/api/webhook', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ event: 'test' }),
              })
            }}
            className="px-3 py-1 bg-blue-600 rounded text-sm"
          >
            Trigger Webhook
          </button>
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    // test-webhook.step.jsx
    import React from 'react'
    import { BaseHandle, Position } from 'motia/workbench'

    export default function WebhookSimulator() {
      return (
        <div className="p-4 bg-gray-800 rounded-lg border border-gray-600 text-white">
          <div className="text-sm font-medium mb-2">Webhook Simulator</div>
          <button 
            onClick={() => {
              fetch('/api/webhook', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ event: 'test' }),
              })
            }}
            className="px-3 py-1 bg-blue-600 rounded text-sm"
          >
            Trigger Webhook
          </button>
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }
    ```
  </Tab>
</Tabs>

## Representing External Processes

NOOP steps represent parts of your workflow that happen outside your system. Common examples include:

### Webhook Callbacks

<Tabs  items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    export const config: NoopConfig = {
      type: 'noop',
      name: 'Wait for Stripe Webhook',
      description: 'Waits for payment confirmation',
      virtualSubscribes: ['payment.initiated'],
      virtualEmits: ['/api/stripe/webhook'],
      flows: ['payment'],
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const config = {
      type: 'noop',
      name: 'Wait for Stripe Webhook',
      description: 'Waits for payment confirmation',
      virtualSubscribes: ['payment.initiated'],
      virtualEmits: ['/api/stripe/webhook'],
      flows: ['payment'],
    }
    ```
  </Tab>
</Tabs>

### Human Approvals

<Tabs  items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    export const config: NoopConfig = {
      type: 'noop',
      name: 'Manager Review',
      description: 'Manager reviews request',
      virtualSubscribes: ['approval.requested'],
      virtualEmits: ['/api/approvals/submit'],
      flows: ['approval'],
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const config = {
      type: 'noop',
      name: 'Manager Review',
      description: 'Manager reviews request',
      virtualSubscribes: ['approval.requested'],
      virtualEmits: ['/api/approvals/submit'],
      flows: ['approval'],
    }
    ```
  </Tab>
</Tabs>

### External System Integration

<Tabs  items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
      export const config: NoopConfig = {
        type: 'noop',
        name: 'GitHub Webhook',
        description: 'Waiting for repository events',
        virtualSubscribes: ['repository.watched'],
        virtualEmits: ['/api/github/webhook'],
        flows: ['repo-automation'],
      }
      ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const config = {
      type: 'noop',
      name: 'GitHub Webhook',
      description: 'Waiting for repository events',
      virtualSubscribes: ['repository.watched'],
      virtualEmits: ['/api/github/webhook'],
      flows: ['repo-automation'],
    }
    ```
  </Tab>
</Tabs>

### Physical Processes

<Tabs  items={['TS', 'JS']}>
  <Tab value="TS">
    ```typescript
    export const config: NoopConfig = {
      type: 'noop',
      name: 'Order Fulfillment',
      description: 'Warehouse processes order',
      virtualSubscribes: ['order.placed'],
      virtualEmits: ['/api/warehouse/status'],
      flows: ['fulfillment'],
    }
    ```
  </Tab>
  <Tab value="JS">
    ```javascript
    const config = {
      type: 'noop',
      name: 'Order Fulfillment',
      description: 'Warehouse processes order',
      virtualSubscribes: ['order.placed'],
      virtualEmits: ['/api/warehouse/status'],
      flows: ['fulfillment'],
    }
    ```
  </Tab>
</Tabs>

## Visualization in Workbench

NOOP steps are visually represented in the Motia Workbench with the following characteristics:

- Distinct node representation with clear input/output handles
- Visual indicators for virtual event connections
- Status indicators for waiting states
- Clear visualization of external system dependencies

## Custom UI

You can enhance your NOOP steps with custom React components for better visualization:

<Tabs  items={['TS', 'JS']}>
  <Tab value="TS">
    ```tsx
    // customNode.step.tsx
    import React from 'react'
    import { BaseHandle, EventNodeProps, Position } from 'motia/workbench'

    export default (_: EventNodeProps) => {
      return (
        <div className="p-3 px-6 flex flex-col max-w-[300px] bg-blue-500 border-white rounded-full text-white border border-solid text-center text-sm">
          <div>Custom Processing</div>
          <BaseHandle type="target" position={Position.Top} />
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }

    // customNode.step.ts
    export const config: NoopConfig = {
      type: 'noop',
      name: 'Custom Process',
      virtualEmits: ['/api/process/complete'],
      virtualSubscribes: ['process.start'],
      flows: ['custom-flow']
    }
    ```
  </Tab>
  <Tab value="JS">
    ```jsx
    // customNode.step.jsx
    import React from 'react'
    import { BaseHandle, EventNodeProps, Position } from 'motia/workbench'

    export default (_: EventNodeProps) => {
      return (
        <div className="p-3 px-6 flex flex-col max-w-[300px] bg-blue-500 border-white rounded-full text-white border border-solid text-center text-sm">
          <div>Custom Processing</div>
          <BaseHandle type="target" position={Position.Top} />
          <BaseHandle type="source" position={Position.Bottom} />
        </div>
      )
    }

    // customNode.step.js
    const config = {
      type: 'noop',
      name: 'Custom Process',
      virtualEmits: ['/api/process/complete'],
      virtualSubscribes: ['process.start'],
      flows: ['custom-flow']
    }

    module.exports = {config};
    ```
  </Tab>
</Tabs>

## Best Practices

| Category | Guidelines |
|----------|------------|
| **File Organization** | ‚Ä¢ Keep configuration and UI code in separate files<br/>‚Ä¢ Use `.step.ts` for configuration<br/>‚Ä¢ Use `.step.tsx` for UI components |
| **UI Components** | ‚Ä¢ Use functional React components<br/>‚Ä¢ Include proper TypeScript types<br/>‚Ä¢ Follow Tailwind's utility classes<br/>‚Ä¢ Keep components minimal and focused<br/>‚Ä¢ Design clear visual connection points<br/>‚Ä¢ Always include BaseHandle components for flow connections |
| **Configuration** | ‚Ä¢ Always include `virtualSubscribes` (even if empty)<br/>‚Ä¢ Use descriptive names for virtual events<br/>‚Ä¢ Include clear descriptions<br/>‚Ä¢ Use descriptive, action-oriented names |
| **External Process Modeling** | ‚Ä¢ Document expected timeframes and SLAs<br/>‚Ä¢ Define all possible outcomes and edge cases<br/>‚Ä¢ Use exact API route matching |
| **Testing** | ‚Ä¢ Create isolated test flows<br/>‚Ä¢ Use realistic test data<br/>‚Ä¢ Handle errors gracefully<br/>‚Ä¢ Implement clear status indicators<br/>‚Ä¢ Label test steps explicitly<br/>‚Ä¢ Provide visual feedback for actions |

## Component Reference

### Core Imports

| Import | Purpose |
|--------|---------|
| `BaseHandle` | A React component that renders connection points for nodes in the workflow. Used to define where edges (connections) can start or end on a node. |
| `EventNodeProps` | (TypeScript only) Interface defining the properties passed to node components, including node data, selected state, and connection information. |
| `Position` | (TypeScript only) Enum that specifies the possible positions for handles on a node (Top, Right, Bottom, Left). Used to control where connection points appear. |

### Handle Placement

| Handle Type | Position | 
|------------|----------|
| Input Handles | Position.Top |
| Output Handles | Position.Bottom |
| Flow Direction | Top to bottom |

### Styling Guidelines

| Category | Guidelines |
|----------|------------|
| Colors | Use semantic colors to indicate state (success, error, pending) |
| States | ‚Ä¢ Implement clear visual indicators for active/inactive states<br/>‚Ä¢ Use subtle animations for state transitions |
| Design System | ‚Ä¢ Follow your project's design tokens<br/>‚Ä¢ Maintain consistent spacing and padding<br/>‚Ä¢ Use standard border radiuses<br/>‚Ä¢ Ensure high contrast for readability<br/>‚Ä¢ Use consistent font sizes (14px-16px) |


-   [Overview](/docs/workbench/overview): Documentation for Overview.
---
title: Overview
---

Motia Workbench is a development platform that helps you build and debug your Motia flows. It serves as your control center where you can:

- Visualize flows as interactive diagrams
- Test steps directly in the UI
- Monitor real-time logs
- Debug issues

![Flow Visualization in Workbench](./../img/motia-build-your-app.gif)

## Getting Started

Start workbench by running:

<Tabs items={['npm', 'yarn', 'pnpm', 'bun']}>
  <Tab value="pnpm">```pnpm run dev ```</Tab>
  <Tab value="yarn">```yarn run dev ```</Tab>
  <Tab value="npm">```npm run dev ```</Tab>
  <Tab value="bun">```bun run dev ```</Tab>
</Tabs>

<Callout>
  Running the dev command starts: - **Motia Server**: Backend services and API endpoints - **Motia Workbench**: Web
  interface at http://localhost:3000 - **Development Mode**: Auto-reloads when changes are made
</Callout>

## Key Features

<Steps>
  <Step>
    
  ### Flow Visualization
  See your entire flow as an interactive diagram:
  - Steps appear as connected nodes
  - API endpoints are highlighted as entry points
  - Event connections show data flow
  - Click any step to see its details
  </Step>

  <Step>
  
  ### Real-time Testing 
  Test your flows directly in the interface: 
  - Send test requests to API endpoints 
  - Monitor how events flow through steps 
  - Visualize step sequence execution 
  - Inspect data at each stage
  </Step>

  <Step>
  
  ### Live Logs 
  Monitor your flow execution: 
  ``` 
  [INFO] [payment-flow] Payment received: $50.00 [DEBUG] [payment-flow]
  Processing payment... 
  ```
  </Step>

  <Step>
   
  ### Development Tools
  - **Hot Reload**: Changes reflect immediately in the UI
  - **Error Handling**: Detailed error messages with contextual debugging information
  - **State Inspector**: Real-time monitoring of state management
  </Step>
</Steps>

## Customization

Motia Workbench allows you to customize how your steps appear in the Workbench flow visualization tool.

### NOOP Steps

NOOP (No Operation) steps represent virtual points in your flow where external actions occur:

- Human approvals or reviews
- Webhook callbacks
- External system integrations
- Manual interventions

These steps help visualize important external touchpoints without implementing actual logic.

### UI Steps

UI steps allow you to customize how your steps appear in the Workbench visualization:

- Override the default layout of Event steps
- Customize API endpoint representations
- Modify how Cron jobs are displayed
- Add custom icons and styling

<Breadcrumb
  items={[
    {
      name: 'UI Steps',
      url: '/docs/workbench/ui-steps',
    },
    {
      name: 'NOOP Steps',
      url: '/docs/workbench/noop-steps',
    },
  ]}
/>

<Callout>New to Motia? Follow the **[quick start](/docs/getting-started/quick-start)** guide to get set up.</Callout>


-   [UI Steps](/docs/workbench/ui-steps): Documentation for UI Steps.
---
title: UI Steps
---

UI Steps provide a powerful way to create custom, visually appealing representations of your workflow steps in the Workbench flow visualization tool.

With UI Steps, you can enhance the user experience by designing intuitive, context-aware visual components that clearly communicate your flow's sequencing and events.

## Overview

To create a custom UI for a step, create a `.tsx` or `.jsx` file next to your step file with the same base name:

<Tabs items={['tsx', 'jsx']}>
  <Tab value="tsx">
    ``` 
    steps/ 
    ‚îî‚îÄ‚îÄ myStep/ 
      ‚îú‚îÄ‚îÄ myStep.step.ts      # Step definition
      ‚îî‚îÄ‚îÄ myStep.step.tsx     # Visual override
    ```
  </Tab>
  <Tab value="jsx">
    ```
    steps/
      ‚îî‚îÄ‚îÄ myStep/
      ‚îú‚îÄ‚îÄ myStep.step.js      # Step definition
      ‚îî‚îÄ‚îÄ myStep.step.jsx     # Visual override
    ```
  </Tab>
</Tabs>

## Basic Usage

Let's override an EventNode but keeping the same look. Like the image below.
We're going to add an image on the side and show the description.

![Custom Event Node](./../img/custom-event-node.png)

<Tabs items={['TypeScript', 'JavaScript']}>
  <Tab>
    ```tsx
    // myStep.step.tsx

    import { EventNode, EventNodeProps } from 'motia/workbench'
    import React from 'react'

    export const Node: React.FC<EventNodeProps> = (props) => {
      return (
        <EventNode {...props}>
          <div className="flex flex-row items-start gap-2">
            <div className="text-sm text-gray-400 font-mono">{props.data.description}</div>
            <img
              style={{ width: '64px', height: '64px' }}
              src="https://www.motia.dev/icon.png"
            />
          </div>
        </EventNode>
      )
    }
    ```

  </Tab>
  <Tab>
    ```jsx
    // myStep.step.jsx

    import { EventNode } from 'motia/workbench'
    import React from 'react'

    export const Node = (props) => {
      return (
        <EventNode {...props}>
          <div className="flex flex-row items-start gap-2">
            <div className="text-sm text-gray-400 font-mono">{props.data.description}</div>
            <img
              style={{ width: '64px', height: '64px' }}
              src="https://www.motia.dev/icon.png"
            />
          </div>
        </EventNode>
      )
    }
    ```

    

  </Tab>
</Tabs>

## Components

Motia Workbench provides out of the box components that you can use to create custom UI steps, which apply to different types of steps.


| Component   | Props Type     | Description                                                                    |
| ----------- | -------------- | ------------------------------------------------------------------------------ |
| EventNode   | EventNodeProps | Base component for Event Steps, with built-in styling and connection points    |
| ApiNode     | ApiNodeProps   | Component for API Steps, includes request/response visualization capabilities  |
| CronNode    | CronNodeProps  | Base component for Cron Steps, displays timing information                     |
| NoopNode    | NoopNodeProps  | Base component for NoopNodes with a different color to comply workbench legend |

## Customizing completely

You can also fully customize your node making it look completely different from the result.
Let's draw the following node.

![Custom Ideator Agent Node](./../img/custom-ideator-agent-node.png)

```tsx
import { BaseHandle, EventNodeProps, Position } from 'motia/workbench'
import React from 'react'

export const Node: React.FC<EventNodeProps> = (props) => {
  return (
    <div className="w-80 bg-black text-white rounded-xl p-4">
      <div className="group relative">
        <BaseHandle type="target" position={Position.Top} variant="event" />

        <div className="flex items-center space-x-3">
          <img className="w-8 h-8" src="https://cdn-icons-png.flaticon.com/512/12222/12222588.png" />
          <div className="text-lg font-semibold">{props.data.name}</div>
        </div>

        <div className="mt-2 text-sm font-medium text-gray-300">{props.data.description}</div>

        <div className="mt-3 flex flex-col gap-2 border border-gray-800 border-solid p-2 rounded-md w-full">
          <div className="flex items-center text-xs text-gray-400 space-x-2">Input</div>
          <div className="flex flex-col gap-2 whitespace-pre-wrap font-mono">
            <div className="flex items-center gap-2">
              <div className="">contentIdea:</div>
              <div className="text-orange-500">string</div>
            </div>
            <div className="flex items-center gap-2">
              <div className="">contentType:</div>
              <div className="text-orange-500">string</div>
            </div>
          </div>
        </div>

        <div className="mt-3 flex flex-col gap-2 border border-gray-800 border-solid p-2 rounded-md w-full">
          <div className="flex items-center text-xs text-gray-400 space-x-2">Output</div>
          <div className="flex flex-col gap-2 whitespace-pre-wrap font-mono">
            <div className="flex items-center gap-2">
              <div className="">topic:</div>
              <div className="text-orange-500">string</div>
            </div>
            <div className="flex items-center gap-2">
              <div className="">subtopics:</div>
              <div className="text-orange-500">string[]</div>
            </div>
            <div className="flex items-center gap-2">
              <div className="">keywords:</div>
              <div className="text-orange-500">string[]</div>
            </div>
            <div className="flex items-center gap-2">
              <div className="">tone:</div>
              <div className="text-orange-500">string</div>
            </div>
            <div className="flex items-center gap-2">
              <div className="">audience:</div>
              <div className="text-orange-500">string</div>
            </div>
          </div>
        </div>

        <BaseHandle type="source" position={Position.Bottom} variant="event" />
      </div>
    </div>
  )
}
```

### Important Notes

- You will need to add `<BaseHandle>` to your node, otherwize it won't show the connectors.
- If your node has padding, make sure to add a group inside your node with class `group relative` so the handles can be correctly positioned.

<Callout type="info">Feel free to create your own custom components and reuse across multiple notes.</Callout>

## Styling Guidelines

| Guideline                           | Description                                                   |
| ----------------------------------- | ------------------------------------------------------------- |
| Use Tailwind's utility classes only | Stick to Tailwind CSS utilities for consistent styling        |
| Avoid arbitrary values              | Use predefined scales from the design system                  |
| Keep components responsive          | Ensure UI elements adapt well to different screen sizes       |
| Follow Motia's design system        | Maintain consistency with Motia's established design patterns |



## Best Practices

| Practice             | Description                                 |
| -------------------- | ------------------------------------------- |
| Use base components  | Use `EventNode` and `ApiNode` when possible |
| Keep it simple       | Maintain simple and clear visualizations    |
| Optimize performance | Minimize state and computations             |
| Documentation        | Document custom components and patterns     |
| Style sharing        | Share common styles through utility classes |



## Optional
-   [https://motiadev.com](https://motiadev.com): Main page for framework.
-   [Github repo](https://github.com/motiadev/motia): Main github repository to file issues.
